<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Global Defense AI Policy Landscape</title>
    
    <!-- SEO & Sharing Meta Tags -->
    <meta name="description" content="Interactive visualization mapping military and defense AI governance frameworks across 45 nations. Explore policies on autonomous weapons, ethical guidelines, and international cooperation.">
    <meta name="keywords" content="defense AI, military AI, autonomous weapons, LAWS, AI governance, defense policy, AI ethics, international security">
    <meta name="author" content="Defense AI Policy Research">
    
    <!-- Open Graph (Facebook, LinkedIn) -->
    <meta property="og:title" content="Global Defense AI Policy Landscape">
    <meta property="og:description" content="Interactive visualization mapping military and defense AI governance frameworks across 45 nations.">
    <meta property="og:type" content="website">
    <meta property="og:locale" content="en_US">
    
    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Global Defense AI Policy Landscape">
    <meta name="twitter:description" content="Interactive visualization mapping military and defense AI governance frameworks across 45 nations.">
    
    <!-- Favicon (embedded data URI) -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'%3E%3Crect fill='%231a2744' width='100' height='100' rx='20'/%3E%3Ctext x='50' y='68' font-size='50' text-anchor='middle' fill='white'%3EðŸŒ%3C/text%3E%3C/svg%3E">
    
    <!-- Theme Color for Mobile Browsers -->
    <meta name="theme-color" content="#1a2744">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link href="https://fonts.googleapis.com/css2?family=Plus+Jakarta+Sans:wght@400;500;600;700;800&family=Montserrat:wght@400;500;600&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/topojson/3.0.2/topojson.min.js"></script>
    <style>
        :root {
            --navy: #1a2744;
            --navy-light: #243352;
            --navy-lighter: #2d3f5f;
            --teal: #0d7377;
            --teal-light: #0f8a8f;
            --coral: #d64045;
            --cream: #f5ead6;
            --cream-dark: #e8dcc8;
            --purple: #6b3074;
            --gold: #c9a227;
            --burnt-orange: #e07020;
            --dark-teal: #0a5e5e;
            --light-green: #4a9d5b;
            --muted-teal: #5a9a9a;
            --text-light: #ffffff;
            --text-dark: #1a2744;
            --text-muted: #7a8a9a;
            --ocean: #1a3a5c;
            --land: #3d5a73;
            --land-data: #0d7377;
        }


        * { margin: 0; padding: 0; box-sizing: border-box; }


        body {
            font-family: 'Montserrat', -apple-system, sans-serif;
            background: #f0f2f5;
            color: var(--text-dark);
            min-height: 100vh;
            line-height: 1.7;
        }


        h1, h2, h3, h4, h5, h6, .header-font {
            font-family: 'Plus Jakarta Sans', -apple-system, sans-serif;
        }


        .container {
            max-width: 1800px;
            margin: 0 auto;
            padding: 0;
        }


        header {
            text-align: left;
            margin-bottom: 40px;
            padding: 50px 50px 40px 50px;
            background: var(--navy);
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
        }
        
        .header-content {
            flex: 1;
        }
        
        .header-logo {
            flex-shrink: 0;
            margin-left: 40px;
        }
        
        .header-logo img {
            height: 50px;
            width: auto;
        }


        .overline {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 12px;
            font-weight: 700;
            letter-spacing: 4px;
            text-transform: uppercase;
            color: var(--teal-light);
            margin-bottom: 20px;
        }


        h1 {
            font-size: clamp(2.2rem, 4vw, 3.2rem);
            font-weight: 800;
            color: #ffffff;
            margin-bottom: 16px;
            letter-spacing: -0.5px;
            line-height: 1.2;
        }


        .subtitle {
            font-size: 1.1rem;
            color: #a8b5c7;
            font-weight: 400;
            max-width: 600px;
            margin: 0;
            line-height: 1.6;
        }


        .line-decoration {
            margin-top: 24px;
        }

        .line-decoration .line { 
            width: 120px; 
            height: 3px; 
            background: var(--coral); 
        }
        
        .line-decoration .dot { 
            display: none;
        }
        
        
        .main-content {
            padding: 40px 50px 60px 50px;
        }


        /* ===== MAP ===== */
        .map-container {
            background: var(--ocean);
            border-radius: 16px;
            padding: 0;
            position: relative;
            overflow: hidden;
            margin-bottom: 40px;
        }


        .map-controls {
            position: absolute;
            top: 16px;
            left: 16px;
            display: flex;
            flex-direction: column;
            gap: 8px;
            z-index: 10;
        }


        .map-control-btn {
            width: 36px;
            height: 36px;
            background: rgba(255,255,255,0.95);
            border: none;
            border-radius: 8px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.2rem;
            font-weight: 700;
            color: var(--navy);
            transition: all 0.2s;
            box-shadow: 0 2px 8px rgba(0,0,0,0.2);
        }


        .map-control-btn:hover {
            background: white;
            transform: scale(1.05);
        }


        .map-hint {
            position: absolute;
            bottom: 16px;
            left: 16px;
            font-size: 0.75rem;
            color: rgba(255,255,255,0.6);
            background: rgba(0,0,0,0.3);
            padding: 6px 12px;
            border-radius: 6px;
            z-index: 10;
        }


        #map-svg { 
            width: 100%; 
            height: 550px; 
            display: block; 
            cursor: grab;
        }


        #map-svg:active {
            cursor: grabbing;
        }


        .ocean {
            fill: var(--ocean);
        }


        .country-path {
            fill: var(--land);
            stroke: rgba(255,255,255,0.15);
            stroke-width: 0.5;
            transition: fill 0.3s ease;
        }


        .country-path.has-data { 
            fill: var(--land-data); 
            cursor: pointer; 
        }


        .country-path.has-data:hover { 
            fill: #10918f; 
        }


        .country-path.selected { 
            fill: rgba(240, 228, 210, 0.8) !important;
        }


        .country-path.disabled { 
            opacity: 0.5; 
            cursor: not-allowed; 
        }


        .country-path.alliance-member {
            fill: var(--teal) !important;
            stroke: #ffffff !important;
            stroke-width: 0.75px !important;
            cursor: pointer;
        }


        .country-path.alliance-member:hover {
            fill: #0d7a78 !important;
            stroke: #ffffff !important;
            stroke-width: 1px !important;
        }


        .graticule { 
            fill: none; 
            stroke: rgba(255,255,255,0.08); 
            stroke-width: 0.5; 
        }


        .tooltip {
            position: fixed;
            background: var(--navy);
            border-radius: 8px;
            padding: 12px 16px;
            font-size: 0.85rem;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.2s;
            z-index: 1000;
            box-shadow: 0 8px 30px rgba(0,0,0,0.25);
            color: var(--text-light);
        }


        .tooltip.visible { opacity: 1; }
        .tooltip-title { font-family: 'Plus Jakarta Sans', sans-serif; font-weight: 700; }
        .tooltip-subtitle { font-size: 0.75rem; color: var(--text-muted); margin-top: 4px; }


        /* ===== TABS ===== */
        .view-tabs {
            display: flex;
            gap: 4px;
            margin-bottom: 24px;
            background: white;
            padding: 6px;
            border-radius: 12px;
            display: inline-flex;
            box-shadow: 0 2px 8px rgba(26, 39, 68, 0.06);
        }


        .view-tab {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.9rem;
            font-weight: 600;
            padding: 12px 28px;
            border: none;
            background: transparent;
            color: var(--text-muted);
            cursor: pointer;
            border-radius: 8px;
            transition: all 0.2s;
        }


        .view-tab:hover { color: var(--navy); }
        .view-tab.active { background: var(--navy); color: white; }


        /* ===== COUNTRY CHIPS ===== */
        .country-selector { margin-bottom: 20px; }


        .country-selector-controls {
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 20px;
            flex-wrap: wrap;
        }


        .country-search-wrapper {
            position: relative;
            width: 250px;
            flex-shrink: 0;
        }


        .country-search {
            width: 100%;
            padding: 10px 14px;
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.85rem;
            font-weight: 400;
            color: var(--navy);
            background: white;
            border: 1px solid var(--cream-dark);
            border-radius: 8px;
            transition: all 0.2s ease;
        }


        .country-search::placeholder {
            color: var(--text-muted);
            font-weight: 400;
        }


        .country-search:hover {
            border-color: #ccc;
        }


        .country-search:focus {
            outline: none;
            border-color: var(--teal);
            box-shadow: 0 0 0 2px rgba(42, 157, 143, 0.1);
        }


        .search-results-dropdown {
            position: absolute;
            top: 100%;
            left: 0;
            right: 0;
            background: white;
            border: 1px solid var(--cream-dark);
            border-radius: 8px;
            margin-top: 4px;
            max-height: 200px;
            overflow-y: auto;
            z-index: 100;
            display: none;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }


        .search-results-dropdown.visible {
            display: block;
        }


        .search-result-item {
            padding: 10px 14px;
            cursor: pointer;
            font-size: 0.85rem;
            color: var(--navy);
            transition: background 0.15s;
        }


        .search-result-item:hover {
            background: #e8ebef;
        }


        .search-result-item:first-child {
            border-radius: 8px 8px 0 0;
        }


        .search-result-item:last-child {
            border-radius: 0 0 8px 8px;
        }


        .search-result-item:only-child {
            border-radius: 8px;
        }


        .search-message {
            position: absolute;
            top: 100%;
            left: 0;
            right: 0;
            background: white;
            border: 1px solid var(--cream-dark);
            border-radius: 8px;
            margin-top: 4px;
            padding: 12px 14px;
            font-size: 0.8rem;
            color: var(--text-muted);
            display: none;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }


        .search-message.visible {
            display: block;
        }
        
        @media (max-width: 600px) {
            .country-selector-controls {
                flex-direction: column;
                align-items: stretch;
            }
            .country-search-wrapper {
                width: 100%;
            }
        }


        .country-selector-label {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.75rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 2px;
            color: var(--text-muted);
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 12px;
        }


        .selection-limit {
            font-weight: 500;
            font-size: 0.7rem;
            color: var(--coral);
            letter-spacing: 1px;
        }


        .country-dropdown {
            width: 350px;
            flex-shrink: 0;
            padding: 12px 16px;
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.95rem;
            font-weight: 500;
            color: var(--navy);
            background: white;
            border: 2px solid var(--cream-dark);
            border-radius: 10px;
            cursor: pointer;
            transition: all 0.2s ease;
            appearance: none;
            background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='16' height='16' viewBox='0 0 24 24' fill='none' stroke='%231a2744' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpath d='M6 9l6 6 6-6'/%3E%3C/svg%3E");
            background-repeat: no-repeat;
            background-position: right 12px center;
        }


        .country-dropdown:hover {
            border-color: var(--teal);
        }


        .country-dropdown:focus {
            outline: none;
            border-color: var(--teal);
            box-shadow: 0 0 0 3px rgba(42, 157, 143, 0.15);
        }


        .selected-countries {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-top: 8px;
        }


        .selected-tag {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 6px 12px;
            background: var(--muted-teal);
            color: white;
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.85rem;
            font-weight: 500;
            border-radius: 20px;
            cursor: default;
        }


        .selected-tag .remove-btn {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 18px;
            height: 18px;
            background: rgba(255,255,255,0.25);
            border: none;
            border-radius: 50%;
            cursor: pointer;
            transition: background 0.2s ease;
            padding: 0;
        }


        .selected-tag .remove-btn:hover {
            background: rgba(255,255,255,0.4);
        }


        .selected-tag .remove-btn svg {
            width: 12px;
            height: 12px;
            stroke: white;
        }


        .country-chips { display: flex; flex-wrap: wrap; gap: 12px; }


        .country-chip {
            display: flex;
            align-items: center;
            gap: 10px;
            padding: 12px 20px;
            background: white;
            border: 2px solid var(--cream-dark);
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.2s;
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-weight: 600;
            font-size: 0.9rem;
            color: var(--navy);
        }


        .country-chip:hover { border-color: var(--teal); }
        .country-chip.selected { background: var(--coral); border-color: var(--coral); color: white; }
        .country-chip.disabled { opacity: 0.4; cursor: not-allowed; border-color: var(--cream-dark); }
        .country-chip.disabled:hover { border-color: var(--cream-dark); }


        .country-chip .check-icon {
            width: 18px;
            height: 18px;
            border: 2px solid var(--cream-dark);
            border-radius: 4px;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s;
        }


        .country-chip.selected .check-icon { background: white; border-color: white; }
        .country-chip .check-icon svg { width: 12px; height: 12px; opacity: 0; color: var(--coral); }
        .country-chip.selected .check-icon svg { opacity: 1; }


        .view-overview .country-chip .check-icon { display: none; }


        /* ===== MAIN SECTION ===== */
        .main-section {
            background: white;
            border-radius: 16px;
            box-shadow: 0 4px 20px rgba(26, 39, 68, 0.06);
            min-height: 500px;
        }


        .section-header {
            padding: 24px 28px;
            border-bottom: 1px solid var(--cream-dark);
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-wrap: wrap;
            gap: 20px;
        }


        .section-title-area { display: flex; align-items: baseline; gap: 20px; }


        .section-title {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 1.75rem;
            font-weight: 800;
            color: var(--navy);
            letter-spacing: -0.3px;
        }


        .section-subtitle { font-size: 0.9rem; color: var(--text-muted); }


        .policy-area-selector { display: flex; align-items: center; gap: 16px; }


        .policy-area-label {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.75rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 1.5px;
            color: var(--text-muted);
        }


        .policy-area-dropdown {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.95rem;
            font-weight: 600;
            padding: 12px 40px 12px 20px;
            border: 2px solid var(--cream-dark);
            border-radius: 10px;
            background: #e8ebef url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='16' height='16' viewBox='0 0 24 24' fill='none' stroke='%231a2744' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpath d='M6 9l6 6 6-6'/%3E%3C/svg%3E") no-repeat right 14px center;
            color: var(--navy);
            cursor: pointer;
            appearance: none;
            min-width: 280px;
        }


        .policy-area-dropdown:hover, .policy-area-dropdown:focus { border-color: var(--teal); outline: none; }


        .filters { display: flex; align-items: center; gap: 20px; flex-wrap: wrap; }


        .filter-label {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.7rem;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 1.5px;
            font-weight: 700;
        }


        .filter-group { display: flex; align-items: center; gap: 10px; }


        .filter-checkbox {
            display: flex;
            align-items: center;
            gap: 8px;
            cursor: pointer;
            font-size: 0.8rem;
            padding: 8px 14px;
            border-radius: 6px;
            background: #e8ebef;
            transition: all 0.2s;
            font-weight: 500;
            color: var(--navy);
            border-left: 3px solid transparent;
        }


        .filter-checkbox:hover { background: #dde1e6; }
        .filter-checkbox input { accent-color: var(--teal); width: 15px; height: 15px; }
        .filter-checkbox.legal { border-left-color: var(--navy); }
        .filter-checkbox.policy { border-left-color: var(--teal); }
        .filter-checkbox.statement { border-left-color: var(--coral); }


        .section-content { padding: 36px; }
        
        #compare-content {
            width: 100%;
            padding: 20px !important;
        }
        
        #compare-content .comparison-grid {
            width: 100%;
        }
        
        /* Compact styling for comparison view */
        #compare-content .source-item-content {
            padding: 10px 12px 12px;
            font-size: 0.82rem;
            line-height: 1.5;
        }
        
        #compare-content .source-item-content p {
            margin-bottom: 8px;
        }
        
        #compare-content .source-item-content ul {
            margin: 6px 0;
            padding-left: 16px;
        }
        
        #compare-content .source-item-content li {
            margin-bottom: 4px;
        }


        .placeholder {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 350px;
            color: var(--text-muted);
            text-align: center;
        }


        .placeholder svg { width: 60px; height: 60px; margin-bottom: 20px; opacity: 0.25; }
        .placeholder p { font-size: 1rem; line-height: 1.6; }


        /* ===== POLICY AREAS (Overview) ===== */
        .policy-areas { display: flex; flex-direction: column; gap: 16px; }


        /* ===== ALLIANCE MEMBERS LIST ===== */
        .alliance-members-list {
            padding: 16px 24px 20px;
            margin-bottom: 8px;
        }
        
        .alliance-members-label {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.7rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 1.5px;
            color: var(--text-muted);
            margin-bottom: 10px;
        }
        
        .alliance-members-chips {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
        }
        
        .alliance-member-chip {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.8rem;
            font-weight: 500;
            padding: 6px 14px;
            background: #e8ebef;
            color: var(--text-muted);
            border-radius: 20px;
            transition: all 0.2s;
        }
        
        .alliance-member-chip.has-data {
            background: var(--navy);
            color: white;
            cursor: pointer;
        }
        
        .alliance-member-chip.has-data:hover {
            background: var(--navy-light);
            transform: translateY(-1px);
        }


        /* ===== ALLIANCE VISUALIZATIONS ===== */
        .alliance-insights-row {
            display: grid;
            grid-template-columns: 1fr 1.4fr;
            gap: 24px;
            margin-bottom: 28px;
        }
        
        @media (max-width: 900px) {
            .alliance-insights-row {
                grid-template-columns: 1fr;
            }
        }
        
        .alliance-chart-box {
            background: white;
            border-radius: 12px;
            padding: 20px 24px;
            box-shadow: 0 2px 12px rgba(0,0,0,0.04);
        }
        
        .alliance-chart-title {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-weight: 700;
            font-size: 0.95rem;
            color: var(--navy);
            margin-bottom: 6px;
        }
        
        .alliance-chart-subtitle {
            font-size: 0.78rem;
            color: var(--text-muted);
            margin-bottom: 18px;
        }
        
        /* Member Contribution Bar Chart */
        .member-bar-row {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 6px;
        }
        
        .member-bar-name {
            width: 90px;
            font-size: 0.78rem;
            font-weight: 600;
            color: var(--navy);
            text-align: right;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }
        
        .member-bar-track {
            flex: 1;
            height: 22px;
            background: #e8ebef;
            border-radius: 4px;
            overflow: hidden;
        }
        
        .member-bar-fill {
            height: 100%;
            border-radius: 4px;
            transition: width 0.4s ease;
        }
        
        .member-bar-fill.rank-1 { background: var(--navy); }
        .member-bar-fill.rank-2 { background: #3d5a80; }
        .member-bar-fill.rank-3 { background: #6b8299; }
        
        .member-bar-value {
            width: 28px;
            font-size: 0.8rem;
            font-weight: 700;
            color: var(--navy);
            text-align: left;
        }
        
        .member-bar-value.muted {
            color: var(--text-muted);
        }
        
        /* Heatmap */
        .alliance-heatmap {
            width: 100%;
            border-collapse: separate;
            border-spacing: 3px;
            font-size: 0.72rem;
        }
        
        .alliance-heatmap th {
            padding: 6px 4px;
            font-weight: 600;
            color: var(--navy);
            text-align: center;
            font-size: 0.68rem;
        }
        
        .alliance-heatmap th.member-col {
            text-align: left;
            padding-left: 8px;
            color: var(--text-muted);
            font-size: 0.65rem;
            letter-spacing: 0.5px;
        }
        
        .alliance-heatmap .area-dot {
            width: 8px;
            height: 8px;
            border-radius: 2px;
            margin: 0 auto 3px;
        }
        
        .alliance-heatmap td {
            padding: 5px 4px;
            text-align: center;
            font-weight: 600;
            border-radius: 4px;
            transition: all 0.2s;
        }
        
        .alliance-heatmap td.member-name {
            text-align: left;
            padding-left: 8px;
            font-weight: 600;
            color: var(--navy);
            background: #fafbfc;
        }
        
        .alliance-heatmap td.total-cell {
            background: var(--cream);
            font-weight: 700;
            color: var(--navy);
        }
        
        .alliance-heatmap td.heat-cell {
            color: var(--navy);
            cursor: default;
        }
        
        .alliance-heatmap td.heat-cell.empty {
            color: #ccc;
        }
        
        .alliance-heatmap td.heat-cell.high {
            color: white;
        }
        
        .heatmap-legend {
            display: flex;
            align-items: center;
            gap: 12px;
            margin-top: 14px;
            font-size: 0.72rem;
            color: var(--text-muted);
        }
        
        .heatmap-legend-item {
            display: flex;
            align-items: center;
            gap: 4px;
        }
        
        .heatmap-legend-swatch {
            width: 16px;
            height: 10px;
            border-radius: 2px;
        }
        
        .expand-more-toggle {
            font-size: 0.75rem;
            color: var(--teal);
            margin-top: 12px;
            text-align: center;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 4px;
            padding: 6px;
            border-radius: 6px;
            transition: all 0.2s;
        }
        
        .expand-more-toggle:hover {
            background: #e8ebef;
        }
        
        .expand-more-icon {
            width: 14px;
            height: 14px;
            transition: transform 0.2s ease;
        }
        
        /* Alliance Info Note */
        .alliance-chart-header {
            display: flex;
            align-items: flex-start;
            justify-content: space-between;
            margin-bottom: 6px;
        }
        
        .alliance-info-note {
            display: inline-flex;
            align-items: center;
            gap: 4px;
            font-size: 0.7rem;
            color: var(--text-muted);
            cursor: help;
            position: relative;
            padding: 4px 8px;
            border-radius: 4px;
            transition: all 0.2s;
            flex-shrink: 0;
        }
        
        .alliance-info-note:hover {
            background: #e8ebef;
            color: var(--navy);
        }
        
        .alliance-info-note .info-icon {
            width: 13px;
            height: 13px;
            border: 1.5px solid currentColor;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.6rem;
            font-weight: 700;
            font-style: italic;
            font-family: Georgia, serif;
        }
        
        .alliance-info-tooltip {
            position: absolute;
            bottom: calc(100% + 8px);
            right: 0;
            background: var(--navy);
            color: white;
            padding: 10px 14px;
            border-radius: 8px;
            font-size: 0.75rem;
            line-height: 1.5;
            width: 260px;
            text-align: left;
            opacity: 0;
            visibility: hidden;
            transition: all 0.2s ease;
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
            z-index: 100;
        }
        
        .alliance-info-tooltip::after {
            content: '';
            position: absolute;
            top: 100%;
            right: 16px;
            border: 6px solid transparent;
            border-top-color: var(--navy);
        }
        
        .alliance-info-note:hover .alliance-info-tooltip {
            opacity: 1;
            visibility: visible;
        }


        .policy-area { background: #e8ebef; border-radius: 12px; overflow: hidden; }


        .policy-area-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 20px 24px;
            cursor: pointer;
            transition: background 0.2s;
        }


        .policy-area-header:hover { background: #dde1e6; }


        .policy-area-title {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-weight: 700;
            font-size: 1rem;
            color: var(--navy);
            display: flex;
            align-items: center;
            gap: 14px;
        }


        .policy-area-title::before {
            content: '';
            width: 5px;
            height: 22px;
            border-radius: 3px;
            background: var(--teal);
        }


        .policy-area[data-area="laws"] .policy-area-title::before { background: var(--navy); }
        .policy-area[data-area="adoption"] .policy-area-title::before { background: var(--coral); }
        .policy-area[data-area="acquisition"] .policy-area-title::before { background: var(--purple); }
        .policy-area[data-area="international"] .policy-area-title::before { background: var(--teal); }
        .policy-area[data-area="technical"] .policy-area-title::before { background: #e07020; }
        .policy-area[data-area="ethical"] .policy-area-title::before { background: #4a9d5b; }


        .policy-area-meta { display: flex; align-items: center; gap: 14px; }
        .source-count { font-size: 0.8rem; color: var(--text-muted); font-weight: 600; }


        .expand-icon {
            width: 20px;
            height: 20px;
            color: var(--text-muted);
            transition: transform 0.3s;
        }


        .policy-area.expanded .expand-icon { transform: rotate(180deg); }


        .policy-area-content { display: none; padding: 0 24px 24px; }
        .policy-area.expanded .policy-area-content { display: block; }


        /* ===== COMPARISON GRID ===== */
        .comparison-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 16px;
            width: 100%;
        }


        .country-column { 
            background: white; 
            border-radius: 10px; 
            overflow: hidden;
            display: flex;
            flex-direction: column;
            border: 1px solid var(--border);
        }
        
        .country-column:first-child .country-column-header {
            background: var(--navy);
        }
        
        .country-column:nth-child(2) .country-column-header {
            background: #3d5a7f;
        }


        .country-column-header {
            background: var(--navy);
            color: white;
            padding: 14px 18px;
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-weight: 700;
            font-size: 1rem;
            display: flex;
            align-items: center;
            justify-content: space-between;
            position: sticky;
            top: 0;
            z-index: 10;
        }


        .country-column-header .col-source-count { 
            font-size: 0.75rem; 
            font-weight: 500; 
            opacity: 0.8;
            background: rgba(255,255,255,0.15);
            padding: 4px 10px;
            border-radius: 12px;
        }


        .country-column-content { 
            padding: 14px; 
            max-height: calc(100vh - 340px); 
            min-height: 520px; 
            overflow-y: auto;
            flex: 1;
            background: #fafbfc;
        }


        .col-policy-area { margin-bottom: 18px; }
        .col-policy-area:last-child { margin-bottom: 0; }
        


        /* === REDESIGNED COMPARE VIEW === */
        .compare-header-chips {
            display: flex;
            justify-content: center;
            gap: 40px;
            margin-bottom: 30px;
        }
        
        .compare-chip {
            display: flex;
            align-items: center;
            gap: 10px;
            padding: 12px 20px;
            background: white;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }
        
        .compare-chip .chip-dot {
            width: 14px;
            height: 14px;
            border-radius: 50%;
        }
        
        .compare-chip.country-1 .chip-dot { background: var(--navy); }
        .compare-chip.country-2 .chip-dot { background: var(--purple); }
        
        .compare-chip .chip-name {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-weight: 600;
            color: var(--navy);
        }
        
        .compare-chip .chip-count {
            color: var(--text-muted);
            font-size: 0.9rem;
        }
        
        .compare-section-box {
            background: white;
            border-radius: 12px;
            padding: 24px 30px;
            margin-bottom: 24px;
            box-shadow: 0 2px 12px rgba(0,0,0,0.06);
        }
        
        .compare-section-title {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 1.1rem;
            font-weight: 600;
            color: var(--navy);
            margin-bottom: 20px;
            text-align: center;
        }
        
        /* Diverging Bar Chart */
        .diverging-chart {
            display: flex;
            flex-direction: column;
            gap: 14px;
        }
        
        .chart-row {
            display: grid;
            grid-template-columns: 50px 1fr 220px 1fr 50px;
            align-items: center;
            gap: 8px;
            min-height: 32px;
        }
        
        .chart-row.total-row {
            padding-bottom: 16px;
            margin-bottom: 10px;
            border-bottom: 2px solid var(--cream-dark);
        }
        
        .chart-row.clickable {
            cursor: pointer;
            border-radius: 4px;
            padding: 4px 0;
            transition: background 0.2s;
        }
        
        .chart-row.clickable:hover {
            background: #e8ebef;
        }
        
        .chart-value-left {
            text-align: right;
            font-weight: 600;
            font-size: 0.95rem;
            color: var(--navy);
        }
        
        .chart-value-right {
            text-align: left;
            font-weight: 600;
            font-size: 0.95rem;
            color: var(--purple);
        }
        
        .chart-bar-left {
            display: flex;
            justify-content: flex-end;
        }
        
        .chart-bar-right {
            display: flex;
            justify-content: flex-start;
        }
        
        .chart-bar {
            height: 22px;
            border-radius: 3px;
            transition: width 0.4s ease-out;
        }
        
        .chart-bar.left { background: var(--navy); }
        .chart-bar.right { background: var(--purple); }
        
        .chart-bar {
            position: relative;
        }
        
        .bar-country-label {
            position: absolute;
            top: -20px;
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.85rem;
            font-weight: 600;
            color: var(--navy);
            white-space: nowrap;
        }
        
        .chart-bar.left .bar-country-label {
            right: 0;
        }
        
        .chart-bar.right .bar-country-label {
            left: 0;
        }
        .chart-header-row {
            display: flex;
            flex-direction: column;
            margin-bottom: 20px;
        }
        
        .country-names-row {
            display: grid;
            grid-template-columns: 1fr 220px 1fr;
            align-items: center;
            margin-top: 8px;
            padding: 0 50px;
        }
        
        .country-name-label {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 1.1rem;
            font-weight: 700;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .country-name-label.country-1 {
            justify-content: center;
            color: var(--navy);
        }
        
        .country-name-label.country-2 {
            justify-content: center;
            color: var(--purple);
        }
        
        .country-name-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            display: inline-block;
        }
        
        .country-name-label.country-1 .country-name-dot {
            background: var(--navy);
        }
        
        .country-name-label.country-2 .country-name-dot {
            background: var(--purple);
        }
        
        .country-name-spacer {
            width: 220px;
        }




        
        .chart-row-label {
            text-align: center;
            font-size: 0.82rem;
            color: var(--text-dark);
            font-weight: 500;
            line-height: 1.3;
            background: rgba(255, 255, 255, 0.7);
            padding: 6px 12px;
            border-radius: 6px;
            box-shadow: 0 1px 4px rgba(0, 0, 0, 0.06);
        }
        
        .chart-row-label.total {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-weight: 700;
            font-size: 0.95rem;
            color: var(--navy);
            background: none;
            box-shadow: none;
            padding: 0;
        }
        
        .chart-row.clickable .chart-row-label {
            color: var(--teal);
        }
        
        .chart-row.clickable:hover .chart-row-label {
            text-decoration: underline;
        }
        
        /* Timeline */
        .compare-timeline-container {
            position: relative;
            padding: 20px 0;
        }
        
        .timeline-row {
            position: relative;
            height: 80px;
            margin: 0 50px;
        }
        
        .timeline-row-label {
            position: absolute;
            left: -50px;
            top: 50%;
            transform: translateY(-50%);
            font-size: 0.75rem;
            font-weight: 600;
            width: 45px;
            text-align: right;
        }
        
        .timeline-row-label.country-1 { color: var(--navy); }
        .timeline-row-label.country-2 { color: var(--purple); }
        
        .timeline-axis {
            position: relative;
            height: 3px;
            background: var(--cream-dark);
            margin: 0 50px;
            border-radius: 2px;
        }
        
        .timeline-dot {
            position: absolute;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            transform: translateX(-50%);
            cursor: pointer;
            transition: transform 0.2s;
            border: 2px solid white;
            box-shadow: 0 1px 3px rgba(0,0,0,0.15);
        }
        
        .timeline-dot:hover {
            transform: translateX(-50%) scale(1.4);
            z-index: 10;
        }
        
        .timeline-dot.country-1 { background: var(--navy); }
        .timeline-dot.country-2 { background: var(--purple); }
        
        .timeline-year-labels {
            display: flex;
            justify-content: space-between;
            margin: 12px 50px 0;
        }
        
        .timeline-year-label {
            font-size: 0.75rem;
            color: var(--text-muted);
            text-align: center;
            width: 40px;
        }
        
        .timeline-legend {
            display: flex;
            justify-content: center;
            gap: 30px;
            margin-top: 16px;
        }
        
        .timeline-legend-item {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 0.85rem;
            color: var(--text-dark);
        }
        
        .timeline-legend-dot {
            width: 11px;
            height: 11px;
            border-radius: 50%;
        }
        
        .timeline-legend-dot.country-1 { background: var(--navy); }
        .timeline-legend-dot.country-2 { background: var(--purple); }
        
        /* Detail List Toggle */
        .detail-toggle-btn {
            width: 100%;
            padding: 14px 20px;
            background: #e8ebef;
            border: 1px solid #dde1e6;
            border-radius: 8px;
            cursor: pointer;
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.95rem;
            font-weight: 500;
            color: var(--navy);
            transition: background 0.2s;
            margin-bottom: 0;
        }
        
        .detail-toggle-btn:hover {
            background: #dde1e6;
        }
        
        .detail-toggle-icon {
            transition: transform 0.3s;
            font-size: 0.8rem;
        }
        
        .detail-toggle-btn.open .detail-toggle-icon {
            transform: rotate(180deg);
        }
        
        .detail-content-wrapper {
            display: none;
            padding: 20px 0 0;
        }
        
        .detail-content-wrapper.open {
            display: block;
        }
        
        .detail-policy-section {
            margin-bottom: 16px;
            border-radius: 12px;
            overflow: hidden;
            background: #e8ebef;
        }
        
        .detail-policy-header {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-weight: 700;
            color: var(--navy);
            padding: 18px 20px;
            background: #e8ebef;
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 10px;
            cursor: pointer;
            transition: background 0.2s;
            position: relative;
            padding-left: 32px;
        }
        
        .detail-policy-header::before {
            content: '';
            position: absolute;
            left: 16px;
            top: 50%;
            transform: translateY(-50%);
            width: 5px;
            height: 24px;
            border-radius: 3px;
            background: var(--teal);
        }
        
        /* Policy area color coding for compare view */
        .detail-policy-section[data-area="laws"] .detail-policy-header::before { background: var(--navy); }
        .detail-policy-section[data-area="adoption"] .detail-policy-header::before { background: var(--coral); }
        .detail-policy-section[data-area="acquisition"] .detail-policy-header::before { background: var(--purple); }
        .detail-policy-section[data-area="international"] .detail-policy-header::before { background: var(--teal); }
        .detail-policy-section[data-area="technical"] .detail-policy-header::before { background: #e07020; }
        .detail-policy-section[data-area="ethical"] .detail-policy-header::before { background: #4a9d5b; }
        
        .detail-policy-header:hover {
            background: #dde1e6;
        }
        
        .detail-policy-header .toggle-icon {
            font-size: 0.8rem;
            transition: transform 0.3s;
            margin-left: 8px;
            color: var(--text-muted);
        }
        
        .detail-policy-section.expanded .detail-policy-header .toggle-icon {
            transform: rotate(180deg);
        }
        
        .detail-policy-content {
            display: none;
            padding: 0 20px 20px;
        }
        
        .detail-policy-section.expanded .detail-policy-content {
            display: block;
        }
        
        .detail-policy-counts {
            display: flex;
            gap: 20px;
            font-size: 0.85rem;
            font-weight: 600;
        }
        
        .detail-policy-counts .count-1 { color: var(--navy); }
        .detail-policy-counts .count-2 { color: var(--purple); }
        
        .detail-entries-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 16px;
        }
        
        .detail-country-entries {
            padding: 16px;
            background: white;
            border-radius: 10px;
            border-left: 4px solid;
            box-shadow: 0 2px 8px rgba(0,0,0,0.04);
        }
        
        .detail-country-entries.country-1 { border-left-color: var(--navy); }
        .detail-country-entries.country-2 { border-left-color: var(--purple); }
        
        .detail-country-entries h4 {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.9rem;
            font-weight: 700;
            color: var(--text-dark);
            margin-bottom: 14px;
            padding-bottom: 10px;
            border-bottom: 1px solid var(--cream-dark);
        }
        
        .detail-entry-item {
            padding: 12px 14px;
            margin-bottom: 10px;
            background: #e8ebef;
            border-radius: 8px;
            font-size: 0.85rem;
            border: none;
        }
        
        .detail-entry-item:last-child {
            margin-bottom: 0;
        }
        
        .detail-entry-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            cursor: pointer;
            gap: 8px;
        }
        
        .detail-entry-header:hover .detail-entry-title {
            color: var(--teal);
        }
        
        .detail-entry-info {
            flex: 1;
        }
        
        .detail-entry-title {
            font-weight: 600;
            color: var(--text-dark);
            line-height: 1.4;
            transition: color 0.2s;
        }
        
        .detail-entry-title a {
            color: var(--teal);
            text-decoration: none;
        }
        
        .detail-entry-title a:hover {
            text-decoration: underline;
        }
        
        .detail-entry-date {
            font-size: 0.75rem;
            color: var(--text-muted);
            margin-top: 3px;
        }
        
        .detail-entry-expand {
            width: 16px;
            height: 16px;
            color: var(--text-muted);
            transition: transform 0.2s;
            flex-shrink: 0;
            margin-top: 2px;
        }
        
        .detail-entry-item.expanded .detail-entry-expand {
            transform: rotate(180deg);
        }
        
        .detail-entry-description {
            display: none;
            margin-top: 10px;
            padding: 12px;
            background: white;
            border-radius: 6px;
            font-size: 0.82rem;
            line-height: 1.5;
            color: var(--text-dark);
            border: 1px solid var(--cream-dark);
        }
        
        .detail-entry-item.expanded .detail-entry-description {
            display: block;
        }
        
        .detail-entry-description p {
            margin: 0 0 8px 0;
            padding-left: 12px;
            border-left: 2px solid var(--teal);
        }
        
        .detail-entry-description p:last-child {
            margin-bottom: 0;
        }
        
        .compare-tooltip {
            position: fixed;
            background: var(--navy);
            color: white;
            padding: 10px 14px;
            border-radius: 6px;
            font-size: 0.8rem;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.2s;
            z-index: 1000;
            max-width: 280px;
            line-height: 1.4;
        }
        
        .country-summary-box {
            background: linear-gradient(135deg, #e8ebef 0%, rgba(224, 228, 233, 0.5) 100%);
            border-left: 4px solid var(--teal);
            padding: 20px 24px;
            margin-bottom: 24px;
            border-radius: 0 8px 8px 0;
            font-size: 0.95rem;
            line-height: 1.6;
            color: var(--text-dark);
        }
        
        /* Option A: Side by Side Layout for Insights */
        .country-insights-row {
            display: grid;
            grid-template-columns: 1fr 1.3fr;
            gap: 32px;
            width: 100%;
            margin: 0 auto 24px;
            background: transparent;
            border-radius: 0;
            padding: 0;
            box-shadow: none;
        }
        
        @media (max-width: 800px) {
            .country-insights-row {
                grid-template-columns: 1fr;
            }
        }
        
        .chart-section {
            display: flex;
            flex-direction: column;
        }
        
        .pie-chart-container {
            display: flex;
            flex-direction: column;
        }
        
        .pie-chart-title, .bar-chart-title {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-weight: 600;
            font-size: 1rem;
            color: var(--navy);
            margin-bottom: 20px;
            text-align: center;
        }
        
        .pie-chart-wrapper, .bar-chart-wrapper {
            display: flex;
            justify-content: center;
            align-items: center;
            flex: 1;
            min-height: 350px;
        }
        
        .pie-chart-svg {
            width: 100%;
            max-width: 500px;
            height: auto;
            overflow: visible;
        }
        
        .bar-chart-svg {
            width: 100%;
            max-width: 520px;
            height: auto;
            overflow: visible;
        }
        
        /* Hover and click effects for pie and bar chart coordination */
        .pie-slice, .bar-rect {
            transition: opacity 0.2s, filter 0.2s;
            cursor: pointer;
        }
        
        .country-insights-row.has-hover .pie-slice:not(.highlighted),
        .country-insights-row.has-hover .bar-rect:not(.highlighted),
        .country-insights-row.has-hover .bar-label:not(.highlighted),
        .country-insights-row.has-hover .bar-value:not(.highlighted),
        .country-insights-row.has-hover .pie-label:not(.highlighted),
        .country-insights-row.has-hover .pie-leader-line:not(.highlighted),
        .country-insights-row.has-hover .pie-leader-dot:not(.highlighted) {
            opacity: 0.3;
        }
        
        .pie-slice.highlighted,
        .bar-rect.highlighted {
            filter: brightness(1.1) drop-shadow(0 0 6px rgba(0,0,0,0.3));
        }
        
        .bar-label, .bar-value, .pie-label, .pie-leader-line, .pie-leader-dot {
            transition: opacity 0.2s;
        }
        
        .pie-label, .pie-leader-line, .pie-leader-dot {
            pointer-events: none;
        }
        
        .insights-hint {
            grid-column: 1 / -1;
            background: #e8ebef;
            padding: 10px 14px;
            border-radius: 8px;
            font-size: 0.75rem;
            color: var(--text-muted);
            text-align: center;
        }
        
        .insights-hint strong {
            color: var(--navy);
        }
        
        .compare-tooltip.visible {
            opacity: 1;
        }


        @media (max-width: 768px) {
            .chart-row {
                grid-template-columns: 35px 1fr 140px 1fr 35px;
            }
            .chart-row-label {
                font-size: 0.7rem;
            }
            .detail-entries-grid {
                grid-template-columns: 1fr;
            }
            .compare-header-chips {
                flex-direction: column;
                align-items: center;
                gap: 12px;
            }
        }


        @media (max-width: 768px) {
            .comparison-grid {
                grid-template-columns: 1fr;
            }
        }


        .col-policy-area-title {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-size: 0.85rem;
            font-weight: 700;
            color: var(--navy);
            margin-bottom: 10px;
            padding: 8px 12px;
            background: white;
            border-radius: 6px;
            border-left: 3px solid var(--teal);
            box-shadow: 0 1px 3px rgba(0,0,0,0.04);
        }


        .col-policy-area:nth-child(2) .col-policy-area-title { border-left-color: var(--coral); }
        .col-policy-area:nth-child(3) .col-policy-area-title { border-left-color: var(--purple); }
        .col-policy-area:nth-child(4) .col-policy-area-title { border-left-color: var(--navy); }
        .col-policy-area:nth-child(5) .col-policy-area-title { border-left-color: var(--teal); }


        /* ===== SOURCE TYPE SECTIONS ===== */
        .source-section { margin-top: 10px; }
        .source-section:first-child { margin-top: 0; }


        .source-type-header {
            font-family: 'Montserrat', sans-serif;
            font-size: 0.6rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 1.2px;
            margin-bottom: 6px;
            padding: 3px 8px;
            border-radius: 3px;
            display: inline-flex;
            align-items: center;
            gap: 5px;
        }


        .source-type-header::before { content: ''; width: 5px; height: 5px; border-radius: 50%; }
        .source-type-header.legal { background: rgba(26, 39, 68, 0.08); color: var(--navy); }
        .source-type-header.legal::before { background: var(--navy); }
        .source-type-header.policy { background: rgba(13, 115, 119, 0.08); color: var(--teal); }
        .source-type-header.policy::before { background: var(--teal); }
        .source-type-header.statement { background: rgba(214, 64, 69, 0.08); color: var(--coral); }
        .source-type-header.statement::before { background: var(--coral); }


        .source-items { display: flex; flex-direction: column; gap: 5px; }


        .source-item {
            background: white;
            border-radius: 6px;
            overflow: hidden;
            border: 1px solid var(--cream-dark);
        }


        .source-item-header {
            padding: 10px 12px;
            cursor: pointer;
            display: flex;
            align-items: flex-start;
            justify-content: space-between;
            gap: 8px;
            transition: background 0.2s;
        }


        .source-item-header:hover { background: #e8ebef; }


        .source-item-title-row { display: flex; align-items: center; gap: 8px; flex: 1; position: relative; }


        .source-item-title {
            font-family: 'Plus Jakarta Sans', sans-serif;
            font-weight: 600;
            font-size: 0.8rem;
            flex: 1;
            color: var(--navy);
            line-height: 1.35;
        }


        .source-item-date {
            flex-shrink: 0;
            margin-left: auto;
            padding: 0;
            background: none;
            color: #7a8a9a;
            font-family: 'Montserrat', sans-serif;
            font-size: 0.7rem;
            font-weight: 500;
            white-space: nowrap;
            letter-spacing: 0.01em;
            align-self: center;
        }


        .source-link {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 28px;
            height: 28px;
            min-width: 28px;
            background: var(--teal);
            border-radius: 6px;
            color: white;
            text-decoration: none;
            flex-shrink: 0;
            transition: all 0.2s;
            position: relative;
            z-index: 100;
            cursor: pointer;
            pointer-events: auto !important;
            margin-left: 8px;
            border: none;
            outline: none;
            padding: 0;
            font-family: inherit;
        }


        .source-link:hover { background: var(--navy); transform: translateY(-1px); }
        .source-link svg { width: 14px; height: 14px; pointer-events: none; }


        .source-item-expand {
            width: 14px;
            height: 14px;
            color: var(--text-muted);
            flex-shrink: 0;
            margin-top: 2px;
            transition: transform 0.3s;
        }


        .source-item.expanded .source-item-expand { transform: rotate(180deg); }


        .source-item-details {
            display: none;
            padding: 0 14px 14px;
            font-size: 0.85rem;
            color: #5a6a7a;
            line-height: 1.7;
            border-top: 1px solid #dde1e6;
        }


        .source-item.expanded .source-item-details { display: block; padding-top: 12px; }
        .source-item-details p { margin-bottom: 8px; }
        .source-item-details p:last-child { margin-bottom: 0; }


        .no-data-message {
            text-align: center;
            padding: 40px 20px;
            color: var(--text-muted);
            font-size: 0.9rem;
        }


        .loading {
            display: flex;
            align-items: center;
            justify-content: center;
            height: 550px;
            color: rgba(255,255,255,0.6);
        }


        .loading-spinner {
            width: 32px;
            height: 32px;
            border: 3px solid rgba(255,255,255,0.2);
            border-top-color: var(--coral);
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-right: 14px;
        }


        @keyframes spin { to { transform: rotate(360deg); } }


        footer {
            text-align: left;
            margin-top: 0;
            padding: 32px 50px;
            background: var(--navy);
            border-top: 3px solid var(--coral);
            color: #a8b5c7;
            font-size: 0.85rem;
            display: flex;
            flex-direction: row;
            align-items: flex-start;
            justify-content: space-between;
            gap: 40px;
            flex-wrap: wrap;
        }


        footer p:first-child {
            flex: 1;
            max-width: 600px;
            line-height: 1.6;
        }
        
        footer .data-disclaimer {
            font-size: 0.8rem;
            color: #a8b5c7;
            font-style: italic;
            white-space: nowrap;
        }


        .view-content { display: none; }
        .view-content.active { display: block; }


        @media (max-width: 900px) {
            .container { padding: 40px 30px; }
            .section-header { flex-direction: column; align-items: flex-start; }
            .policy-area-dropdown { width: 100%; }
            header { margin-bottom: 40px; padding-bottom: 30px; }
        }


        @media (max-width: 600px) {
            .container { padding: 30px 20px; }
            .section-header { padding: 24px; }
            .section-content { padding: 24px; }
            .country-dropdown { width: 100%; max-width: 100%; font-size: 0.9rem; }
            .selected-countries { gap: 6px; }
            .selected-tag { font-size: 0.8rem; padding: 5px 10px; }
            h1 { font-size: 1.8rem; }
            .view-tabs { width: 100%; }
            .view-tab { flex: 1; text-align: center; padding: 12px 16px; }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <div class="header-content">
                <p class="overline">Research Data Visualization</p>
                <h1>Global Defense AI Policy Landscape</h1>
                <p class="subtitle">Mapping military and defense AI governance frameworks across select states</p>
                <div class="line-decoration">
                    <span class="dot"></span>
                    <span class="line"></span>
                    <span class="dot"></span>
                </div>
            </div>
            <div class="header-logo">
                <img src="./ari-logo.svg" alt="Americans for Responsible Innovation">
            </div>
        </header>


        <div class="main-content">
        <div class="map-container">
            <div class="map-controls">
                <button class="map-control-btn" id="zoom-in" title="Zoom in">+</button>
                <button class="map-control-btn" id="zoom-out" title="Zoom out">âˆ’</button>
                <button class="map-control-btn" id="zoom-reset" title="Reset view">âŸ²</button>
            </div>
            <div class="map-hint">Scroll to zoom â€¢ Drag to pan</div>
            <div id="map-loading" class="loading">
                <div class="loading-spinner"></div>
                <span>Loading map...</span>
            </div>
            <svg id="map-svg" style="display: none;"></svg>
        </div>


        <div class="view-tabs">
            <button class="view-tab active" data-view="overview">Country Overview</button>
            <button class="view-tab" data-view="alliance">Alliance Overview</button>
            <button class="view-tab" data-view="compare">Compare Countries</button>
        </div>


        <!-- OVERVIEW VIEW -->
        <div id="view-overview" class="view-content view-overview active">
            <div class="country-selector">
                <p class="country-selector-label">Select a country</p>
                <div class="country-selector-controls">
                    <select class="country-dropdown" id="overview-dropdown">
                        <option value="">-- Choose a country --</option>
                    </select>
                    <div class="country-search-wrapper">
                        <input type="text" class="country-search" id="country-search" placeholder="Search countries...">
                        <div class="search-results-dropdown" id="search-results-dropdown"></div>
                        <div class="search-message" id="search-message"></div>
                    </div>
                </div>
            </div>


            <section class="main-section">
                <div class="section-header" id="overview-header" style="display: none;">
                    <div class="section-title-area">
                        <h2 class="section-title" id="overview-country-name"></h2>
                        <span class="section-subtitle" id="overview-subtitle"></span>
                    </div>
                    <div class="filters">
                        <span class="filter-label">Source Types:</span>
                        <div class="filter-group">
                            <label class="filter-checkbox legal">
                                <input type="checkbox" id="filter-legal" checked>
                                <span>Legal</span>
                            </label>
                            <label class="filter-checkbox policy">
                                <input type="checkbox" id="filter-policy" checked>
                                <span>Policy</span>
                            </label>
                            
                            <label class="filter-checkbox statement">
                                <input type="checkbox" id="filter-statement" checked>
                                <span>Statement</span>
                            </label>
                        </div>
                    </div>
                </div>
                <div class="section-content" id="overview-content">
                    <div class="placeholder">
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M9 20l-5.447-2.724A1 1 0 013 16.382V5.618a1 1 0 011.447-.894L9 7m0 13l6-3m-6 3V7m6 10l4.553 2.276A1 1 0 0021 18.382V7.618a1 1 0 00-.553-.894L15 4m0 13V4m0 0L9 7" />
                        </svg>
                        <p>Select a country to explore its<br>defense AI policy framework</p>
                    </div>
                </div>
            </section>
        </div>


        <!-- ALLIANCE VIEW -->
        <div id="view-alliance" class="view-content view-alliance">
            <div class="country-selector">
                <p class="country-selector-label">Select an alliance</p>
                <select class="country-dropdown" id="alliance-dropdown">
                    <option value="">-- Choose an alliance --</option>
                    <option value="NATO">NATO</option>
                    <option value="AUKUS">AUKUS</option>
                    <option value="FVEY">Five Eyes (FVEY)</option>
                </select>
            </div>


            <section class="main-section">
                <div class="section-header" id="alliance-header" style="display: none;">
                    <div class="section-title-area">
                        <h2 class="section-title" id="alliance-name"></h2>
                        <span class="section-subtitle" id="alliance-subtitle"></span>
                    </div>
                    <div class="filters">
                        <span class="filter-label">Source Types:</span>
                        <div class="filter-group">
                            <label class="filter-checkbox legal">
                                <input type="checkbox" id="alliance-filter-legal" checked>
                                <span>Legal</span>
                            </label>
                            <label class="filter-checkbox policy">
                                <input type="checkbox" id="alliance-filter-policy" checked>
                                <span>Policy</span>
                            </label>
                            <label class="filter-checkbox statement">
                                <input type="checkbox" id="alliance-filter-statement" checked>
                                <span>Statement</span>
                            </label>
                        </div>
                    </div>
                </div>
                <div class="alliance-members-list" id="alliance-members-list" style="display: none;"></div>
                <div class="section-content" id="alliance-content">
                    <div class="placeholder">
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 4.354a4 4 0 110 5.292M15 21H3v-1a6 6 0 0112 0v1zm0 0h6v-1a6 6 0 00-9-5.197M13 7a4 4 0 11-8 0 4 4 0 018 0z" />
                        </svg>
                        <p>Select an alliance to explore its<br>defense AI policy framework</p>
                    </div>
                </div>
            </section>
        </div>


        <!-- COMPARE VIEW -->
        <div id="view-compare" class="view-content">
            <div class="country-selector">
                <p class="country-selector-label">
                    Select countries to compare
                    <span class="selection-limit" id="selection-limit"></span>
                </p>
                <div class="country-selector-controls">
                    <select class="country-dropdown" id="compare-dropdown">
                        <option value="">-- Add a country --</option>
                    </select>
                    <div class="country-search-wrapper">
                        <input type="text" class="country-search" id="compare-search" placeholder="Search countries...">
                        <div class="search-results-dropdown" id="compare-search-results"></div>
                        <div class="search-message" id="compare-search-message"></div>
                    </div>
                </div>
                <div class="selected-countries" id="selected-countries"></div>
            </div>


            <section class="main-section">
                <div class="section-header" style="display:none;">
                    <h2 class="section-title">Policy Comparison</h2>
                </div>
                <div class="section-content" id="compare-content">
                    <div class="placeholder">
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M9 20l-5.447-2.724A1 1 0 013 16.382V5.618a1 1 0 011.447-.894L9 7m0 13l6-3m-6 3V7m6 10l4.553 2.276A1 1 0 0021 18.382V7.618a1 1 0 00-.553-.894L15 4m0 13V4m0 0L9 7" />
                        </svg>
                        <p>Select 2 countries to compare their<br>defense AI policy frameworks</p>
                    </div>
                </div>
            </section>
        </div>


        </div>
        <footer>
            <p>Data compiled from official government documents, national document submissions, public statements, press releases, and secondary sources where primary information is not publicly available</p>
            <p class="data-disclaimer">Data current as of November 2025</p>
        </footer>
    </div>


    <div class="tooltip" id="tooltip">
        <div class="tooltip-title"></div>
        <div class="tooltip-subtitle"></div>
    </div>


    <script id="policy-data" type="application/json">
{
  "countries": {
    "USA": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [
          {
            "text": "DoD Directive 3000.09 \"Autonomy in Weapons Systems\" (Jan 2023)\n\n- This directive establishes policy and assigns responsibilities for developing and using autonomous and semi-autonomous functions in weapons systems. It also establishes guidelines designed to minimize the probability of failures in such weapons systems that could lead to unintended consequences.\n\n- The following are required: rigorous hardware and software verification and validation (V&V) and realistic system developmental and operational testing and evaluation (T&E), including analysis of unanticipated emergent behavior in complex operational environments.",
            "url": "https://www.esd.whs.mil/portals/54/documents/dd/issuances/dodd/300009p.pdf"
          },
          {
            "text": "H.R.5009 - Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025 (Dec 2024)\n\n- Section 1066 \u2013 requires the Secretary of Defense to submit annual comprehensive reports to congressional defense committees on the approval and deployment of lethal autonomous weapon systems by the United States through December 31, 2029.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/5009/text"
          }
        ],
        "policy_documents": [
          {
            "text": "US Submission to the Group of Governmental Experts (GGE) at the Convention on Prohibitions or Restrictions on the Use of Certain Conventional Weapons (Nov 2017)\n\n- The US states that it complies with the law of war and a rigorous testing and evaluation (T&E), and verification and validation (V&V) for autonomous and semi-autonomous weapons.\n\n- Autonomy in weapons systems can improve the implementation of the law of war in military operations, and legal accountability and legal reviews of the development and use of autonomous weapons.",
            "url": "https://ogc.osd.mil/Portals/99/Law%20of%20War/Practice%20Documents/US%20Working%20Paper%20-%20Autonomy%20in%20Weapon%20Systems%20-%20CCW_GGE.1_2017_WP.6_E.pdf?ver=Vh75581oFwDjfaDK0EE8MQ%3D%3D"
          },
          {
            "text": "US Paper to the CCW on the Humanitarian Benefits of Emerging Technologies in the Area of Lethal Autonomous Weapon Systems (Apr 2018)\n\n- The US acknowledges the potential benefits of autonomous lethal weapons and encourages the innovation of such technologies that further the \"objectives and purposes of the Convention,\" opposing a ban on Lethal Autonomous Weapons Systems (LAWS).",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-_Group_of_Governmental_Experts_%282018%29/CCW_GGE.1_2018_WP.4.pdf"
          },
          {
            "text": "US National Statement at the Vienna Conference \"Humanity at the Crossroads: Lethal Autonomous Weapon Systems\" (Apr 2024)\n\n- This statement emphasizes the GGE's work on the issues surounding LAWS, but states that the US is not in a position to align itself with the view that new measures to regulate LAWS are necessary.\n\n- The US reaffirms that all use of AI in armed conflict must be in accordance with states' obligations under International Humanitarian Law (IHL).",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/United_States_National_Statement.pdf"
          },
          {
            "text": "US Submission to the UN Secretary General Pursuant to Resolution 78/241 on Lethal Autonomous Weapon Systems (May 2024)\n\n- The United States views the UN GGE to be the best forum to advance international effors on LAWS.\n\n- IHL already provides the applicable framework of prohibitions and regulations on the use of LAWS in armed conflict.\n\n- The US states that it does not currently support a legally binding instrument on LAWS.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-US-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "US Statement at the Second Session in 2023 of the CCW GGE on LAWS (May 2023)\n\n- The US holds and reaffirms that IHL already governs LAWS and that autonomy in weapon systems is not unlawful. The US urges a reconsideration of the creation of a new legally binding prohibition or regulatory framework on LAWS.",
            "url": "https://geneva.usmission.gov/2023/05/15/second-session-in-2023-of-the-gge-on-emerging-technologies-in-the-area-of-laws/?utm_source=chatgpt.com"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- The US voted in support of this Resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- The US voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Dec 2018)\n\n- Section 238 \u2013 Joint Artificial Intelligence Research, Development, and Transition Activities; directs the DoD to establish activities for joint AI R&D . This requires a strategic plan, identification of priority AI missions, coordination with components, and a statutory definition for artificial intelligence.",
            "url": "https://www.congress.gov/115/plaws/publ232/PLAW-115publ232.pdf"
          },
          {
            "text": "National Defense Authorization Act for Fiscal Year 2020 (Dec 2019)\n\n-Section 256 \u2013 Artificial Intelligence Strategy; directs the DoD to develop an AI education strategy for military and civilian personnel, to include identifying required AI competencies, education programs, andopportunities for training.\n\n- Section 260 \u2013 Biannual Reporting on the Joint Artificial Intelligence Center; requires the Secretary of Defense to submit a biannual report to Congress on JAIC activities, progress, resources, and integration into operations.",
            "url": "https://www.congress.gov/116/plaws/publ92/PLAW-116publ92.pdf"
          },
          {
            "text": "James M. Inhofe National Defense Authorization Act for Fiscal Year 2023 (Dec 2022)\n\n- Section 1513: Establishing Projects for Data Management, AI, and Digital Solutions; establishes projects and builds infrastructure that leverage data, AI, and digital tools to support operations. It also mandates that the CDAO work with the Under Secretary of Defense to implement, track, and modify data and AI practices in accordance with the outlined policy.",
            "url": "https://www.congress.gov/bill/117th-congress/house-bill/7776/text"
          },
          {
            "text": "National Defense Authorization Act for Fiscal Year 2024 (Dec 2023)\n\n- Section 346 \u2013 authorizes a pilot program to optimize aerial refueling and fuel management in contested environments through use of AI.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/2670/text"
          },
          {
            "text": "NSM-25 Advancing the United States\u2019 Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence (Oct 2024)\n\n- Within 270 days of the release of this document and yearly for the next 5 years, all departments, including the DoD, are mandated to provide a report of to the President that offers a detailed accounting of activities in response to the taskings in the memorandum.\n\n- The DoD is instructed to, when building computational infrastructure, design facilities capable of \"harnessing frontier AI for relevant scientific research domains and intelligence analysis\".",
            "url": "https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/"
          },
          {
            "text": "DoD Directive 5105.89 \"Chief Digital and Artificial Intelligence Officer (CDAO) (Nov 2024)\n\n- The CDAO is established as the senior DoD official for the adoption and integration of data, analytics, and AI capabilities.\n\n- CDAO is also given policy oversight over the modernization process with authority over relevant acquisition activities.\n\n- The directive  pesents the CDAO's responsibilities and functions, as well as its relationship to other relevant authorities and actors such as DoD Component heads and principal staff assistants.",
            "url": "https://www.esd.whs.mil/Portals/54/Documents/DD/issuances/dodd/510589p.PDF?ver=Ikhn-60VR-GpxO78wiYQZA%3D%3D"
          },
          {
            "text": "H.R.5009 - Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025 (Dec 2024)\n\n- Section 221 \u2013 requires the appointment of a Chief Digital Engineering Recruitment and Management Officer to identify and clarify roles and responsibilities of the DoD AI workforce, including creating qualification programs for the force.\n\n- Section 222 \u2013 develops educational courses on responsible and ethical AI development and use.\n\n- Section 236 \u2013 establishes a five-year pilot program for developing AI for national security biotechnology applications through public-private partnerships.\n\n- Section 225 \u2013 expands CDAO Governing Council duties to identify AI models that could pose national security risks if accessed by adversaries, develop strategies to prevent unauthorized access, and make recommendations to Congress for legislative action.\n\n- Section 1534 \u2013 directs the evaluation of establishing centers of excellence to support the development and maturation of AI-enabled weapons systems with collaboration between DoD and foreign partners.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/5009/text"
          }
        ],
        "policy_documents": [
          {
            "text": "DoD Responsible Artificial Intelligence Strategy & Implementation Pathway (Jun 2022)\n\n- This document operationalizes the DoD AI Ethical Principles and guides the implementation of Responsible AI (RAI) into the Department's existing framework.\n\n- Tenet 6: AI Workforce; aims to achieve a standard level of technological familiarity and proficiency for system operators to achieve justified confidence in AI capabilities and AI-enabled systems. It also ensure that all DoD AI Workforce members possess an appropriate understanding of the technology development process and the operational methods applicable to implementing RAI commensurate with their duties.",
            "url": "https://media.defense.gov/2024/Oct/26/2003571790/-1/-1/0/2024-06-RAI-STRATEGY-IMPLEMENTATION-PATHWAY.PDF"
          },
          {
            "text": "DoD 2023 Data, Analytics, and AI Adoption Strategy (Jun 2023)\n\n- The Strategy requires compliance with the DoD AI Ethical Principles and presents Key Outcomes, Strategic Goals, and an Implementation Pathway.\n\n- The DoD is mandated to identify and employ talent both within and ouside the defense workforce in addition to training nontechnical personnel to lead and oversee the developmental pathway for AI in the Department.\n\n- A decentralized data ownership system that is managed using the VAULTIS framework (Visible, Accessible, Understandable, Linked, Trustworthy, Interoperable, Secure) is required.\n\n- Included in this strategy are plans to reduce institutional barriers that inhibit collective R&D, planning, interoperability, intelligence, and information sharing . This is expected to be achieved by using iterative feedback and \"campaigns of learning\" to improve capability.",
            "url": "https://media.defense.gov/2023/Nov/02/2003333300/-1/-1/1/DOD_DATA_ANALYTICS_AI_ADOPTION_STRATEGY.PDF"
          }
        ],
        "public_statements": [
          {
            "text": "Deputy Secretary of Defense Remarks \"Unpacking the Replicator Initiative\" (Sep 2023)\n\n- Deputy Secretary Kathleen Hicks states that the Replicator Inititative will be a strategic development of \"all-domain, attritable autonomy (ADA2)\" to counter the People's Republic of China's (PRC) advantage of more ships, missiles, and forces.\n\n- Hicks states that the DoD has invested in self-piloting ships, uncrewed aircraft across the services, DIU, and the combatant commands.\n\n- The goal is \"to field attritable autonomous systems at a scale of multiple thousands, in multuple domains, within the next 18-to-24 months\".\n\n- The US policy for autonomy in weapons remains that \"there is always a human responsible for the use of force\".",
            "url": "https://www.war.gov/News/Speeches/Speech/Article/3517213/deputy-secretary-of-defense-kathleen-hicks-remarks-unpacking-the-replicator-ini/"
          },
          {
            "text": "Remarks by Vice President Harris on the Future of Artificial Intelligence (Nov 2023)\n\n- Vice President Kamala Harris reiterates the principles for responsible development, deployment, and use of military AI and autonomous capabilities, and states that these principles include a \"rigorous legal review process for AI decision-making.\" This statement commits that US AI systems will always operate under IHL.",
            "url": "https://bidenwhitehouse.archives.gov/briefing-room/speeches-remarks/2023/11/01/remarks-by-vice-president-harris-on-the-future-of-artificial-intelligence-london-united-kingdom/?utm_source=chatgpt.com"
          },
          {
            "text": "Deputy Secretary of Defense on \"The State of AI in the Department of Defense\" (Nov 2023)\n\n- Deputy Secretary Kathleen Hicks announces current progress on foundational efforts made in the data and AI fields.\n\n- US policy for autonomy in weapon systems remains unchanged in that a human will always be responsible for the use of force.\n\n- Hicks states that the DoD does not use \"AI to censor, constrain, repress, or disempower people,\" and that AI and its capabilities will be used only to deter aggression and defend the homeland, allies and partners, and interests.",
            "url": "https://www.war.gov/News/Speeches/Speech/Article/3578046/remarks-by-deputy-secretary-of-defense-kathleen-h-hicks-on-the-state-of-ai-in-t/"
          },
          {
            "text": "Deputy Secretary of Defense  Announcement of Additional Replicator ADA2 Capabilities (Nov 2024)\n\n- Deputy Secretary Kathleen Hicks announces air and maritime domain systems will be selected for accelerated fielding as part of the Replicator 1.2 initiative.\n\n- The Department plans to invest in unmanned aircraft systems and loitering munitions, as well as classified systems involving \"low-cost long-range strike capabilities and maritime uncrewed systems\".\n\n- Hicks states that autonomy efforts strive to act as \"integrated enablers\" capable of autonomously coordinating vast numbers of unmanned assets.",
            "url": "https://www.war.gov/News/Releases/Release/article/3963289/deputy-secretary-of-defense-kathleen-hicks-announces-additional-replicator-all/"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- The US voted in support of this Resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "DoW Under Secretary of War for Reseach and Engineering on AI Implementation (Sep 2025)\n\n- Under Secretary of Defense Emil Michael states that \"we want to have an AI capability on every desktop - 3 million desktops - in six to nine months\" to focus on applications for corporate use cases like efficiency in addition to intelligence and warfighting needs.",
            "url": "https://www.nextgov.com/artificial-intelligence/2025/09/pentagon-research-official-wants-have-ai-every-desktop-6-9-months/408152/"
          },
          {
            "text": "DoW Under Secretary of War for Research and Engineering Announcement of Six Critical Technology Areas (Nov 2025)\n\n- Under Secretary Emil Michael announces that Applied Artificial Intelligence is one of the six critical technology areas that the War Department will focus on to define the future of US military superiority.",
            "url": "https://www.war.gov/News/Releases/Release/Article/4333074/under-secretary-of-war-for-research-and-engineering-emil-michael-announces-six/"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [
          {
            "text": "National Defense Authorization Act for Fiscal Year 2022 (Dec 2021)\n\n- Section 227 \u2013 Modification of the Joint Common Program; mandates that the DoD modify the Joint Common Foundation program to ensure that the department's components can more easily contract with leading commercial AI companies.\n\n- Section 232 \u2013 Pilot Program on Data Repositoriesto Facilitate the Development of AI Capabilities for the DoD; authorizes the DoD to create data repositories to support AI/ML development and includes requirements for categorization, annotation, and use in a common evaluation framework for AI models.",
            "url": "https://www.congress.gov/bill/117th-congress/senate-bill/1605"
          },
          {
            "text": "H.R.5009 - Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025 (Dec 2024)\n\n- Section 125 \u2013 requires the Secretary of the Navy to designate an official responsible for developing and acquiring advanced autonomous vehicles with a dedicated program element in Navy budgets.\n\n- Section 235 \u2013 requires the CDAO to develop venue and testing processes for comparing automated target recognition algorithms by June 1, 2025.\n\n- Section 1620 \u2013 develops a plan to streamline the budgeting process for necessary data acquisition with annual evaluations and reporting to Armed Services Committees.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/5009/text"
          }
        ],
        "policy_documents": [
          {
            "text": "US DoD 2023 Data, Analytics, and AI Adoption Strategy (Jun 2023)\n\n- The strategy requires DoD Components to follow an \"adopt-buy-create\" approach to acquiring R&D capabilities, prioritize joint or DoD-sponsored solutions, then source commercial assets where viable.\n\n- Tenet 3: AI Product and Acquisition Life Cycle; develops RAI-related acquisition resources and tools, such as standardized langauge, best practices, and processes to align AI development with the National Defense Strategy.",
            "url": "https://media.defense.gov/2023/Nov/02/2003333300/-1/-1/1/DOD_DATA_ANALYTICS_AI_ADOPTION_STRATEGY.PDF"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [
          {
            "text": "DoD Memorandum on Implementing Responsible Artificial Intelligence in the Department of Defense (May 2021)\n\n- This memorandum issued by Deputy Secretary of Defense Kathleen Hicks outlines the DoD's adoption of the DoD AI Ethical Principles in accordance with the tenets that describe responsible AI (RAI): RAI Governance, Warfighter Trust, AI Product and Acquisition Lifeycle, Requirements Validation, Responsible AI Ecosystem, and AI Workforce.",
            "url": "https://www.war.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/"
          },
          {
            "text": "National Security Memorandum 25 (NSM-25) (Oct 2024)\n\n- The DoD (among other departments) is mandated to prioritize research on AI safety and trustworthiness and to improve the security, robustness, and reliability of AI systems and controls.",
            "url": "https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/"
          }
        ],
        "policy_documents": [
          {
            "text": "DoD Ethical Principles for Artificial Intelligence (Feb 2020)\n\n- The principles build on the US military's existing ethics framework with a specific focus on artificial intelligence, mandating its development and deployment to be Responsible, Equitable, Traceable, Reliable, and Governable. These principles apply to both combat and non-combat applications across the DoD.",
            "url": "https://www.war.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/"
          },
          {
            "text": "DoD Responsible Artificial Intelligence Strategy & Implementation Pathway (Jun 2022)\n\n- The document creates a comprehensive framework for ensuring AI systems are developed and deployed ethically through clear accountability and oversight mechanisms, outlining the Office of Professional Responsibility (OPR) for each Line of Effort.",
            "url": "https://media.defense.gov/2024/Oct/26/2003571790/-1/-1/0/2024-06-RAI-STRATEGY-IMPLEMENTATION-PATHWAY.PDF"
          }
        ],
        "public_statements": [
          {
            "text": "Secretary of Defense Speech on AI Development (Jul 2021)\n\n- Secretary of Defense Lloyd Austin III commits the DoD to developing AI responsibly and without sacrificing safety, security, and ethics while addressing the \"pacing challenge\" of China's AI development.",
            "url": "https://www.war.gov/News/News-Stories/Article/Article/2692297/ethics-key-to-ai-development-austin-says/"
          },
          {
            "text": "Keynote Remarks by Ambassador Jenkins to the Summit on Responsible Artificial Intelligence in the Military Domain (Responsible AI in the Military Domain (REAIM)) Ministerial Segment (Feb 2023)\n\n- US Ambassador Bonnie Jenkins provides remarks at the 2023 REAIM Summit affirming the US approach to safely and securely harnessing AI capabilities and following all IHL provisions.\n\n- Ambassador Jenkins also announces the Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy, urging states to join in implementing international norms.",
            "url": "https://2021-2025.state.gov/keynote-remarks-by-u-s-jenkins-t-to-the-summit-on-responsible-artificial-intelligence-in-the-military-domain-reaim-ministerial-segment/"
          },
          {
            "text": "The United States' Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- The US supports the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://asianews.network/seoul-summit-charts-framework-on-responsible-ai-military-use/"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [
          {
            "text": "H.R.5009 - Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025 (Dec 2024)\n\n- Section 1087 \u2013 establishes a DoD working group for multilateral AI coordination to accelerate interoperability of systems used for intelligence sharing and battlespace awareness with several allies and partners.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/5009/text"
          }
        ],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US-Singapore Statement of Interest Regarding Data, Analytics, and AI Cooperation (Jul 2024)\n\n- The Statement of Interest adopts a \"holistic approach\" to enable defense cooperation regarding best practices and future cooperation between the two countries.",
            "url": "https://www.war.gov/News/Releases/Release/Article/3839100/united-states-and-singapore-sign-soi-to-strengthen-data-analytics-and-artificia/"
          },
          {
            "text": "US DoD Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\n- The United States spearheaded the effort and signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [
          {
            "text": "DoD Directive 3000.09 \"Autonomy in Weapons Systems\" (Jan 2023)\n\n- Section 3: Verification amd Validation and Testing and Evaluation of Autonomous and Semi-Autonomous Weapons Systems; outlines the safety requirements that all autonomous and semi-autonomous weapon systems must adhere to and follow.\n\n- The Under Secretary of Defense for Research and Engineering oversees establishment of standards for developmental testing, safety certification, and reliability assessment with particular attention to the risk of unintended engagements.\n\n- Systems must have clear procedures to activate and deactivate functions, provide transparent feedback on system status, and be designed to complete engagements within defined timeframes and geographic areas consistent with commander intentions.",
            "url": "https://www.esd.whs.mil/portals/54/documents/dd/issuances/dodd/300009p.pdf"
          },
          {
            "text": "NSM-25 Advancing the United States\u2019 Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence (Oct 2024)\n\n- The AI Safety Institute (AISI) must issue guidance for AI developers, including the DoD, on testing, evaluating, and managing risks of dual-use foundation models, addressing how to measure capabilities relevant to biological and chemical weapons or automated offensive cyber operations and develop mitigation measures.\n\n- The Framework prohibits using AI to \"remove a human in the loop for actions critical to informing and executing decisions by the President to initiate or terminate nuclear weapons employment.\".",
            "url": "https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/?utm_source=chatgpt.com"
          },
          {
            "text": "H.R.5009 - Servicemember Quality of Life Improvement and National Defense Authorization Act for Fiscal Year 2025 (Dec 2024)\n\n- Section 1638 \u2013 establishes a Statement of Policy regarding use of AI in nuclear weaponry systems requiring positive human action in executing decisions by the president to use such weapons.",
            "url": "https://www.congress.gov/bill/118th-congress/house-bill/5009/text"
          }
        ],
        "policy_documents": [
          {
            "text": "DoD Ethical Principles for Artificial Intelligence (Feb 2020)\n\n- The Reliable Principle requires that DoD AI capabilities have explicit, well-defined uses with safety, security and effectiveness subject to testing and assurance within those defined uses across their entire life cycle.\n\n- The framework states that the \"Department will design and engineer AI capabilities to fulfill their intended functions while possessing the ability to detect and avoid unintended consequences, and the ability to disengage or deactivate deployed systems that demonstrate unintended behavior\".",
            "url": "https://www.war.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/"
          },
          {
            "text": "DoD Responsible Artificial Intelligence Strategy & Implementation Pathway (Jun 2022)\n\n- Tenet 4: Requirements Validation; ensures that capabilties that use or leverage AI incorporate RAI and are aligned with operational needs while addressing AI risks.",
            "url": "https://media.defense.gov/2024/Oct/26/2003571790/-1/-1/0/2024-06-RAI-STRATEGY-IMPLEMENTATION-PATHWAY.PDF"
          }
        ],
        "public_statements": []
      }
    },
    "China": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Working Paper of the PRC on Lethal Autonomous Weapons Systems (LAWS) to the UN Group of Governmental Experts (GGE) (Jul 2022)\n\n- The paper defines unacceptable conditions of LAWS, to include: lethality of payload, complete autonomy, impossibility of termination, indiscriminate killing, and self-evolution. It also outlines the acceptability of LAWS which comply with IHL and human control, for which China calls regulation and risk-mitigation.",
            "url": "https://documents.unoda.org/wp-content/uploads/2022/07/Working-Paper-of-the-Peoples-Republic-of-China-on-Lethal-Autonomous-Weapons-Systems%EF%BC%88English%EF%BC%89.pdf"
          },
          {
            "text": "Document Submitted by China to the UN Secretary-General on the Issue of \"Lethal Autonomous Weapons Systems\" (May 2024)\n\n- China views the Convention on Certain Conventional Weapons (CCW) as a suitable platform for discussing LAWS. It states that defining the characteristics of LAWS is necessary to develop control measures, and a \"classification and grading\" approach should be used to address LAWS.",
            "url": "https://www.mfa.gov.cn/web/wjb_673085/zzjg_673183/jks_674633/fywj_674643/202405/t20240523_11310587.shtml"
          }
        ],
        "public_statements": [
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n- China abstained from voting on this resolution.\n- The resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Statement of the Chinese Delegation at the Thematic Discussion on Conventional Weapons at the First Committee of the 79th Sessions of the UNGA (Oct 2024)\n\n- This statement calls for the human control over AI-driven weapons and support for the continued discussion on the ethical, humanitarian, and legal considerations of lethal autonomous weapons.",
            "url": "https://www.mfa.gov.cn/eng/wjb/zzjg_663340/jks_665232/kjfywj_665252/202410/t20241025_11516326.html"
          },
          {
            "text": "China Executive Vice Minister for Foreign Affairs at the UNSC (Sep 2025)\n\n- Executive Vice Minister Ma states that it is \"essential to ensure that AI remains under human control and prevents the emergence of lethal autonomous weapons that operate without human intervention\" when highlighting the risks of military applications of AI.",
            "url": "https://www.aa.com.tr/en/asia-pacific/china-urges-global-solidarity-in-ai-governance-warns-about-lethal-autonomous-weapons/3698234"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "A New Generation Artificial Intelligence Development Plan (Jul 2017)\n\n- This plan sets out guiding ideology for China's AI development, to include civil-military fusion and intelligent national defense infrastructure.\n\n- By 2025: the goal is to achieve major breakthroughs in theory/technology and reach world-leading aspects of AI, including national defense construction.\n\n- By 2030: China aims to be the world leader in AI theory, technology, and application.\n\n- China advocates for an \"Open-Source and Open\" approach to AI innovation, with a coordinated development of national defense, and the two-way (dual-use) conversion and application of military and scientific resources.",
            "url": "https://www.newamerica.org/cybersecurity-initiative/digichina/blog/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/"
          },
          {
            "text": "China's National Defense in the New Era White Paper (Jul 2019)\n\n- This white paper states that China will advance \"intelligent warfare\" by integrating development, mechanization, and informatization.\n\n- By 2035, China's goal is to have completed the modernization of national defense and the military.",
            "url": "https://english.www.gov.cn/archive/whitepaper/201907/24/content_WS5d3941ddc6d08408f502283d.html"
          },
          {
            "text": "Document Submitted by China in Accordance With UNGA Resolution 79/239 on the Opportunities and Challenges of Military Applications of AI (Mar 2024)\n\n- This document reiterates China's stance on avoiding military superiority by using AI and preventing an AI arms race.\n\n- China maintains that relevant weapons should remain under human control and respect human dignity and human rights, while emphasizing that military applications of artificial intelligence must be guided in the \u201cright direction\u201d and constrained to prevent unchecked growth.",
            "url": "https://www.mfa.gov.cn/web/wjb_673085/zzjg_673183/jks_674633/fywj_674643/202504/t20250421_11598980.shtml"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "A New Generation Artificial Intelligence Development Plan (Jul 2017)\n\n- The plan explicitly calls for normalized mechanisms for communication and coordination between scientific research institutes, universities, enterprises, and military industry.",
            "url": "https://www.newamerica.org/cybersecurity-initiative/digichina/blog/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "CCW Conference Position Paper of the People's Republic of China on Regulating Military Application of Artificial Intelligence (AI) (Dec 2021)\n\n- The paper states that countries \"must bear in mind that military applications of AI shall never be used as a tool to start a war or pursue hegemony.\" It also states that new weapons and their methods of warfare must comply with IHL and other applicable international laws.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-SixthReview_Conference_(2021)/CCW-CONF.VI-WP.2.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "China's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- China did not sign or endorse the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          },
          {
            "text": "US DoS Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\n- China was a non-participant in this declaration.\n\n- Signatory states must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "CCW Conference Position Paper of the People's Republic of China on Regulating Military Application of Artificial Intelligence (AI) (Dec 2021)\n\n- The paper states that relevant AI weapon systems must be under human control and \"efforts must be made to ensure human suspension at any time,\" suggesting a human in the loop minimum.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-SixthReview_Conference_(2021)/CCW-CONF.VI-WP.2.pdf"
          },
          {
            "text": "Opportunities and Challenges Posed to International Peace and Security by the Application of AI in the Military Domain - Document submitted by China in accordance with General Assembly resolution 79/239 (Apr 2025)\n\n- China reiterates its commitment to a \"people-centered\" approach in military applications of AI and proposes the establishment of a testing and assessment system based on AI risk levels. It also plans to implement an agile governance response framework.\n\n- China holds that the human must be the \"final subject of responsibility\" in use-of-force decisions.",
            "url": "https://www.mfa.gov.cn/eng/wjb/zzjg_663340/jks_665232/kjfywj_665252/202504/t20250421_11598983.html"
          }
        ],
        "public_statements": [
          {
            "text": "Remarks by China's Permanent Representative to the UN Ambassador Fu Cong at the UNSC Briefing on Artificial Intelligence (Jan 2024)\n\n- China advocates for human control in military applications of AI to \"oppose the misuse, abuse, and proliferation of such systems.\" China also calls for a \"prudent and responsible\" attitude in developing AI technology in the military field, and stresses the need to maintain human control over the decision to use nuclear weapons.",
            "url": "https://www.fmprc.gov.cn/mfa_eng/xw/zwbd/202412/t20241225_11517873.html?ref=blog.denic.de&utm_source=chatgpt.com"
          },
          {
            "text": "Biden-Xi Statement on Human Control over Nuclear Arms (Nov 2024)\n\n- News reports state that Presidents Biden and Xi affirmed the need to maintain human control over the decision to use nuclear weapons and not delegate the responsibility to artificial intelligence.",
            "url": "https://www.reuters.com/world/biden-xi-agreed-that-humans-not-ai-should-control-nuclear-weapons-white-house-2024-11-16/"
          }
        ]
      }
    },
    "France": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Artificial Intelligence in Support of Defence (Sep 2019)\n\n- Section 2: Armed Forces Ministry Roadmap; states that \"France has no plans to develop fully autonomous systems where human operators have no control over the definition and performance of their missions.\" Furthermore, the development of AI for military use will systematically retain commander's responsibility for the use of such weapons.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          },
          {
            "text": "France Submission Pursuant to UNGA Resolution A/RES/78/241 on Lethal Autonomous Weapons Systems (May 2024)\n\n- France supports the two-tier approach to regulating Lethal Autonomous Weapons Systems (LAWS). France calls for the prohibition of LAWS that cannot be developed and used in accordance with IHL and the regulation of other types of autonomous weapons by implementing appropriate measures throughout the lifecycle of the system to mitigate legal, ethical, and security challenges.\n\n- The document reaffirms the necessity of the human to retain command and control over decisions to use lethal force.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-France-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Armed Forces Minister Statement on \"Killer Robots\" (Apr 2019)\n\n- Former Minister Florence Parly states that France will not delegate life-and-death decisions to any fully autonomous machine or system. She emphasizes that France will develop military AI only in accordance with international law, with sufficient human control and permanent command responsibility.",
            "url": "https://cd-geneve.delegfrance.org/La-France-ne-developpera-pas-de-robots-tueurs-Discours-de-la-Ministre-des?utm_source=chatgpt.com"
          },
          {
            "text": "Defense Ethics Committee Opinion on the Integration of Autonomy Into Lethal Autonomous Weapon Systems (Apr 2021)\n\n- The Committee distinguishes between Lethal Autonomous Weapon Systems (LAWS) and Partially Autonomous Lethal Weapon Systems (PALWS) and confirms France's decision to never develop or use fully autonomous systems.",
            "url": "https://www.defense.gouv.fr/sites/default/files/ministere-armees/20210429_Comite_Ethique_Defense_avis_autonomie_EN.pdf"
          },
          {
            "text": "General Statement by France to the UN Group of Governmental Experts (GGE) on LAWS (Jul 2022)\n\n- France states that the two-tier approach is most appropriate to regulating LAWS, stressing IHL compliance, human control, and promoting the CCW as an appropriate forum for additional discussion on this topic.",
            "url": "https://cd-geneve.delegfrance.org/General-statement-of-France-to-the-Group-of-Governmental-Experts-GGE-on-lethal"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- France voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UNGA Draft Resolution L.77 (Oct 2024)\n\n- France voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- France led and endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "Military Programming Law (MPL) 2024-2030 (Aug 2023)\n\n- This law sets milestones for the desired number of personnel working under the Ministerial Agency for Defence Artificial Intelligence (AMIAD), with a goal of a 700 personnel growth from 2024-2026.",
            "url": "https://www.defense.gouv.fr/sites/default/files/cde_1/Livret%20de%20pr%C3%A9sentation%20de%20la%20Loi%20de%20programmation%20militaire%202024-2030%20%286%20avril%202023%29.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Defense Innovation Orientation Document (2019)\n\n- Sections 3.8 and 3.9 outline the challenges that the Ministry of Armed Forces must address in regard to artificial intelligence and the direction the Ministry will take to advance capabilities and technological prowess.\n\n- AI and autonomy are identified as \"priority capability axes, and presents plans to accelerate acquisition of AI-enabled systems, stressing interoperability and security.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Document-dorientation-de-linnovation-de-Defense-DOID-2019.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Artificial Intelligence in Support of Defence (Sep 2019)\n\n- Section 2.4.1 creates a Defence Artificial Intelligence Coordination Unit (CCIAD) attached to the Defence Innovation Agency (AID) and describes three governance levels and the model for implementation within the Armed Forces Ministry.\n\n- Section 2.2: Data and Hardware; addresses the governance of data, creates a data architecture with three phases of implementation into the development of AI.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          },
          {
            "text": "Ministry of the Armed Forces Combined Arms Center of Concepts, Doctrine, and Experiments (CICDE) \"Operational Employment of Artificial Intelligence\" (Dec 2020)\n\n- This document acts as a joint exploratory concept on the use of AI in the military, outlining the role of AI in C2, ISR, decision support, and man-machine teaming.\n\n- Chapter 4 Section VI: emphasizes human supervision and control and states that AI systems should be usable, understandable, and subject to appropriate regulations.",
            "url": "https://www.defense.gouv.fr/sites/default/files/cicde/20201202-NP-CEIA-3.0.1_EMPLOI-SYST-ARMES-LETAUX-AUTONOMES.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- France voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle. It encourages global efforts to pursue action, participate in multilateral dialogue and knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Artificial Intelligence in Support of Defence (Sep 2019)\n\n- Section 2.5.1 aims to set up key partnerships between the Armed Forces Ministry and academic research organizations that have significant AI skills.\n\n- Section 2.5.3 dedicates \u20ac430 million to upstream AI-related studies from 2019-2025.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Artificial Intelligence in Support of Defence (Sep 2019)\n\n- Section 2.1: A Robust Ethical Legal Framework for the Armed Forces Ministry; establishes the creation of a ministerial ethics committee, takes steps to raise awareness on the use of AI from an ethical standpoint, and implements the standardization of norms within France and the international community.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          },
          {
            "text": "Ministry of the Armed Forces Combined Arms Center of Concepts, Doctrine, and Experiments (CICDE) \"Operational Employment of Artificial Intelligence\" (Dec 2020)\n\n- Chapter 4 Section I covers the ethics and legality of using AI in military applications, including compliance with IHL, sufficient human control, and the permanent and necessary responsability of command.",
            "url": "https://www.defense.gouv.fr/sites/default/files/cicde/20201202-NP-CEIA-3.0.1_EMP-OPS-IA2020-VF.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Defense Ethics Committee Opinion on the Use of AI Technologies by the French Armed Forces (Jan 2025)\n\n- This document presents 9 Principles and 12 Recommendations covering all aspects of military AI and calls for: proportionate use of force in line with the Law of Armed Conflict, command responsibility, transparency to avoid the \"black box\" effect, and rigorous benefit-risk evaluation.\n\n- France reiterates the need for clear human responsibility and control across the AI life cycle.",
            "url": "https://www.defense.gouv.fr/sites/default/files/ministere-armees/20250114_Opinion%20on%20the%20use%20of%20artificial%20intelligence%20technologies%20by%20the%20French%20armed%20forces.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Defense Ethics Committee Opinion on the Integration of Autonomy Into Lethal Autonomous Weapon Systems (Apr 2021)\n\n- Section II.D.a covers the moral acceptability of using force without human intervention, stating that the moral acceptability of using force will vary based in different operational situations.",
            "url": "https://cd-geneve.delegfrance.org/IMG/pdf/defence_ethics_committee_-_opinion_on_the_integration_of_autonomy_into_lethal_weapon_systems.pdf?2423/17d8f6beb2f5c9caa9c9168c53c24a91d9d32513"
          },
          {
            "text": "France's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- France supports the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.carnegiecouncil.org/media/article/principles-action-military-ai-governance"
          },
          {
            "text": "US DoS Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\n- France signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Artificial Intelligence in Support of Defence (Sep 2019)\n\n- Section 2.6: International Cooperation and Export Strategy; presents different circles of potential cooperation, which are categorized as structural partnerships, scoping partners, and occasional partners.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          }
        ],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Artificial Intelligence in Support of Defence (2019)\n\n- Section 2.1.3: Technical Measures to Ensure Trustworthy AI; ensures that the \"right level\" of trustworthiness and robustness is assessed for each AI application, commensurate with the criticality of the functions performed. It also includes a figure outlining risk level of AI-based algorithmic technology according to criticality.\n\n- Section 1.2.2: Assurance of Trustworthy, Controlled, and Responsible AI; states that systems containing AI must have robust and secure frameworks to avoid \"black-box\" effects, and must retain human responsibility for action.",
            "url": "https://www.defense.gouv.fr/sites/default/files/aid/Report%20of%20the%20AI%20Task%20Force%20September%202019.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Defense Ethics Committee Opinion on the Integration of Autonomy Into Lethal Autonomous Weapon Systems (Apr 2021)\n\n- Section II: Why and When Use PALWS; outlines the acceptable and unacceptable conditions for employing and deploying partially autonoous weapons systems (PALWS) and includes a rigorous test to ensure the 5 P's: performance, precision, pertinence, protection, and permanence.\n\n- Section III.A: reaffirms the central role of the human in the use of PALWS.\n\n- Section III.B: states that the military must adhere to a set of principles that guarantee proper use. The list includes: command, risk control, compliance, competence, and confidence.",
            "url": "https://cd-geneve.delegfrance.org/IMG/pdf/defence_ethics_committee_-_opinion_on_the_integration_of_autonomy_into_lethal_weapon_systems.pdf?2423/17d8f6beb2f5c9caa9c9168c53c24a91d9d32513"
          }
        ]
      }
    },
    "UK": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Ambitious, Safe, Responsible: Our Approach to the Delivery of AI-Enabled Capability in Defence (Jun 2022)\n\n- Annex C: The British government defines fully lethal autonomous weapons systems as those that \u201cidentify, select, and engage targets without context-appropriate human involvement.\u201d It deems such systems unacceptable and has stated that the UK will not develop them. For other autonomous systems, the UK will establish clear human responsibility and accountability.",
            "url": "https://assets.publishing.service.gov.uk/media/62a9b1d1e90e07039e31b8cb/20220614-Ambitious_Safe_and_Responsible.pdf"
          },
          {
            "text": "United Kingdom National Statement at the Vienna Conference on Lethal Autonomous Weapon Systems (Apr 2024)\n\n- This statement expresses the UK's declaration that it will not develop fully autonomous weapons and that International Humanitarian Law (IHL) applis to all technology that is AI-enabled.\n\n- Human judgement is always necessary throughout the development and use of weapon systems with autonomous functions.\n\n- However, the UK holds that IHL already constrains states in respect to their development ad procurement of weapons, and new legally binding rules are unnecessary beyond the application of IHL.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Republic_of_Korea_National_Statement.pdf"
          },
          {
            "text": "UK Submission Pursuant to United Nations General Assembly (UNGA) Resolution A/RES/78/241 on Lethal Autonomous Weapons Systems (May 2024)\n\n- The UK states that it does not possess fully autonomous weapon systems and has no intention of developing them, and that no states should develop or deploy such weapons.\n\n- The document reaffirms the necessity of the human to retain command and control over autonomous systems and states that accountability cannot be transferred to a machine.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-UK-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Ministry of Defence Letter to the UN on Lethal Autonomous Weapons Systems (Jan 2021)\n\n- This letter in response to international discussions on Lethal Autonomous Weapons Systems (LAWS) states that \"the operation of [UK] weapon sysems will always be under human control and no UK weapons ystems will be capable of attacking targets without [it]\".\n\n- The UK affirms that the GGE remains the right forum to discuss and progress the work on LAWS and states that a \"legally binding instrument which hampers the legitimate development and use of such technologies would be counterproductive\"..",
            "url": "https://article36.org/wp-content/uploads/2021/01/UK-govt-reply-2020-LAWS.pdf"
          },
          {
            "text": "UK Written Contribution to the Convention on Certain Conventional Weapons (CCW) on LAWS (Jun 2021)\n\n- This document presents the UK's views on the legal framework that should guide all aspects of LAWS, to include compliance with IHL and legal reviews of new weapons.\n\n- The UK holds that human responsibility and accountability for military outcomes is fundamental, and asserts that human control should be present across all stages of the AI life cycle.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_(2021)/GGE_LAWS_-_June_2021_-_United_Kingdom_-_written_contribution.pdf"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- The UK voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- The UK voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- The UK endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Joint Concept Note (JCN) 1/18  \"Human-Machine Teaming\" (May 2018)\n\n- This concept note by the British MOD introduces the idea that trust in machines that have autonomous functions is necessary.\n\n- The document frames human-machine teaming as central to future UK defense, with humans retaining judgment over critical decisions.",
            "url": "https://assets.publishing.service.gov.uk/media/5b02f398e5274a0d7fa9a7c0/20180517-concepts_uk_human_machine_teaming_jcn_1_18.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Defence Artificial Intelligence Strategy (Jun 2022)\n\n-  Overview Section; defines roles for the MOD Head Office, Business Units and Functional Leads, and Strategic Command.\n\n- Section 1.3: establishes Human-Machine teaming as the default approach to AI adoption, and mandates appropriate human involvement, supervision, or operational control parameters.\n\n- Section 2: Transform into an AI Ready Organisation; covers workforce changes within the UK MOD, to include an AI skills framework, the establishment of a Head of AI Profession, creates AI career paths, and mandates AI leadership training.\n\n- Section 3.3: Promoting Pace, Innovation, and Experimentation; mandates a \"systematic roll-out\" of mature data science and Machine Learning (ML) techniques. It also presents priority Capability Challenges which direct the  focus of R&D efforts.\n\n- Section 6.2: Leadership and Governance; outlines responsibilities for the Defence AI Unit (DAU), Defence AI Centre (DAIC), and describes a decentralized governance model with no single owner of AI within the MOD.",
            "url": "https://assets.publishing.service.gov.uk/media/62a7543ee90e070396c9f7d2/Defence_Artificial_Intelligence_Strategy.pdf"
          },
          {
            "text": "British Army Approach to Artificial Intelligence (Dec 2023)\n\n- This strategy document focuses on AI for decision advantage, emphasizing decision support rather than autonomous decision-making.\n\n- The Army AI Centre (AAIC) is established, which acts as the primary point of contact with DAIC to ensure compliance with defence AI regulation and best practice.",
            "url": "https://www.army.mod.uk/media/24745/20231001-british_army_approach_to_artificial_intelligence.pdf"
          },
          {
            "text": "Defence AI Centre (DAIC) Defence AI Playbook (Jan 2024)\n\n- This document was released to accelerate the adoption of AI within the British MOD and drive the transformation of Defence into an AI-ready organization.\n\n- The playbook covers various use case studies and solutions for the MOD to integrate, apply, and enhance AI-enabled capabilities for the given challenges in the battlespace.",
            "url": "https://assets.publishing.service.gov.uk/media/65bb75fa21f73f0014e0ba51/Defence_AI_Playbook.pdf"
          },
          {
            "text": "Government Response to House of Common Second Report of Session 2024-2025 Developing AI Capacity and Expertise in UK Defence (Apr 2025)\n\n- This document responds to the recommendations made by the House of Commons on developing AI capacity and expertise within the MOD.\n\n- Recommendation 1 addresses the need for benchmarks to track and compare AI sector strength.\n\n- Recommendation 5 provides a summary of the actions the MOD has taken to advance the UK to become an AI-ready nation, and it outlines the duties of the newly created Responsible AI Senior Officer in accordance with JSP 936 \"Dependable Artificial Intelligence in Defence\".\n\n- Recommendation 7 commits the MOD to developing  an interoperable AI framework across the MOD.\n\n- Recommendation 13 commits the MOD to a mapping exercise to identify gaps, duplication, and areas that need further investment of development within the defense AI infrastructure.\n\n- Recommendation 15 presents updated Strategic Outcomes in the Digital Strategy that guide the development and deployment of defense AI.\n\n- Recommendations 17-19 address the need for the MOD to investigate avenues for workforce enhancement, training, and retention as it pertains to AI in the MOD.",
            "url": "https://www.documentcloud.org/documents/25973602-government-response-developing-ai-capacity-and-expertise-in-uk-defence/?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Statement on Defence AI Strategy Launch (Jun 2022)\n\n- This statement by Minister of State for Defence Procurement Jeremy Quin announced the launch of the Defence AI Strategy and outlined the goals for the British government as it relates to defense AI and the adherence to ethical standards.",
            "url": "https://questions-statements.parliament.uk/written-statements/detail/2022-06-15/hcws101"
          },
          {
            "text": "The UK's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- The UK supports the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.carnegiecouncil.org/media/article/principles-action-military-ai-governance"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- The UK voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [
          {
            "text": "JSP 936 V1.1 Dependable Artificial Intelligence (AI) in Defence (Nov 2024)\n\n- Section 8: Suppliers; details requirements for external AI acquisition, including competence demonstrations and intellectual property considerations that must be taken into account for authorized procurement.",
            "url": "https://assets.publishing.service.gov.uk/media/6735fc89f6920bfb5abc7b62/JSP936_Part1.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Defence Artificial Intelligence Strategy (Jun 2022)\n\n- Section 4.4.1: Information Age Acquisition and Procurement Policy; outlines plans to streamline 'small' value digital purchases and enable agile methodologies for end-to-end acquisition of systems.\n\n- The MOD plans to work with both the Defence and National Security AI Network and the Defence Suppliers Forum SME Working Group to help reduce barriers that prevent viable industry partners from entering the supply chain.",
            "url": "https://assets.publishing.service.gov.uk/media/62a7543ee90e070396c9f7d2/Defence_Artificial_Intelligence_Strategy.pdf"
          },
          {
            "text": "Government Response to House of Common Second Report of Session 2024-2025 Developing AI Capacity and Expertise in UK Defence (Apr 2025)\n\n- This document responds to the recommendations made by the House of Commons on developing AI capacity and expertise within the MOD.\n\n- Recommendation 8 outlines the MOD's plans to bring about more regular development and deployment of AI-enabled defense systems, and also urges the MOD to consider new procurement models to reach developers with software that has dual-use potential.",
            "url": "https://www.documentcloud.org/documents/25973602-government-response-developing-ai-capacity-and-expertise-in-uk-defence/?utm_source=chatgpt.com"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [
          {
            "text": "JSP 936 V1.1 Dependable Artificial Intelligence (AI) in Defence (Nov 2024)\n\n- Section 3: Legal & Ethical Considerations of AI; establishes five binding ethical principles: Human-Centricity, Responsibility, Fairness, Security, and Explainability. These principles must be implemented across all Defence AI projects.",
            "url": "https://assets.publishing.service.gov.uk/media/6735fc89f6920bfb5abc7b62/JSP936_Part1.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Ambitious, Safe, Responsible: Our Approach to the Delivery of AI-Enabled Capability in Defence (Jun 2022)\n\n- Annex A details the five ethical principles framework with reference to the MOD's existing obligations under UK law and international law.\n\n- Annex B outlines the responsibility of the Ministry of Defence AI Ethics Advisory Panel, which is to scrutinize the MOD's ongoing approach to responsible and ethical AI and provide guidance and feedback.",
            "url": "https://assets.publishing.service.gov.uk/media/62a9b1d1e90e07039e31b8cb/20220614-Ambitious_Safe_and_Responsible.pdf"
          },
          {
            "text": "Defence Artificial Intelligence Strategy (Jun 2022)\n\n- Section 1.3 defers to the Ambitious, Safe, Responsible framework for AI ethics.\n\n- Chapter 3.5: International Capability Collaboration; outlines key efforts with various allies and alliances to enhance AI cooperation and increase mutual benefit.",
            "url": "https://assets.publishing.service.gov.uk/media/62a7543ee90e070396c9f7d2/Defence_Artificial_Intelligence_Strategy.pdf"
          },
          {
            "text": "British Army Approach to Artificial Intelligence (Dec 2023)\n\n- This strategy document commits the British Army to delivering capabilities that are interoperable with NATO allies and partners.",
            "url": "https://www.army.mod.uk/media/24745/20231001-british_army_approach_to_artificial_intelligence.pdf"
          },
          {
            "text": "The Government Response to the Report by the House of Lords AI in Weapons Systems Committee: 'Proceed With Caution: Artificial Intelligence in Weapons Systems' (Feb 2024)\n\n- Section 2: Ethics, Legal, and Governance; addresses recommendations and conclusioons regarding the domestic and international implementation of the MOD's AI Ethical Principels in the context of legal and safety frameworks.",
            "url": "https://assets.publishing.service.gov.uk/media/65cb77caa7ded0000c79e526/Government_response_to_the_House_of_Lords_AI_in_Weapon_Systems_Committee_Report.pdf"
          },
          {
            "text": "Government Response to House of Common Second Report of Session 2024-2025 Developing AI Capacity and Expertise in UK Defence (Apr 2025)\n\n- Recommendation 20 addresses cooperation with the UK's allies through AUKUS and NATO to reach a mutual understanding of AI objectives and strategies, focusing on shared approaches to ethics, data collection and labelling, and capacity-building.",
            "url": "https://www.documentcloud.org/documents/25973602-government-response-developing-ai-capacity-and-expertise-in-uk-defence/?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\n- The United Kingdom signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [
          {
            "text": "JSP 936 V1.1 Dependable Artificial Intelligence (AI) in Defence (Nov 2024)\n\n- Section 4: AI Ethics Governance (Governance of Non-Sovereign AI Development); details requirements for international AI sharing and alignment with NATO principles.",
            "url": "https://assets.publishing.service.gov.uk/media/6735fc89f6920bfb5abc7b62/JSP936_Part1.pdf"
          }
        ],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [
          {
            "text": "JSP 936 V1.1 Dependable Artificial Intelligence (AI) in Defence (Nov 2024)\n\n- Section 2: AI in Defence Systems; clearly defines autonomous systems and the levels within such systems.\n\n- Section 5: Human/AI Teams; mandates \"clearly defined means by which human control is exercised throughout their lifecycles.\" It directs human-centered AI design and training.\n\n- Section 6: AI Lifecycles; mandates data integrity management, control frameworks for training/testing data, and bias mitigation. It covers requirements for all stages of the AI lifecycle.\n\n- Section 7: Quality, Safety & Security; requires safety assurance through testing, evaluation, verification, and validation. It also requires compliance with UK Defence Standards 00-055 and 00-056.\n\n- Section 7: Quality, Safety & Security; requires a \"secure by design\" approach with specific attention to security challenges, such as data poisoning and adverserial attacks.",
            "url": "https://assets.publishing.service.gov.uk/media/6735fc89f6920bfb5abc7b62/JSP936_Part1.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Ambitious, Safe, Responsible: Our Approach to the Delivery of AI-Enabled Capability in Defence (Jun 2022)\n\n- Section: Using AI Safely; describes the UK AI safety regime, and provides the responsibilities of the Defence Accident Investigation Branch (DAIB), and the role of the Defence Safety Authority (DSA). Strict compliance is a focus item for safe use of AI.\n\n- Section: Our Approach and AI-Enabled Weapons; establishes that appropriate human control is necessary in autonomous AI systems.",
            "url": "https://assets.publishing.service.gov.uk/media/62a9b1d1e90e07039e31b8cb/20220614-Ambitious_Safe_and_Responsible.pdf"
          },
          {
            "text": "Defence Artificial Intelligence Strategy (Jun 2022)\n\n- Section 5.3.1: AI, Strategic Systems and Deterrence; explicitly states that \"regardless of any use of AI in our strategic systems - human political control of our nuclear weapons is maintained at all times\".",
            "url": "https://assets.publishing.service.gov.uk/media/62a7543ee90e070396c9f7d2/Defence_Artificial_Intelligence_Strategy.pdf"
          },
          {
            "text": "The Government Response to the Report by the House of Lords AI in Weapons Systems Committee: 'Proceed With Caution: Artificial Intelligence in Weapons Systems' (Feb 2024)\n\n- The British government's paper in response to a House of Lords report addresses the concerns voiced by the House and outlines the efforts being made by the government to ensure a safe and responsible approach to AI adoption in weapon systems.\n\n- The government opposes formally defining autonomous weapon systems due to the potential for an official definition to lead to a prohibitive legal instrument on certain types of autopnomous weapon systems, which the UK opposes.\n\n- Section 3: Safeguarding Against Risks; addresses AI safety regarding the potential escalation in conflicts, use against the UK, and integration within strategic systems.",
            "url": "https://assets.publishing.service.gov.uk/media/65cb77caa7ded0000c79e526/Government_response_to_the_House_of_Lords_AI_in_Weapon_Systems_Committee_Report.pdf"
          }
        ],
        "public_statements": []
      }
    },
    "South Korea": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Republic of Korea National Statement at the Vienna Conference \"Humanity at the Crossroads: Lethal Autonomous Weapon Systems\" (Apr 2024)\n\n- This statement expresses the ROK's views on the approach to addressing concerns on Lethal Autonomous Weapons Systems (LAWS). ROK recommends the \"three boxes\" approach, which centers on how existing IHL applies, how practical measures can be implemented to ensure IHL compliance, and whether new laws would be needed.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Republic_of_Korea_National_Statement.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "The Republic of Korea\u2019s Contribution to the Resolution on \u201cLethal Autonomous Weapons Systems\u201d A/RES/78/241 (May 2024)\n\n- This position paper defines LAWS as systems that, once activated, can identify, select and engage targets without further human intervention. South Korea reaffirms CCW Group of Governmental Experts (GGE) as \u201ccentral and unique forum\u201d and endorses a two-tier approach: (1) prohibition of LAWS inherently incompatible with IHL, and (2) regulation and risk-mitigation measures for other LAWS.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-ROK-EN.pdf"
          },
          {
            "text": "Foreign Minister Opening Remark at Responsible AI in the Military Domain (REAIM) Summit 2024 in Seoul (Sep 2024)\n\n- Foreign Minister Cho Tae-yul states that discussions at the summit would cover legal reviews to ensure compliance with IHL and mechanisms to prevent autonomous weapons from making life-and-death decisions without appropriate human oversight.",
            "url": "https://www.reuters.com/world/asia-pacific/south-korea-summit-target-blueprint-using-ai-military-2024-09-09/?utm_source=chatgpt.com"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "TIGER 4.0 Concept (Sep 2021)\n\n(DISCLAIMER - extremely limited public information)\n\n- The modernization plan includes a focus area on AI-based decision support systems (DSS) and the development of autonomous \"dronebot combat systems.\" It also emphasizes integration of AI into man-machine teams.",
            "url": "https://www.koreaherald.com/article/2694958"
          },
          {
            "text": "Defense Innovation 4.0 (Mar 2023)\n\n(DISCLAIMER - limited public information)\n\n- This strategy covers a phased approach to AI deployment with risk management protocols, safety evaluations, and performance standards for AI systems.\n\n- The initiative plans to integrate AI into surveillance, combat, command and control (C2) systems, manned-unmanned combat systems, and Joint All-Domain C2 Systems.\n\n- Military pilots are designated to enhance human expertise in defense AI application in an effort to advance digital proficiency within the Ministry of National Defense.",
            "url": "https://link.springer.com/chapter/10.1007/978-3-031-58649-1_23?utm_source=chatgpt.com"
          },
          {
            "text": "Minister of Science and Minister of Defense Memorandum of Understanding on Cooperation in Science, Technology, and Defense (Apr 2024)\n\n- This statement announces the plan to increase civilian-military cooperation in the technology, science, and defense sectors to create an elite and advanced military.",
            "url": "https://doc.msit.go.kr/SynapDocViewServer/viewer/doc.html?key=045a6f22883a49c296b601f4a261cf23&convType=html&convLocale=ko_KR&contextPath=/SynapDocViewServer/"
          }
        ],
        "public_statements": [
          {
            "text": "Establishment of the Defense AI Center (Apr 2024)\n\n- The MND established this center as part of the Defense Innovation 4.0 plan to oversee AI development in the defense sector, which employs 110 full-time staff and will focus on developing technologies in AI-based manned-unmanned teaming systems and battlefield situational awareness.",
            "url": "https://www.koreaherald.com/article/3360368"
          },
          {
            "text": "Vice Minister of National Defense Meeting (Aug 2025)\n\n- Defense Vice Minister Lee Do-hee chaired a meeting where the ministry discussed expanding AI use to aid decision-making in combat and ministerial policy decisions.",
            "url": "https://en.yna.co.kr/view/AEN20250829006300315"
          },
          {
            "text": "Minister of National Defense Statement at the 2025 Defense AI Implementation Review Meeting (Nov 2025)\n\n- Minister Ahn Gyu-baek states that the Ministry of National Defense (MND) plans to use AI to increase administrative efficiency, build an \"AI policy aide\" that supports the Minister's policy decisions, and an \"AI combat aide\" that supports commanders' decisions on the battlefield.",
            "url": "https://biz.chosun.com/en/en-policy/2025/11/18/ZD524MVDGJF65MTFZRYFBO6D3M/"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "South Korea's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- South Korea co-led the resolution (with the Netherlands and Singapore) on the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          },
          {
            "text": "US DoS Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\n- South Korea signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- Signatory states must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Israel": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Israel's Submission Pursuant to Resolution 78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\n- Israel views human control as a potentially relevant concept in the implementation of IHL obligations in different circumstances.\n\n- It acknowledges the importance of dialogue on Lethal Autonomous Weapons Systems (LAWS) in forums such as CCW and finds CCW the most suitable avenue for addressing the challenges and opportunities presented by LAWS.\n\n- IHL is a sufficient legal framework for any future use of LAWS in armed conflicts and stresses that the focus of the application of relevant laws should include the operational context in which the weapon system is used.\n\n- The paper states that \"discussion of the implementation of IHL rules that are context-dependent should not be conflated with discussion of the per se legality of weapons\"..",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Israel-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 on Lethal Autonomous Weapons Systems (Dec 2023)\n- Israel abstained from voting on this resolution.\n- The resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Israel's Vote on UN Draft Resolution L.77 on Lethal Autonomous Weapons Systems (Oct 2024)\n- Israel abstained from voting on this draft resolution.\n- The resolution raises concerns about the \u2018negative consequences and impact of autonomous weapon systems on global security and regional and international stability\u2019 and stresses \u2018the importance of the role of humans in the use of force to ensure responsibility and accountability and for States to comply with international law\u2019.",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "Israel's Vote on UNGA Resolution 79/239 \"Artificial Intelligence in the Military Domain and Its Implications for International Peace and Security\" (Dec 2024)\n\n- Israel voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Israeli Defense Force (IDF) Information & AI Strategy\n\n- DISCLAIMER - document not publicly available.\n\n- Secondary sources outline the IDF's plan to harness big data and integrate AI into all branches with a multi-level command framework.\n\n- The goal of the strategy is to make the IDF more effective, adaptable, and more efficient by harnessing AI capabilities.",
            "url": "https://www.c4isrnet.com/artificial-intelligence/2022/02/11/israel-unveils-artificial-intelligence-strategy-for-armed-forces/#:~:text=The%20IDF%20strategy%20spells%20out,Frantzman"
          },
          {
            "text": "National Program for Artificial Intelligence (Apr 2025)\n\n- Section 6.4.4 outlines the IDF's plan to increase the number of AI experts in the defense organizations and launch an integrated program to train young graduates to be incorporated into relevant units.",
            "url": "https://innovationisrael.org.il/wp-content/uploads/2025/05/AI-National-Program-en-14.5.25.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "IDF Director of Digital Transformation Administration Statement (Feb 2022)\n\n- Brigadier General Dagan, the Director of Digital Transformation Administration, states that the IDF is remodernizing by way of digital networking across branches and command ranks. This means that the IDF will build \"mini-clouds, or networks, for each of its arms and sometimes smaller subdivisions so that they can process and receive data even faster than in the current network\".",
            "url": "https://www.jpost.com/business-and-innovation/tech-and-start-ups/article-695843"
          },
          {
            "text": "Statement by the Israeli Ministry of Defense (IMOD) Director General on the AI and Autonomy Administration (Jan 2025)\n\n- Director General Major General Zamir states that the new AI and Autonomy Administration aims to centralize and advance AI and autonomous capabilities within IMOD.\n\n- He states that the \"future battlefield will see integrated teams of soldiers and autonomous systems working in concert\" in all braches of IMOD.",
            "url": "https://mod.gov.il/en/press-releases/press-room/israel-mod-establishes-ai-and-autonomy-administration"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Press Release on the IDF's Use of Data Technologies in Intelligence Processing (Jun 2024)\n\n- This statement by the IDF states that the identification of targets for attacks is always done by an analyst and the process for such processes is subject to international law. Furthermore, the IDF stresses that AI systems cannot be the sole basis for identifying, selecting, or generating targets autonomously.\n\n- The IDF addresses claims of its employment of AI systems that autonomously select targets for attack and refutes these claims by stating that military and intelligence processes utilize AI-enabled tools to complete mission objectives in accordance with IDF standard operating procedures (SOPs).",
            "url": "https://www.idf.il/en/mini-sites/idf-press-releases-israel-at-war/june-24-pr/the-idfs-use-of-data-technologies-in-intelligence-processing-published-june-18-2024/"
          },
          {
            "text": "US DoS Political Declaration on Responsible MIlitary Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Israel signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Israel's Stance in the Responsible Artificial Intelligence in the Military Domain (Responsible AI in the Military Domain (REAIM)) Summit 2024\n\n- Israel did not endorse the 'blueprint for action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.carnegiecouncil.org/media/article/principles-action-military-ai-governance"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Russia": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Document of the Russian Federation Pursuant to UNGA Resolution 78/241 \"Lethal Autonomous Weapons Systems\"  (May 2024)\n\n- The document states that Russia does not support a ban on the development or use of Lethal Autonomous Weapons Systems (LAWS).\n\n- Russia provides a suggestion for the requirements for a working definition of LAWS and states that existing highly automated military systems should not be subject to immediate restrictions and bans, and LAWS should not be defined purely through functions alone.\n\n- LAWS should not be indiscriminate nor disproportionate and should comply with the \"principle of proportionality between military necessity and damage caused,\" and Russia emphasizes that human control over the operation of LAWS is an important constrainer.\n\n- Russia outlines various means of control and methods to minimize risks with regard to LAWS.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Russian-Federation-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Russian Statement at the CCW Group of Governmental Experts (GGE) on LAWS (2021)\n\n- Russia states that a ban or limitation on the possibility of developing LAWS could have a negative influence on both the development of high technology in the civilian sphere and on the achievement of the aims of societal security.",
            "url": "https://conf.unog.ch/digitalrecordings/en/clients/61.0500/sessions/A1ACCA66-1B3F-4FC3-BC64-3915EEACA9EF"
          },
          {
            "text": "Russian Statement at the Sixth Review Conference of the CCW (Dec 2021)\n\n- Russia states that it is \"against the elaboration of any legally binding instrument\" on autonomous weapons systems, as well as being against \"a position of a moratorium on the development and use of such systems, and as well as the technologies used for making these systems\".",
            "url": "https://conf.unog.ch/digitalrecordings/en/clients/61.0500/sessions/AE782C82-C5CF-4D53-AC4F-A3D162685B62"
          },
          {
            "text": "Russia's Vote on UNGA Resolution A/RES/78/241 \"Lethal Autonomous Weapons Systems\" (Dec 2023)\n- Russia voted against this resolution.\n- The resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.\n- Explaining it\u2019s vote, Russia said that it \"opposes the development  of any internationally legally binding instrument with regard to lethal autonomous weapons systems, and the introduction of a moratorium on development and the use of systems and the technology used to create them\".",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "Concept of Activities of the Armed Forces in Development and Use of Weapons Systems with AI (Jul 2022)\n\n- DISCLAIMER: framework is internal to the Russian MOD and is not publicly accessible.\n\n- The document outlines how the Russian Armed Forces will apply weapons systems and military equipment with AI technologies. Secondary sources mention review systems, human control, and AI lifecycle management.\n\n- The Concept reaffirms that International Humanitarian Law (IHL) fully apply to all weapons and it presents a roadmap for AI integration into the Russian Armed Forces.",
            "url": "https://www.cnas.org/publications/reports/the-role-of-ai-in-russias-confrontation-with-the-west"
          }
        ],
        "policy_documents": [
          {
            "text": "National Strategy for AI Development Through 2030, Presidential Decree No. 490 (Oct 2019)\n\n- Article 6 mandates that the President's Security Council, the Ministry of Defense, and other federal bodies are responsible for implementing, monitoring, and reporting on AI applications in defense and security.",
            "url": "https://cset.georgetown.edu/wp-content/uploads/Decree-of-the-President-of-the-Russian-Federation-on-the-Development-of-Artificial-Intelligence-in-the-Russian-Federation-.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Presidential Address to the Federal Assembly (Mar 2018)\n\n- President Vladimir Putin states that Russia has developed unmanned submersible vehicles that are both conventional- and nuclear-capable, while also stating that Russia must eliminate all barriers for development and wide use robotic equipment, artificial intelligence, unmanned vehicles, among other capabilities.",
            "url": "http://en.kremlin.ru/events/president/news/56957"
          },
          {
            "text": "Defense Minister Statement at New Knowledge Lecture (May 2021)\n\n- Defense Minister Sergei Shoigu states that Russia has begun to produce \"robots that can be really shown in science-fiction films as they are capable of fighting on their own,\" singaling Russia's commitment to autonomy in weapons systems.",
            "url": "https://tass.com/science/1292483"
          },
          {
            "text": "Statement by Deputy Head of the Delegation of the Russian Federation at the Thematic Discussion on Conventional Arms in the First Committee of the 77th Session of the UN General Assembly (Oct 2022)\n\n- This statement stresses that measures to control LAWS and military AI are sufficient under international humanitarian law.\n\n- The Deputy Head also warns against rapid bans or restrictions on AI and autonomy to prevent undermining deterrence stability and broader arms control architecture.",
            "url": "https://reachingcriticalwill.org/images/documents/Disarmament-fora/1com/1com22/statements/20Oct_Russia.pdf"
          },
          {
            "text": "Presidential Speech at the Meeting of the Board of the Ministry of Defense (Dec 2022)\n\n- President Vladimir Putin calls for the integration of AI technology at all levels of decision-making in the armed forces.",
            "url": "http://kremlin.ru/events/president/news/70159"
          },
          {
            "text": "Deputy Prime Minister Statement on Military AI Developments (Aug 2024)\n\n- Russian Deputy Prime Minister Chernyshenko states that a specialized department for the development of AI is now in place within the Russian Ministry of Defense.",
            "url": "https://www.defensenews.com/global/europe/2024/08/16/russian-defense-plan-kicks-off-separate-ai-development-push/"
          },
          {
            "text": "Russia's Vote on UNGA Resolution A/RES/79/239 \"Artificial Intelligence in the Military Domain and Its Implications for International Peace and Security (Dec 2024)\n- Russia voted against this resolution.\n- The resolution calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Defense Minister Announcement at Russian MOD Collegium (Aug 2025)\n\n- Defense Minister Belousov outlines 10 priority objectives for the Defense Ministry, the second being the rearmament of strategic nuclear forces, air defense, EW, signals, and unmanned and robotic artificial intelligence systems by 2036.",
            "url": "https://understandingwar.org/research/russia-ukraine/russian-force-generation-and-technological-adaptations-update-september-24-2025/"
          },
          {
            "text": "Statement by Deputy Head of the Delegation of the Russian Federation at the Thematic Debate on Cluster V \"Other disarmament measures and international security\" in the First Committee of the 80th Session of the UNGA (Oct 2025)\n\n- Russia sees a clear link between international security and disarmament and warns against the discussion of these topics (development of definitions, standards, or applications) outside of UN fora.\n\n- Specific forms and methods of human control over AI-enabled weapons systems and military equipment should be left to individual states, and \"direct control should not be the only option\".",
            "url": "https://russiaun.ru/en/news/427102025"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Strategy for AI Development Through 2030, Presidential Decree No. 490 (Oct 2019)\n\n- The strategy recognizes autonomy as a pillar of defense modernization and mandates sovereign, independent development and priority acquisition of autonomous military systems.",
            "url": "https://cset.georgetown.edu/wp-content/uploads/Decree-of-the-President-of-the-Russian-Federation-on-the-Development-of-Artificial-Intelligence-in-the-Russian-Federation-.pdf"
          }
        ],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Strategy for AI Development Through 2030, Presidential Decree No. 490 (Oct 2019)\n\n- Article 2 states that the realization of AI must account for the moral, ethical, and legal norms, including the traditions and values of the people of the Russian Federation.",
            "url": "https://cset.georgetown.edu/wp-content/uploads/Decree-of-the-President-of-the-Russian-Federation-on-the-Development-of-Artificial-Intelligence-in-the-Russian-Federation-.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Statement by the Representative of the Delegation of the Russian Federation on Draft Resolution \"Artificial Intelligence in the Military Domain and Its Implications for International Peace and Security\" L.43 at the UNGA (Nov 2024)\n\n- This statement begins by outlining Russia's vote against the draft resolution, emphasizing the resolution's premature approach and reiterating the lack of necessity for new instruments and bans on military AI.\n\n- Russia criticizes the discussion outside of UN and CCW avenues on topics relating to military AI, its development, safeguards, and applications.",
            "url": "https://mid.ru/en/foreign_policy/news/1979934/"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n- Russia voted against this resolution.\n- The resolution calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Estonia": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Joint Paper to the Convention on Certain Conventional Weapons (CCW) on Categorizing Lethal Autonomous Weapons Systems (Aug 2018)\n\n- This joint paper with Finland stresses the need to understand autonomy levels, targeting functions, and human involvement for compliance with IHL.\n\n- The document states that \"humans must retain ultimate control over decisions of life and death,\" but \"human control does not necessarily have to be exercised contemporaneously with the delivery of force\".",
            "url": "https://unoda-documents-library.s3.amazonaws.com/Convention_on_Certain_Conventional_Weapons_-_Group_of_Governmental_Experts_%282018%29/2018_GGE%2BLAWS_August_Working%2BPaper_Estonia%2Band%2BFinland.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Group of Governmental Experts (GGE) on Lethal Autonomous Weapons Systems (LAWS) - Statement by Estonia (Mar 2019)\n\n- Estonia declares that humans must exercise control over a weapon system to ensure that the system operates in accordance with IHL, and that autonomous functions may be permissible if they are used consistently with the law.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-_Group_of_Governmental_Experts_%282019%29/LAWS%2BGGE%2B2019%2BI%2B-%2BEstonia%2B-%2BAgenda%2Bitem%2B5%28c%29.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Defence Artificial Intelligence Strategy for Estonia (2025)\n\n- Section 3.4 explicitly address the use of AI in autonomous weapons, including Estonia's support for such weapons. However, the document states a need for human control over the final decision on the use of lethal force.\n\n- The Strategy requires a weapons analysis in accordance with Article 36 of Protocol 1 of the Geneva Convention.",
            "url": "https://kaitseministeerium.ee/sites/default/files/defence_artificial_intelligence_strategy_for_estonia.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \"Lethal Autonomous Weapons Systems\" (Dec 2023)\n\n- Estonia voted in support of this Resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS.",
            "url": "https://automatedresearch.org/news/state_position/estonia/"
          },
          {
            "text": "UNGA Draft Resolution L.77 (Oct 2024)\n- Estonia abstained from voting on this draft resolution.\n- The resolution repeatedly calls for a binding legislation on a legally binding instrument with prohibitions and restrictions on.\n- This resolution also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://automatedresearch.org/news/state_position/estonia/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Defence Artificial Intelligence Strategy for Estonia (2025)\n\n- Section 3.2 mandates the appointment of a Chief Innovation Officer and/or Chief Digitalization Officer, who is responsible for a new unit guiding digital and technological developments for AI. The section outlines responsibilities for this position and presents expected frameworks regarding data and AI concepts for the Ministry of Defence to produce.\n\n- Section 3.2 calls for an update to the Estonian Military Academy curriculum, increasing funding for AI studies, and leveraging civilian STEM capacity to address workforce gaps within the Ministry of Defence.",
            "url": "https://kaitseministeerium.ee/sites/default/files/defence_artificial_intelligence_strategy_for_estonia.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Estonian Ministry of Defense Joint Statement on AI-Driven Defence Cooperation (Aug 2024)\n\n- This statement announces the advancement of Estonia's defense capabilities through the development and application of AI technologies.\n\n- Estonia will explore software-defined reconnaissance and strike capabilities using AI.",
            "url": "https://www.kaitseministeerium.ee/en/news/estonian-ministry-defence-and-helsing-ou-sign-joint-statement-ai-driven-defence-cooperation?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Defence Artificial Intelligence Strategy for Estonia (2025)\n\n- Section 3.4 commits to developing and deploying defense AI in accordance with international law, NATO's six Principles of Responsible Use (PRUs), and national ethical values. It explicitly references compliance with international humanitarian law as a requirement.",
            "url": "https://kaitseministeerium.ee/sites/default/files/defence_artificial_intelligence_strategy_for_estonia.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "US DoD Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\n- Estonia signed as an endorsing state to promote the development, deployment, and use of responsible military AI. \n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Estonia's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (May 2025)\n\n- Estonia supports the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.eeas.europa.eu/delegations/un-geneva/eu-statement-conference-disarmament-developments-science-and-technology-related-disarmament-and_en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Defence Artificial Intelligence Strategy for Estonia (2025)\n\n- Section 3.2 explicitly prioritizes network participation and interoperability with NATO, the EU, UK, US, and the Nordic states. It also requires strategic alignment with allied frameworks.",
            "url": "https://kaitseministeerium.ee/sites/default/files/defence_artificial_intelligence_strategy_for_estonia.pdf"
          }
        ],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Australia": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Australia National Statement at the Vienna Conference \u201cHumanity at the Crossroads: Lethal Autonomous Weapon Systems\u201d (Apr 2024)\n\n- Australia states that the CCW GGE is the most appropriate avenue to discuss Lethal Autonomous Weapons Systems (LAWS), and believes that humans are the responsible entity for \"effecting international humanitarian law (IHL) obligations - not machines.\" Australia also encourages other states to join initiatives that advance discussion on LAWS, including the REAIM  Summit and the Political Declaration on Responsible Use of Military AI and Autonomy.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Australia_National_Statement.pdf"
          },
          {
            "text": "Australia's Submission to the UN Secretary-General's Report on Lethal Autonomous Weapons Systems (May 2024)\n\n- Australia states that compliance with IHL is critical for the responsible development and use of LAWS and that the context in which LAWS is used is important to the laws that are applied to their development and use.\n\n- Australia also opposes the creation of a new legally binding instrument that would regulate or ban LAWS, and it supports the two-tier approach, which elaborates on LAWS that should be prohibited under IHL and those that should be regulated in accordance with IHL.\n\n- This document states human control as one and not the only means of ensuring compliance with IHL.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Australia-EN.pdf"
          },
          {
            "text": "Inquiry into the Department of Defence Annual Report 2022-23 (Oct 2024)\n\n- Chapter 5: Artificial Intelligence and Autonomous Weapons Related Issues; provides Australia's definition of AI and autonomy in weapons and Australian policy as it relates to AI regulation in general.\n\n- Australia foresees AI applications in human-machine teaming and requires a human in or on the loop for lethal capabilities, providing a tailored level of human control throughout the AI lifecycle.\n\n- This document reaffirms the commitment to applying IHL to lethal autonomous weapons.",
            "url": "https://www.aph.gov.au/Parliamentary_Business/Committees/Joint/Foreign_Affairs_Defence_and_Trade/DefenceAR2022-23/Inquiry_into_the_Defence_Annual_Report_2022-23/Chapter_5_-_Artificial_Intelligence_and_Autonomous_Weapons_related_issues"
          }
        ],
        "public_statements": [
          {
            "text": "\"Loyal Wingman\" Test Flight Announcement (Mar 2021)\n\n- The Head of Australian Air Force Capability announces the first successful flight test for the Loyal Wingman, which provides capability advantage by working with existing platforms to complement and extend air combat platforms.\n\n- This test signals Australia's commitment to developing unmanned aerial assets that are integrated into man-machine teams that use autonomous and AI-enabled systems, and improve the acquisition process to complement future force sructure.",
            "url": "https://www.defence.gov.au/news-events/releases/2021-03-02/first-flight-loyal-wingman"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Australia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Australia voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Australian Army - Robotic & Autonomous Systems Strategy v2.0 (Aug 2022)\n\n- This strategy outlines the plan to generate a competitive advantage by systematically integrating robotic and autonomous systems (RAS) into land warfare.\n\n- The Army embeds a \"trust-by-design\" model, which includes a graduated autonomy level for different autonomous systems, testing and verification, and human override mechanisms to ensure human control over critical decisions.\n\n- The document presents lines of effort: innovation, coordination, and realisation; and it also assigns responsibilities to various authorities to enable the strategy as the Australian Army moves forward with this plan.",
            "url": "https://researchcentre.army.gov.au/sites/default/files/Robotic%20and%20Autonomous%20Systems%20Strategy%20V2.0.pdf"
          },
          {
            "text": "Royal Australian Navy \u2014 RAS-AI Campaign Plan 2025 (Feb 2024)\n\n- This plan outlines the Australian Navy's plan to operationalize the use of robotics, autonomous systems, and AI.\n\n- This document positions the following capabilities as mission-critical: undersea warfare, maritime ISR, mine countermeasures, fleet protection, and distributed lethality.\n\n- The Campaign Plan states that AI will support decisions, not replace human command authority, and the decision to use lethal force remains with the human.\n\n- As a whole, the document provides a step-by-step roadmap to integrating and establishing AI within the Navy.",
            "url": "https://www.navy.gov.au/sites/default/files/2024-02/RAS-AI-Campaign-Plan-2025.pdf"
          },
          {
            "text": "Royal Australian Navy - RAS-AI Strategy 2040 (Oct 2020)\n\n- This strategy document outlines the Australian Navy's long-term plan to integrate AI and autonomy into day-to-day operations and assets.\n\n- The RAS envisions using AI for force protection, a partnered and interoperable force, a common control system, maximization of force potential, and a substantial force projection as five main priorities for the future.\n\n- The strategy presents design principles and four lines of effort to which the RAS will invest resources to achieve the main priorities, presenting specific initiatives and projects that the Navy will begin or conduct in accordance with this plan.",
            "url": "https://www.navy.gov.au/about-navy/strategic-planning/robotics-autonomous-systems-artificial-intelligence-strategy"
          }
        ],
        "public_statements": [
          {
            "text": "Interview with Minister of Defense on ADF Activities (Feb 2024)\n\n- The Minister of Defence states that the Australian Navy is preparing 26 surface combatants that will be \"large optionally crewed surface vessels,\" signaling that these vehicles will have the capacity to operate with autonomous functions.",
            "url": "https://www.defenceconnect.com.au/joint-capabilities/13653-defence-minister-teases-secret-autonomous-systems-developed-by-australian-defence-force"
          },
          {
            "text": "Statement by Minister for Defence on the National Defence Strategy (Apr 2024)\n\n- Minister Richard Marles states that additional investments toward autonomous systems, among other defense capabilities, and priority capabilities will be made for the next four years.",
            "url": "https://www.minister.defence.gov.au/media-releases/2024-04-17/2024-national-defence-strategy"
          },
          {
            "text": "Statement by Minister for Defence Industry on Integrated Investment Program (Apr 2024)\n\n- Minister Pat Conroy addresses the Australian Defence Force's (ADF) efforts to build an integrated and focused force, and outlines the major investments that the country will make to achieve this goal.\n\n- Autonomous capabilities and AI-enabled systems are a big focus of the investment program, and Conroy suggests a deliberate choice to invest in the chosen capabilities.",
            "url": "https://www.minister.defence.gov.au/media-releases/2024-04-17/2024-integrated-investment-program"
          },
          {
            "text": "Press Conference on Ghost Shark Capability (Sep 2025)\n\n- Deputy Prime Minister Richard Marles and Defence Industry Minister Pat Conroy gave a press statement covering the Ghost Shark project, claiming that it is \"the best autonomous underwater military capability on the planet\".\n\n- The Ministers state that Ghost Shark will have the capability for autonomous ISR and strike from \"extremely long distances from the Australian continent\".\n\n- This press statement shows evidence of Australia's intent to continue developing autonomous capabilities with various functions in the maritime domain.",
            "url": "https://www.minister.defence.gov.au/transcripts/2025-09-10/press-conference-sydney"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "2024 Integrated Investment Program (2024)\n\n- This document outlines Australia's defense spending commitment for a decade, beginning in 2024.\n\n- Chapter 1: Investing in the National Defence Strategy; defines \"trusted autonomy\" as one of the six National Defence Strategy priorities and presents \"smaller, low-cost and expendable robotic and autonomous systems that could be deployed in larger groups across the maritime, land and air domains\" as a priority investment area.\n\n- Chapter 2: Undersea Warfare; commits considerable investment to uncrewed maritime systems as well as large uncrewed autonomous underwater vehicles.\n\n- Chapter 7: Amphibious Capable Combined-Arms Land Systems; commits to comntinued R&D of uncrewed aerial vehicles for intelligence, surveillance, and force protection, and uncrewed ground systems for combat missions and support roles.\n\n- Chapter 8: Expeditionary Air Operations; commits investments to uncrewed aerial systems to augment crewed Air Force capabilities.\n\n- Chapter 14: Enabling Capabilities; commits to the integration of automated processes for faster and more efficient data processing and dissemination.",
            "url": "https://www.defence.gov.au/about/strategic-planning/2024-national-defence-strategy-2024-integrated-investment-program"
          }
        ],
        "public_statements": [
          {
            "text": "Press Conference on AI Capabilities (Jul 2024)\n\n- Minister for Defence Industry Pat Conroy states that the government is committing over $10 billion (AUD) to support autonomous systems and drones and their acquisition over the next ten years.\n\n- Minister Conroy announces the government's commitment to acquire 110 small uncrewed aerial systems.",
            "url": "https://www.minister.defence.gov.au/transcripts/2024-07-15/press-conference-sypaq-systems-melbourne"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Australia voted in support of this resolution, which  calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Australia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Assistant Minister for Defence Statement on the Australian Industry Group (Nov 2025)\n\n- Assistant Minister Peter Khalil states that AUKUS is developing and deploying advanced AI algorithms on the P-8A Maritime Patrol Aircraft, which process data from each nationa's sonobuoys and assists anti-submarine operators to detect submarines faster.\n\n- Australia is developing capabilities in conjunction with the UK and the US to accelerate defense innovation and achieve shared strategic goals.",
            "url": "https://www.minister.defence.gov.au/speeches/2025-11-27/australian-industry-group"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Foreign Minister Statement of AI Use in Nuclear Weapons (Sep 2025)\n\n- Foreign Minister Penny Wong states at the UN Security Council Open Debate that humans should not delegate responsibility over the use of lethal force to a machine. The decision to use nuclear weapons should also remain with humans.",
            "url": "https://www.foreignminister.gov.au/minister/penny-wong/speech/statement-un-security-council-open-debate"
          }
        ]
      }
    },
    "Germany": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "German Commentary on \"Operationalizing All Eleven Guiding Principles at a National Level as Requested by the Chair of the 2020 GGE on Lethal Autonomous Weapons Systems (LAWS) within the CCW\" (2020)\n\n- Germany states that as \"machines cannot be held liable for the actions they effect - neither morally, politically not legally... humans remain responsible for the actions they effect throughout the entire life cycle\".\n\n- Humans must have assurance that a relevant weapon system, once activated, conform to the applicable laws, rules, of engagement, and intentions of its operator.\n\n- The document also offers a commentary on how Germany does or plans to implement the guiding principles.",
            "url": "https://documents.unoda.org/wp-content/uploads/2020/07/20200626-Germany.pdf"
          },
          {
            "text": "Germany National Statement at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems and the Challenge of Regulation\" (Apr 2024)\n\n- Germany states that LAWS that cannot comply with International Humanitarian Law (IHL) should be prohibited, supporting a legally binding instrument consented by the GGE on LAWS to ban such weapons.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Germany_National_Statement.pdf"
          },
          {
            "text": "Germany's Submission to the UN Secretary General's Report on Lethal Autonomous Weapons Systems (May 2024)\n\n- Human control is seen as a key requirement when assessing the admissability of weapons that contain autonomous functions and supports an additional legally binding instrument to prohibit the development, use, and acquisition of LAWS  \"operating outside of human control and a responsible chain of command\".\n\n- Germany states that the decision over life and death must be made by humans.\n\n- The document states that Germany supports a two-tier approach to regulating LAWS, where a prohibition on LAWS that do not comply with IHL is in place, and a regulation of weapons systems that do have autonomous functions and are within the bounds of IHL.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Germany-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Foreign Minister Statement on Agreement to Guiding Principles Relating to LAWS (Feb 2020)\n\n- Minister Haas states that \"Killer robots must never become a reality\" and reiterates Germany's goal of creating a worldwide ban on fully autonomous lethal weapons systems (2019).\n\n- He states that \"letting machines decide over life and death of human beings runs against all of our ethical standards\" (2020).",
            "url": "https://www.auswaertiges-amt.de/en/newsroom/news/maas-autonomous-weapons-systems-2277194?utm_source=chatgpt.com"
          },
          {
            "text": "Foreign Minister Statement on the Use of Fully Autonomous Weapons Systems (Mar 2019)\n\n- Foreign Minister Heiko Maas states that Germany supports a worldwide ban on fully autonomous weapons systems (LAWS).",
            "url": "https://www.auswaertiges-amt.de/en/newsroom/news/maas-autonomous-weapons-systems-2277194"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Germany voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n - Germany voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Germany endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Germany's National Contribution to the UN Secretary General's Report on the Opportunities and Challenges Posed to Int'l Peace and Security by the Application of AI in the Military Domain (Apr 2025)\n\n- This document states that Germany is aligned with NATO's Principles of Responsible Use (PRUs) and endorses various multilateral frameworks.\n\n- Germany states that it is committed to addressing risks associated with the use of AI in the military domain and reaffirms its view on maintaining human control as a necessary condition for military AI.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Germany-en.pdf"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Germany signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Germany voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Turkey": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by Turkiye at the Thematic Discussion on \"Conventional Weapons\" (Oct 2022)\n\n- Turkiye states that the development and use of autonomous weapons which do not have meaningful human control are \"undesirable\" and do not align with International Humanitarian Law (IHL).\n\n- The position is that humans must be involved in the decision loop and bear responsibility in the cases of life and death.",
            "url": "https://reachingcriticalwill.org/images/documents/Disarmament-fora/1com/1com22/statements/21Oct_Turkiye.pdf"
          },
          {
            "text": "Statement by Turkiye at the GGE Meeting on Lethal Autonomous Weapons Systems (LAWS) (Mar 2024)\n\n- Developing a new legally binding instrument that prohibits LAWS would not serve a purpose in the absence of a universally agreed definition.\n\n- Systems that perform all steps of a targeting cycle outside human control or supervision are \"not technically feasible, militarily desirable, or legally permissible in terms of IHL\".",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_(2024)/T%C3%BCrkiye-CCW_LAWS_GGE-04032024.pdf"
          },
          {
            "text": "Turkiye National Statement at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems\" (Apr 2024)\n\n- Turkiye supports the progress and access to civilian research development due to the dual-use nature of emerging technologies such as LAWS.\n\n- Turkiye holds that all parties to armed conflict must act in accordance with the basic principles of IHL.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Tuerkiye_National_Statement.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n- Turkiye abstained from the vote on this resolution.\n- The resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n- Turkiye abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems.\n- The resolution signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Artificial Intelligence Strategy 2021-2025 (Aug 2021)\n\n- While not a military-specific strategy, this document contains goals of creating \"a competency repository in certain software development areas that are critical for defense needs, especially AI\".\n\n- The strategy announces areas of R&D projects that use AI technologies for defense and security, including: classification and identification of surface targets detected by radar, autonomous reconnaissance with collaborative robots, AI-assisted fire control and autonomous driving for land vehicles, etc.",
            "url": "https://cdn-assets.inwink.com/b0269dea-af7b-4460-b29a-c40b9941c4c5/d32fa511-ac43-49ef-b5b2-d90034d2af03"
          },
          {
            "text": "Defense Industry Sectoral Strategy 2023-2027 SSB (Jan 2024)\n\n- This strategy document sets goals for defence industry R&D capability, including increasing autonomy levels of UAV systems through AI applications, enabling swarm and manned-unmanned teaming in drones, and bolstering naval unmanned systems.\n\n- AI is framed as a core enabling technology in ISR and targeting and outlines the Turkish military's plans to reorganize its talent and focus areas to better implement and deploy AI.",
            "url": "https://www.scribd.com/document/805331508/F-20231106165507582242?language_settings_changed=English&utm_source=chatgpt.com"
          },
          {
            "text": "2024-2028 Defence Industry Sectoral Strategy SSB Update (2025)\n\n- This document builds on the 2023-2027 version, but expands on the activities the military will undertake.\n\n- This document outlines goals to maintain a shared infrastructure that the defence, academic, and private sectors can all use.\n\n- The strategy places emphasis on developing AI talent and working with the academic sector to develop capabilities within the defense focus areas.",
            "url": "https://www.manisatso.org.tr/tr/haber/6345/2024_2028_savunma_sanayi_sektorel_strateji_dokumani.html?utm"
          },
          {
            "text": "Future of Artificial Intelligence Technologies Report (Oct 2025)\n\n- This report contains a multi-stakeholder approach and an R&D technology roadmap for near and long-term goals.\n\n- The document assess the current level of AI integration, challenges encountered, goals achieved, and future growth areas that have been identified which inform the roadmap.\n\n- There are five main focus groups categorized within this report: AI technologies with image, video, and 3D data; voice/speech and text data; time series and tabular data; hybrid AI; and regulations and data policies for military AI applications.",
            "url": "https://envantermedya.com/ssb-gelecegin-yapay-zeka-teknolojileri-raporunu-yayinladi/?utm_source=chatgpt.com"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Turkiye signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Turkiye voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "India": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "India Submission to the UN Secretary General Pursuant to Resolution 78/241 on Lethal Autonomous Weapons Systems (LAWS) (May 2024)\n\n- IHL should apply to all aspects of lethal autonomous weapons, and India supports the view that emerging technologies, in general, have the potential to improve compliance with IHL.\n\n- The document states India's view that states should limit the types of targets LAWS can engage, limit the duration, geographical scope, and scale of operations, and provide appropriate training to operators of LAWS. This signals India's stance that it does not oppose toe development or use of autonomous weapons systems.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-India-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n- India voted against this resolution.\n- The resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n- India abstained from the vote on Draft Resolution L.77 on lethal autonomous weapons systems.\n- The resolution signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "Executive Order Creating the Defence AI Council (DAIC) and the Defence AI Project Agency (DAIPA) (Feb 2019)\n\n- This executive order creates the DAIC and DAIPA, which provide necessary guidance to enable and develop operating frameworks, policy level changes, and structural support for AI adoption.",
            "url": "https://www.pib.gov.in/PressReleaseIframePage.aspx?PRID=1810442&reg=3&lang=2"
          }
        ],
        "policy_documents": [
          {
            "text": "Defence Minister Statement on Employing AI in the Armed Forces (Aug 2018)\n\n- The Defence Minister presents \"thrust areas\" identified for employing AI to enhance future capabilities, some of which include: object identification and image classification, intelligence & autonomous unmanned systems, defense, offense, and command information warfare, autonomous underwater vehicles, etc.",
            "url": "https://sansad.in/getFile/loksabhaquestions/annex/15/AU3471.pdf?source=pqals&utm_source=chatgpt.com"
          },
          {
            "text": "Strategic Implementation of AI for National Security and Defense (Feb 2019)\n\n- This document adopts and mandates several provisions recommended by the Ministry of Defence Task Force.\n\n- The High Level Defence AI Council (DAIC) is established, which provides necessary guidance to enable and effect the development of operational frameworks, policy changes, and structural support.\n\n- The Ministry of Defence (MOD) is ordered to allocate funds to the Defence AI Project Agency (DAIPA) and other AI-specific application development.\n\n- The document mandates AI capacity building frameworks, which includes AI-specific training for defense personnel.",
            "url": "https://www.ddpmod.gov.in/sites/default/files/123b4638d3f145463b3e40614e9e78c3dd74f1c39351594bb4bd9c545e0de04d/82b14144040372c3f831243d48de3cdad873fcbce7be33a1269dfc58e96b0692."
          },
          {
            "text": "Ministry of Defence Development of Advanced Technologies for Military (Mar 2022)\n\n- This document responds to an inquiry into details of government progress on developing advanced technologies.\n\n- The Defence Research Development Organisation (DRDO) has two dedicated AI laboratories for application oriented research in AI, both of which have AI technology groups to introduce AI features into products under development.",
            "url": "https://sansad.in/getFile/loksabhaquestions/annex/178/AU3904.pdf?source=pqals"
          }
        ],
        "public_statements": [
          {
            "text": "Press Release on Task Force for Implementation of AI (Mar 2022)\n\n- This press release announces the establishment of the AI Sub Committee and Joint Working Group on AI in Tri-Services.\n\n- Each service has also formulated data policy and appointed Data Management Officers, engaged in the development of AI projects through iDEX, and have implemented training frameworks for defense personnel.",
            "url": "https://www.pib.gov.in/PressReleasePage.aspx?PRID=1810442&reg=3&lang=2"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Ministry of Defence Innovation in Defence Production Projects (Mar 2023)\n\n- This document presents the list of government-approved projects under the Innovations for Defence Excellence (iDEX) framework, which aims to foster innovation and technology development in Defence by engaging with industry.\n\n- Projects include AI-based satellite image analysis, autonomous underwater swarm drones and weaponized boat swarms, AI-based intelligence capabilities, and others.",
            "url": "https://sansad.in/getFile/annex/259/AU1329.pdf?source=pqars&utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Defence Minister Launches 75 AI Products/Technologies at \"AI in Defence\" Symposium (Jul 2022)\n\n- Defence Minister Shri Rajnath Singh launched 75 newly-developed AI products and technologies during the New Delhi Symposium, which included domains regarding AI platform automation, autonomous/unmanned/robotic systems, LAWS, and ISR (among other topics).\n\n- Minister Singh asserted that India has begun to incorporate AI into remote piloted, unmanned aerial vehicles.\n\n- India's Ministry of Defence is working closely with academic insitutions and industry, and three dual-use application products were screened to potentially open new avenues for defense innovation.",
            "url": "https://www.pib.gov.in/PressReleasePage.aspx?PRID=1840740&reg=3&lang=2"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- India voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and to submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Evaluating Trustworthy Artificial Intelligence (ETAI) Framework & Guidelines for the Armed Forces (Oct 2024)\n\n- The framework focuses on five principles: Reliability & Robustness, Safety & Security, Transparency, Fairness & Privacy. It defines a comprehensive set of criteria for evaluating the trustworthiness of AI, and provides specific measures to be implemented in the AI pipeline.\n\n- This is a risk-based asssessment framework developed specifically for the defense sector, which prescribes specific processes and technical measures across the AI lifecycle to meet the criteria outlined in the five principles.",
            "url": "https://www.pib.gov.in/PressReleaseIframePage.aspx?PRID=2065847"
          }
        ],
        "public_statements": []
      }
    },
    "Pakistan": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Pakistan at the First Session of the CCW GGE on Lethal Autonomous Weapons Systems (LAWS) (Apr 2018)\n\n- Pakistan states that LAWS, by nature, are unethical because there is no longer a human in the loop and the decision over life and death is delegated to a machine.\n\n- This submission states the inherent ethical implications of LAWS and the necessity for human control and responsibility at all times for the use of autonomous weapons systems.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-_Group_of_Governmental_Experts_%282018%29/2018_LAWS6b_Pakistan.pdf"
          },
          {
            "text": "Pakistan National Statement at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems and the Challenges of Regulation\" (Apr 2024)\n\n- Pakistan advocates for the establishment of an international legal framework through the CCW that clearly delineates the boundaries for LAWS and supports a two-tier approach: \"outright prohibition of systems that function outside human control and fail to conform to International Humanitarian Law (IHL) standards,\" and restrictions for other types of weapons.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Pakistan_National_Statement.pdf"
          },
          {
            "text": "Submission of Views by Pakistan to the UN Secretary General Pursuant to Resolution 78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\n- This document offers Pakistan's views regarding the humanitarian, legal, ethical, and security perspectives that must be considered when addressing the issue of LAWS.\n\n- Pakistan calls for a new international legal instrument to prohibit and restrict LAWS which cannot comply with IHL at all points in the life cycle.\n\n- The document presents Pakistan's opinion on what conditions warrant an absolute prohibition of LAWS and what restrictions should be placed on autonomous weapons that are not prohibited.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Pakistan-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Pakistan voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Pakistan voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Pakistan voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Pakistan Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- Pakistan endorses the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI, and the future governance of AI in the military domain.",
            "url": "https://asianews.network/seoul-summit-charts-framework-on-responsible-ai-military-use/"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission of Views by Pakistan in Accordance with UNGA Resolution 79/239 \"Artificial Intelligence in the Military Domain and its Implications for International Peace and Security\" (2025)\n\n- This submission presents Pakistan's views on the role of AI in nuclear weapon decisions, operational risks, technical risks, legal, ethical, and global security risks.\n\n- Pakistan advocates for normative dialogue across multiple multilateral frameworks to discuss concerns, risk mitigation efforts, and peaceful progress that military AI presents.\n\n- Pakistan also supports negotiations on a legally binding instrument to prohibit fully autonomous weapons incapable of complying with IHL.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Pakistan-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Defense Minister Comment at UN Security Council Debate (Sep 2025)\n\n- Defense Minister Khawaja Muhammad Asif states that AI, particularly in military applications, must be governed by the UN Charter and international law.\n\n- Minister Asif also reiterates Pakistan's stance that AI applications without meaningful human control should be prohibited stating that \"humans must always retain authority over life-and-death decisions.\" Asif calls for a legally binding instrument to be decided or placed by 2026.",
            "url": "https://www.arabnews.com/node/2616641/pakistan"
          }
        ]
      }
    },
    "Azerbaijan": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Azerbaijan voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "News Release \"The Contribution of Unmanned Aerial Vehicles to the Military and Modern Warfare\" (Dec 2024)\n\n- This Ministry of Defense (MOD) news release outlines Azerbaijan's use of unmanned aerial vehicles and the importance of AI in future warfare.\n\n- The release signals Azerbeijan's intent to integrate AI into UAV assets, stating potential use cases that \"automatically identify targets, analyze the terrain and predict enemy movements... analyzing them in real time, making autonomous decisions and improving adaptation to new conditions\".",
            "url": "https://mod.gov.az/az/pre/53548.html?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Ukraine": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Ukraine voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n- Ukraine abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems.\n- The resolution signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Ukraine's Submission in Connection With Resolution 79/239 \"Artificial Intelligence in the Military Domain and its Implications for International Peace and Security\" (2025)\n\n- Ukraine states that it uses military AI' exclusively to strengthen its defence capabilities by exercising the right to self-defense provided by the UN Charter.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_(2025)/79-239-Ukraine-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Deputy Prime Minister Statement on the Future of Autonomous Warfare (Apr 2023)\n\n- Deputy PM and Minister of Digital Transformation Mykhailo Fedorov states that AI can be and currently is used for target recognition and other tasks.\n\n- Minister Fedorov answers ambiguously on whether Ukraine has developed any technology that can operate fully autonomously.",
            "url": "https://www.wired.com/story/fast-forward-ukraines-quest-for-homegrown-ai-drones-to-take-on-russia/?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Ukraine voted in support of this resolution, which calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "Ministry of Defence Event \"Decisive Innovations: Ukraine's Next Steps in the Technology War\" (Aug 2025)\n\n- This news release covers the Ministry of Defence's plan to launch new support tools for the Ukrainian military, including artificial intelligence.\n\n- Minister of Defence Denys Shmyhal announces 70 technical areas across nine categories, some of which include: AI, drones, ground robotic systems, unmanned boats, and more.",
            "url": "https://mod.gov.ua/en/news/ministry-of-defence-and-ministry-of-digital-transformation-establish-a-unified-ecosystem-to-support-ukrainian-arms-manufacturers?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Brave1 Grant Competition Initiative (Sep 2025)\n\n- The Ministry of Defence and the Ministry of Digital Transformation launched the Brave1 grant competition for companies to provide solutions to improve mission autonomy for the Ukrainian military.\n\n- The focus areas include: autonomous drones, autonomous guidance modules and thermal targeting systems for drone interceptors, AI-based solutions for the interception and neutralization of guided aerial bombs, and simulation environments for training and testing AI-enabled autonomous combat systems.\n\n- This initiative shows Ukraine's intent to invest in both offensive and defensive capabilities for AI-based weapons.",
            "url": "https://mod.gov.ua/en/news/up-to-uah-100-million-for-breakthrough-ai-solutions-ministry-of-defence-and-ministry-of-digital-transformation-launch-brave1-grant-competition?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Ukraine signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Ukraine Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024\n\n- Ukraine endorses the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI, and the future governance of AI in the military domain.",
            "url": "https://asianews.network/seoul-summit-charts-framework-on-responsible-ai-military-use/"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "UAE": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n- The UAE abstained from voting on this resolution.\n- The resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- The UAE voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "UAE Export Control Regime (2020)\n\n- In July 2020, the updated Control List, which prohibits the delivery, transfer, publication, leaking, or sharing of information, included equipment facilitating autonomous capabilities.",
            "url": "https://www.morganlewis.com/pubs/2025/08/overview-of-the-uaes-export-control-regime"
          }
        ],
        "public_statements": [
          {
            "text": "UAE- USA Joint Venture for Autonomous Defense Systems (Nov 2025)\n\n- UAE-based company EDGE and US-based Anduril announced a government-backed venture to co-develop and locally produce a hover-to-cruise Autonomous Air Vehicle (AAV).\n\n- The UAE has finalized the acquisition of 50 \"Omen\" systems, which combines the \"endurance, payload, and autonomy of larger systems with the flexibility of a compact, runway-independent airframe\".\n\n- This joint venture signals the UAE's goal of domestically produced autonomous dual-use aircraft, to include R&D and simulation centers for future expansion.",
            "url": "https://uasweekly.com/2025/11/13/edge-anduril-form-uae-us-jv-for-autonomous-defense-systems/"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- UAE voted in support of this resolution, which calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Iran": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Iran Statement on Lethal Autonomous Weapons Systems (2023)\n\n- The representative from Iran to the UN stated that Iran will abstain from voting on the draft resolution titled \"Lethal Autonomous Weapons Systems\" due to a lack of a clear definition and scope of the terminology \"lethal autonomous weapons\".",
            "url": "https://press.un.org/en/2023/gadis3731.doc.htm"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n- Iran abstained from voting on this resolution.\n- The resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n- Iran abstained from voting on this resolution.\n- The resolution signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n- Iran abstained from voting on this resolution.\n- The resolution calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "North Korea": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n- North Korea abstained from voting on this resolution.\n- The resolution supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n- North Korea voted against Draft Resolution L.77 on lethal autonomous weapons systems.\n- The resolution signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n- North Korea voted against this resolution.\n- The resolution calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Norway": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Norway on Lethal Autonomous Weapons Systems (May 2024)\n\n- Norway supports a two-tier approach consisting of a combination of a prohibition on certain autonomous weapons systems and the regulation of the use of other such systems and explicitly supports a legally binding instrument to prohibit certain autonomous weapon systems.\n\n- This document extensively presents what should constitute as \"meaningful human control\" as it pertains to autonomous weapons.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Norway-EN.pdf"
          },
          {
            "text": "Statement by Norway to the GGE on Emerging Technologies in the Area of Lethal Autonomous Weapons Systems (LAWS) (Aug 2024)\n\n- Norway supports a legally binding instrument to clarify the application of IHL to lethal autonomous weapons.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_%282024%29/2024-08-26_Norway_CCW_GGE_LAWS_2nd_session_general_statement.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Norway supports this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Norway voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [
          {
            "text": "Award Letter for Defence Equipment 2024 (Jan 2024)\n\nSection 5.2: Strategy for Artificial Intelligence and Innovation; mandates a half year and annual report on developing a follow-up plan for the defense sector in regards to the Strategy for AI in the Defence Sector\n\n- The letter also mandates an action plan for specific areas where AI can be applied.",
            "url": "https://www.regjeringen.no/contentassets/d88b9ee605634445a3165501cc0f8d12/ugradert-~-b23_00676-7-tildelingsbrev-for-forsvaret-2024-214503_10_0.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Norway Submission to the UN Secretary General Pursuant to UNGA Resolution 79/239 (Apr 2025)\n\n- This document effectively summarizes the Norwegian Strategy for AI in the Defence Sector (2023) and the key areas and principles in the development of responsible AI in the military domain.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Norway-EN.pdf?utm"
          },
          {
            "text": "Strategy for Artificial Intelligence in the Defence Sector (Oct 2023)\n\n- The strategy highlights key application areas for AI in the military, including: enhanced situational awareness & decision support, cyber defense, logistics, and support activities.\n\n- Norway emphasizes the responsible development, acquisition, and use of artificial intelligence.",
            "url": "https://www.regjeringen.no/contentassets/a36197a7d69c45e68186b10117e76b5b/forsvarsdepartementet-kunstig-intelligens.pdf"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Strategy for Artificial Intelligence in the Defence Sector (Oct 2023)\n\n- This strategy contains the government's plan to use AI to promote Norway's security and defense goals.\n\n- The key principles for responsible development and use of AI are: lawfulness, responsibility & accountability, explainability & understandability & traceability, training, reliability & safety & security, and control.",
            "url": "https://www.regjeringen.no/contentassets/a36197a7d69c45e68186b10117e76b5b/forsvarsdepartementet-kunstig-intelligens.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Norway voted in support of this resoluton, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Norway endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      }
    },
    "Singapore": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Singapore's National Submission on the Topic of Lethal Autonomous Weapons Systems (LAWS) (May 2024)\n\n- Singapore supports a two-tier approach to regulating laws, which would prohibit LAWS that are incapable of conforming to IHL and regulates other cases of autonomous weapons systems.\n\n- Singapore also supports a \"concept of limits\" to clarify the scope of LAWS and to ensure that LAWS can be used in accordance with IHL.\n\n- The document reiterates Singapore's commitment to upholding the following principles for AI in the military realm: Responsible, Reliable, Robust, and Safe.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Singapore-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Singapore voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Singapore voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Singapore's National Submission on the Topic of Artificial Intelligence in the Military Domain and its Implications for International Peace and Security (Apr 2025)\n\n- Singapore acknowledges the potential benefits of AI in the military domain, advocates for the responsible and safe use of AI, reiterating the national principles of responsibility reliability, robustness, and safety.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Singapore-en.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Creation of Digital Intelligence Service (2022)\n\n- The Digital Intelligence Service (DIS) is responsible for optimizing the application of new technologies, particularly AI, across the armed forces.",
            "url": "https://www.mindef.gov.sg/news-and-events/latest-releases/15feb25_speech2/?utm_source=chatgpt.com"
          },
          {
            "text": "Singapore Armed Forces (SAF) AI Centre Establishment (2024)\n\n- The SAF established the AI Centre to accelerate AI adoption, grow expertise, and operationalize AI capabilities.\n\n- Use case examples include natural langauge processing, computer vision, generative AI, and AI for cybersecurity.",
            "url": "https://www.linkedin.com/posts/dis-safc4dc_guardiansofnewfrontier-thesingaporedis-activity-7311240070479446016-JGwu/"
          },
          {
            "text": "Singapore Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- Singapore endorses the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.\n\n- Singapore co-hosted the REAIM summit in Seoul, South Korea alongside South Korea, the Netherlands, Kenya, and the UK.",
            "url": "https://www.mindef.gov.sg/news-and-events/latest-releases/10sep24_nr/"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Deputy Prime Minister at Singapore Defence Technology Summit 2025 (Mar 2025)\n\n- Deputy PM Swee Keat states that Singapore has committed funds to \"develop innovative AI solutions in self-driving vehicles\u2026for military and commecial applications\".\n\n- The Defense Science and Technology Agency (DSTA) is working with technology start-up companies to enhance the defense ecosystem by way of autonomous vehicles and underwater autonomous capabilities.",
            "url": "https://www.pmo.gov.sg/newsroom/dpm-heng-swee-keat-at-the-singapore-defence-technology-summit-2025/?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Statement of Intent on Data Analytics and Artificial Intelligence (Jul 2024)\n\n- The US DoD's CDAO and Singapore's deputy secretary for technology signed a statement of intent to strengthen interoperability and advance cutting-edge technology in the realm of data and AI.",
            "url": "https://www.war.gov/News/News-Stories/Article/Article/3839335/us-singapore-cooperate-on-data-analytics-artificial-intelligence/"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Singapore signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Singapore voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "Statement by Minister for Foreign Affairs at the UNSC Open Debate (Sep 2025)\n\n- Minister Vivian Balakrishan states that Singapore supports multilateral frameworks that implement guardrails for AI in military applications.\n\n- The Minister reiterates Singapore's adherence to its national principles for AI in the military domain, which which are responsibility, reliability, robustness, and safety.",
            "url": "https://www.mfa.gov.sg/newsroom/press-statements-transcripts-and-photos/unsc-open-debate-on-ai-and-international-peace-and-security/"
          },
          {
            "text": "Singapore's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- Singapore co-led the resolution (with South Korea and the Netherlands) on the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Canada": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "The Department of National Defence and Canadian Armed Forces (DND/CAF) Artificial Intelligence Strategy (Mar 2024)\n\n- The Guiding Principles explicitly state that applications of military-use AI involving lethal force must always retain human in the loop.",
            "url": "https://hkifoa.com/wp-content/uploads/2024/11/ai-strategy-cananda-defense.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\n- Canada voted in support of this resolution and states that autonomy in weapons must be trustworthy, predictable, and used in accordance with IHL.\n\n- Canada stresses reducing collateral harm and maintaining human responsibility.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Canada-EN.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "UN Draft Resolution 79/L77 (Dec 2023)\n\n- Canada voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://documents.un.org/doc/undoc/ltd/n24/305/45/pdf/n2430545.pdf"
          },
          {
            "text": "Convention on Certain Conventional Weapons (CCW) Guiding Principles on Lethal Autonomous Weapons Systems (Sep 2019)\n\n- Canada endorsed the CCW's Guiding Principles on Lethal Autonomous Weapons Systems (LAWS) in 2019, citing them as a baseline for future work in regulatory frameworks in AI and autonomy.",
            "url": "https://documents.unoda.org/wp-content/uploads/2020/09/CCW_GGE.1_2019_3_E.pdf"
          },
          {
            "text": "Minister of Foreign Affairs Mandate Letter (Dec 2019)\n\n- Prime Minister Justin Trudeau explicitly instructs the new Foreign Minister to \"advance international efforts to ban the development and use of fully autonomous weapons systems\".",
            "url": "https://www.pm.gc.ca/en/mandate-letters/2019/12/13/archived-minister-foreign-affairs-mandate-letter"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "The Department of National Defence and Canadian Armed Forces (DND/CAF) Artificial Intelligence Strategy (Mar 2024)\n\n- Line of Effort 1: Fielding and Employing AI Capabilities; directs the DND/CAF to develop an internal AI Center (DCAIC), which acts as a hub of AI expertise and a catalyst for R&D, standardization, and implementation of AI in the military.\n\n- The Core Principles state that DND/CAF will deploy AI to augment and not replace human action and decision-making.\n\n- Line of Effort 4: Talent and Training; directs DND/CAF to review the workforce needs for AI, identify priorities for AI training and appropriate curricula, and identify processes for recruiting talent.",
            "url": "https://hkifoa.com/wp-content/uploads/2024/11/ai-strategy-cananda-defense.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Minister of Defence Blair Keynote at the Ottawa Conference on Security and Defence (Mar 2024)\n\n- Minister Blair formally announces the DND/CAF Artificial Intelligence Strategy and emphasizes the need for Canada to responsibly harness emerging technologies such as AI. He states that the goal for Canadian defese is to become \"AI-enabled\" by 2030, claiming that the Strategy will guide the adoption of AI throughout the Defence Ministry.",
            "url": "https://www.canada.ca/en/department-national-defence/news/2024/03/keynote-address-by-minister-of-national-defence-bill-blair-to-the-cda-institute-ottawa-conference-on-security-and-defence.html"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [
          {
            "text": "Directive on Automated Decision-Making (ADM) (Apr 2019)\n\n- This directive applies to the Department of National Defence (DND) and is a policy that federal departments that use automated systems must adhere to. It centers around an Algorithmic Impact Assessment (AIA) that classifies the system's level of impact and drives safeguard requirement and compliance.",
            "url": "https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32592"
          }
        ],
        "policy_documents": [
          {
            "text": "The Department of National Defence and Canadian Armed Forces (DND/CAF) Artificial Intelligence Strategy (Mar 2024)\n\n- Line of Effort 3: Ethics, Safety, and Trust; commits to developing ethics principles and frameworks. The strategy plans to incorporate both internal and external partners in developing ethical use of AI in the military.",
            "url": "https://hkifoa.com/wp-content/uploads/2024/11/ai-strategy-cananda-defense.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Minister of National Defence Remarks at the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- Canada commits to developing a framework for the responsible use of AI in military contexts while addressing the challenges of unintended bias, and implementing such technologies in accordance with applicable laws, policies, and IHL.",
            "url": "https://www.canada.ca/en/department-national-defence/news/2024/09/minister-of-national-defence-remarks-at-the-responsible-ai-in-the-military-domain-reaim-summit-2024.html?utm_source=chatgpt.com"
          },
          {
            "text": "Canada's Stance in the Responsible Artificial Intelligence in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- Canada supports the 'blueprint' for ethical and human-centric use of AI in the military, which emphasizes the importance of compliance with international law, human oversight, and risk assessment.",
            "url": "https://www.asiapacific.ca/publication/us-china-competition-looms-large-seoul-summit-use-ai?utm_source=chatgpt.com"
          },
          {
            "text": "US DoS Political Declaration on Responsible Use of Artificial Intelligence and Autonomy (Nov 2024)\n\n- Canada signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.https://www.state.gov/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy-2/.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "The Department of National Defence and Canadian Armed Forces (DND/CAF) Artificial Intelligence Strategy (Mar 2024)\n\n- Line of Effort 5: Partnerships; addresses the need for cooperation and collaboration with trusted partners and allies. There are foci on secure data infrastructure sharing with partners, and a need for collaboration with the civilian industry to further develop capabilities.",
            "url": "https://hkifoa.com/wp-content/uploads/2024/11/ai-strategy-cananda-defense.pdf"
          }
        ],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "The Department of National Defence and Canadian Armed Forces (DND/CAF) Artificial Intelligence Strategy (Mar 2024)\n\n- Line of Effort 3: Ethics, Safety, and Trust; the DND/CAF plan to conduct AI maturity assessments and develop metrics, supporting mechanisms, and governance to align resources and goals.\n\n- The DND/CAF state that they will implement any military-use AI in accordance with applicable laws, policies, and guidelines.",
            "url": "https://hkifoa.com/wp-content/uploads/2024/11/ai-strategy-cananda-defense.pdf"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\n- Canada's formal submission to the United Nations (UNGA 78/241) states Canada conducts national legal reviews of new weapons to ensure compliance with International Humanitarian Law (IHL) throughout the lifecycle of the weapon. It states that LAWS that cannot be used in compliance with IHL are prohibited, and emerging weapons in the realm of LAWS must maintain appropriate human involvement.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Canada-EN.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": []
      }
    },
    "Japan": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Guideline for Responsible AI Application in Research and Development of AI-Equipped Defense Systems (June 2025)\n\n- This document states that autonomous weapons that operate completely outside of human involvement should be prohibited.",
            "url": "https://www.mod.go.jp/atla/soubiseisaku/ai_guideline/ai_guideline_ver.01_eng_202506.pdf"
          },
          {
            "text": "Working Paper Submitted by Japan to the UN on Emerging Technologies in the Area of Lethal Autonomous Weapon Systems (May 2024)\n\n- Japan explicitly states that it will \"not conduct research, development, or operation of weapon systems whose use is not permitted under domestic or international law, including International Humanitarian Law (IHL).\"\n\n- Japan reiterates that it does not intend to develop autonomous systems with lethal force that operate completely without human involvement and those with autonomous functions must have the ability to attribute responsibility to humans.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Japan-rev-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Japan voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Japan voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Defense of Japan White Paper (2025)\n\n- A defense target for the MOD is accelerated decision-making through the use of AI and an overall push toward enhanced capabilities through unmanned assets in the aerial, land, and maritime domains.\n\n- This white paper is an annual publication that builds upon previous versions and outlines Japan's assessment of the current national security environment and plans to bolster the Self-Defense Force (SDF).\n\n- Previous DOJ documents include goals of improving AI-enabled intelligence functions, unmanned asset control, and automatic identification systems.",
            "url": "https://www.mod.go.jp/j/press/wp/wp2025/pdf/DOJ2025_EN_Full.pdf"
          },
          {
            "text": "Defense Buildup Program (Dec 2022)\n\n- This document presents Japan's plans to bolster its defense capabilities and mentions the Defense Intelligence Headquarters' (DIH) responsibility of developing \"automatic collection and analysis of open-source information using artificial intelligence.\" Use cases examples include social networking site information collection, authenticity analysis of international communication, and forecasting functions for security situation estimates.",
            "url": "https://www.mod.go.jp/j/policy/agenda/guideline/plan/pdf/program_en.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "National Defense Strategy (2022)\n\n- The strategy emphasizes the relevance and impact of AI on security, and commits to strengthening \"unmanned defense capabilities\" through early production and deployment or leasing by FY2027.\n\n- Japan commits to further materializing unmanned assets and reinforcing \"the ability to simultaneously control multiple unmanned assets using systems such as AI\".",
            "url": "https://japan.kantei.go.jp/content/000120033.pdf"
          },
          {
            "text": "Ministry of Defense Basic Policy on Promoting the Utilization of AI (Jul 2024)\n\n- The MOD identifies seven fields in which to focus AI applications: detection and identification of targets, intelligence collection and analysis, command and control, logistics support operations, unmanned assets, cyber security, efficient administrative works.\n\n- The policy indicates that AI is applied to support human decision-making, not replace it.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Japan-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Japan Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- Japan supports the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://asianews.network/seoul-summit-charts-framework-on-responsible-ai-military-use/"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Defense Strategy (2022)\n\n- Section: Immediate Objectives; outlines procurement priorities for advanced standoff missiles, wide area defense capabilities, and an enhanced ability to simultaneously control unmanned assets.",
            "url": "https://japan.kantei.go.jp/content/000120033.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Automated Asset Procurement (Aug 2024)\n\n- Japan's MOD announces a budget allocation for an Aisurveillance system for military base security, as well as the procurement of unmanned drones and three \"highly-automated air defense warships\" that require \"less than half the cew o current ships\".",
            "url": "https://www.reuters.com/world/japan/japans-military-spend-ai-automation-perks-combat-recruitment-crisis-2024-08-30/?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [
          {
            "text": "Guideline for Responsible AI Application in Research and Development of AI-Equipped Defense Systems (June 2025)\n\n- This document presents classification definitions of AI-equipped systems, as well as the compliance measures that autonomous or AI-enabled weapons systems must meet.\n\n- Each requirement outlined in the document provides \"confirmation item\" questions to ensure that the compliance measures are met.",
            "url": "https://www.mod.go.jp/atla/soubiseisaku/ai_guideline/ai_guideline_ver.01_eng_202506.pdf"
          }
        ],
        "policy_documents": [
          {
            "text": "Working Paper Submitted by Japan to the UN on AI in the Military Domain and its Implications for International Peace and Security (Apr 2025)\n\n- The Japanese MOD commits reducing the risks posed by AI, implementing the following concepts: human-centric, safety, fairness, privacy protection, ensuring security, transparency, and accountability.\n\n- Japan views AI as having the potential to bring benefits to the military domain, such as improvements in precision, accuracy and efficiency, enhanced situational awareness, rapid information analysis, reduction of human errors, etc.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Japan-rev-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Japan signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians.\n\n- Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Japan voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US-Japan Joint Agreement for AI UAS Research (Dec 2023)\n\n- The US and Japan sign an agreement to conduct joint research on \"Overwhelming Response Through Collaborative Autonomy\".\n\n- This inititative aims to \"revolutionize airborne combat by merging state-of-the-art AI and machine learning with advanced unmanned air vehicles\".\n\n- The research is to be implemented in UAVs operating alongside Japan's next fighter aircraft.",
            "url": "https://www.af.mil/News/Article-Display/Article/3624158/japan-mod-us-dod-sign-joint-agreement-for-ai-uas-research/"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [
          {
            "text": "Guideline for Responsible AI Application in Research and Development of AI-Equipped Defense Systems (June 2025)\n\n- This document provides a comprehensive set of mandatory guidelines for the legal/policy requirements and the technical requirements necessary for AI systems to be developed and used by the defense forces.",
            "url": "https://www.mod.go.jp/atla/soubiseisaku/ai_guideline/ai_guideline_ver.01_eng_202506.pdf"
          }
        ],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Belgium": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [
          {
            "text": "Belgium Ban on Killer Robots (Jul 2018)\n\n- The Begian Parliament voted and passed a resolution to ban \"killer robots,\" calling on the Belgian government to forbid the development and use of lethal autonomous weapons ad to work toward an international treaty to ban such weapons.",
            "url": "https://paxforpeace.nl/news/belgium-votes-to-ban-killer-robots/?utm_source=chatgpt.com"
          }
        ],
        "policy_documents": [
          {
            "text": "Contribution by Belgium on Addresing the Challenges Posed by Lethal Autonomous Weapons Systems (Dec 2022)\n\n- Belgium supports internationally agreed limits on Lethal Autonomous Weapons Systems (LAWS) and supports the prohibition of LAWS that cannot comply with IHL, including the regulation of other types of autonomous weapons systems.\n\n- This document outlines what Belgium considers to be \"sufficient human involvement\" in the execution of a complete tageting cycle of a weapons system.",
            "url": "https://dppa.un.org/sites/default/files/belgium.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Belgium voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Belgium voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Strategic Vision 2025 Belgian Defense (Jul 2025)\n\n- The Vision includes AI, robotics, and autonomous systems as key innovation drivers for the defense sector.\n\n- The Belgian Defense Ministry is investing in capabilities such as AI-integrated systems, smart logistics, and autonomous resupply.",
            "url": "https://inno4def.be/strategic-vision-2025/?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Belgium signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians.\n\n- Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Belgium voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Egypt": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Egypt's Views on Lethal Autonomous Weapons Systems Resolution A/78/241 (May 2024)\n\n- Egypt supports a two-tiered approach to regulating Lethal Autonomous Weapons Systems (LAWS), combining a prohibition of fully autonomous weapons and the regulation of other military applications of AI.\n\n- Egypt views human responsibility as central to the discussion on autonomy in weapons systems, stating that \"regardless of the type of weapon systems that deliver the force, delegating the decisions to take a human life to machines is unethical and represents a grave violation of IHL\".",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Egypt-EN.pdf"
          },
          {
            "text": "Egypt National Statement at the Vienna Conference: Humanity at the Crossroads \"Autonomous Weapons Systems and the Challenge of Regulation\" (Apr 2024)\n\n- This document reitarates Egypt's position that the two-tiered approach is most effective in regulating autonomous weapons systems.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Egypt_National_Statement.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Egypt voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Egypt voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Egypt voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Poland": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Republic of Poland Contribution to the GGE on Normative and Operational Framework on Emerging Technologies in the Area of Lethal Autonomous Weapons Systems (LAWS) (Apr 2021)\n\n- Poland emphasizes the principles of distinction, proportionality, and precaution in attack in regard to LAWS.\n\n- State authorities will keep humans accountable and in control of the use of LAWS regardless of the degree of autonomy.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_%282021%29/GGE_LAWS_-_June_2021_-_Poland_-_written_contribution.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Working Paper to the Convention on Certain Conventional Weapons (CCW) GGE on LAWS (Mar 2018)\n\n- Poland outlines specific examples of weapons systems that would be deemed unlawful under IHL, including those that are indiscriminate and those that disproportionately cause more harm than the intended objective.\n\n- However, Poland is not averse to the use of lethal autonomous weapons in combat and holds that the context in which LAWS are used is an important consideration.",
            "url": "https://www.reachingcriticalwill.org/images/documents/Disarmament-fora/ccw/2018/gge/documents/GGE.1-WP3.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Poland abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Poland voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Policy for the Development of Artificial Intelligence in Poland From 2020 (Dec 2020)\n\n- While this policy document does not cover activities in the areas of national security and defence, it \"assumes the cooperation of the civilian sector with the military sector in all areas considered useful for the needs of national defence in accordance with the priorities set out in the National Security Strategy of the Republic of Poland\".\n\n- This signals an open posture to innovation and a desire to take advantage of civilian-military colaboration.",
            "url": "https://wp.oecd.ai/app/uploads/2021/12/Poland_Policy_for_Artificial_Intelligence_Development_in_Poland_from_2020_2020.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Ministry's Artificial Intelligence Strategy Until 2039 (Aug 2024)\n\n- The document is explicit in the future use of AI systems in military operations: autonomous combat systems that can operate without direct human intervention or support human actions, intelligence and reconnaissance analysis, logistics optimization, cyberspace defense, simulation and training, decision support, and training data analysis.\n\n- The Polish Armed Forces is directed to create conditions to ensure accountability of decisions, balance the risks and possible benefits at an acceptable level, and minimize bias and unpredictable behavior of AI systems used.\n\n- The strategy defines human-machine teaming as the default approach to implementing AI in the Ministry of Defense.\n\n- The MOD plans to create defined pathways for AI-trained staff, with specific plans for recruitment and retention, as well as plans to establish a strategy and processes for data utilization and verification.\n\n- The Polish MOD will also implement a force restructuring to include dedicated AI units and centers.",
            "url": "https://www.gov.pl/web/obrona-narodowa/resortowa-strategia-sztucznej-inteligencji-do-roku-2039?utm_source=chatgpt.com"
          },
          {
            "text": "Poland's Contribution to the Reflection on Opportunities and Challenges Posed to International Peace and Security by AI in the Military Domain (Mar 2025)\n\n- Poland advocates for AI applications in the military domain to be human-centric, accountable, safe, secure, and trustworthy, and sees compliance with IHL is seen as a \"crucial aspect\".",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_(2025)/79-239-Poland-EN.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Deputy Prime Minister and Minister of National Defense, Secretary of State Briefing on the Implementation of AI in the Polish Armed Forces (Mar 2025)\n\n- The ministers announce the establishment of an Artificial Intelligence Implementation Center within the Cyberspace Defense Forces Component Command.\n\n- The briefing covers the goals of scaling AI rapidly and delivering timely AI projects \"to ensure strategic advantage\".\n\n- Operational activities expected to implement AI are: cyber defense support, intelligence and reconnaissance analysis, modernizing autonomous combat systems, decision-making support, and logistics optimization.",
            "url": "https://www.wojsko-polskie.pl/articles/tym-zyjemy-v/2025-03-045-nowe-kompetencje-i-mozliwosci-dla-wojsk-obrony-cyberprzestrzeni/?utm_source=chatgpt.com"
          },
          {
            "text": "President Statement at UN Security Council Debate on AI (Sep 2025)\n\n- President Karol Nawrocki supports the development of AI in the security and defense sectors that is \"based on transparent principles, consistent with human ethics and international regulations\".",
            "url": "https://www.prezydent.pl/aktualnosci/wizyty-zagraniczne/debata-rady-bezpieczenstwa-onz-ws-sztucznej-inteligencji,107789"
          },
          {
            "text": "Drone Revolution Conference with Secretary of State of the Ministry of National Defense (Jul 2025)\n\n- Secretary Cezary Tomczyk announced the signing of agreements to \"develop technical solutions, tactics, and procedures for the use of drones for the Polish Army\".\n\n- The announcement includes the involvement of the Cyberspace Defense Forces Component Command in ensuring security measures for UAV control software and the implementation of AI.",
            "url": "https://www.swiatdronow.pl/cezary-tomczyk-mon-dzis-zaczyna-sie-rewolucja-dronowa-w-polskich-silach-zbrojnych-konferencja-22-07-2025-r?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Poland voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Poland signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Poland endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Italy": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by Italy to the CCW GGE on Lethal Autonomous Weapons Systems (LAWS) (Mar 2019)\n\n- Ambassador Giancarto Incarnato states that the decision to use lethal force and to produce lethal effects should remain in human hands to guarantee accountability in the case of IHL violations and because only human judgement can adequately assess the application of IHL principles.\n\n- The document states that for Italy, human operators are responsible for the validation of selection of objectives and for the \"activation/deactivation of the autonomous mode of the relevant system\".",
            "url": "https://italiarappdisarmo.esteri.it/wp-content/uploads/2024/02/IURMIMD.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Italy's Contribution Pursuant to United Nations General Assembly (UNGA) Resolution 78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\n- Italy supports the creation of a new legally binding instrument to prohibit the development and use of LAWS.\n\n- Italy supports the \"two-tier\" approach to regulating LAWS, which includes an outright prohibition of LAWS that cannot comply with IHL and a regulation of other \"systems featuring decision-making autonomy in critical functions\".\n\n- This document reiterates the criticality of human responsibility and command and control of autonomous weapons systems.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Italy-EN.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Italy voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Italy voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Report Regarding UNGA Resolution 79/239 \"Artificial Intelligence in the Military Domain and its Implications for International Peace and Security\" (2025)\n\n- Italy reiterates support for various multilateral functions that further the adoption of safe and responsible use of AI in the military.\n\n- This report includes Italy's support for an instrument with a clear set of prohibitions and regulations to be adopted as an Additional Protocol to the CCW, emphasizing the role of human control and responsibility.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Italy-en.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Act of Guidance for the Launch of the Integrated Cycle of Performance Programming and Budget Formation for the 2024 Financial Year and the 2025-2026 Multi-Annual Programming (2023)\n\n- Section 2.18 lists artificial intelligence as a field in which the military will direct, guide, and control technological research.\n\n- Section 3.6 suggests activities to bolster training systems and modules that \"combine traditional resources with innovative methodologies and \"narrow artificial intelligence\" algorithms.",
            "url": "https://www.difesa.it/assets/allegati/26763/atto_di_indirizzo_ed._2023_-_final.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Multi-Annual Programming Document 2025-2027 (2025)\n\n- This annual document highlights artificial intelligence as an emerging disruptive technology which the Italian military intends to develop.\n\n- Data infrastructure is listed as a top priority to invest into, including artificial intelligence.\n\n- Previous versions of the document also address the need to focus on AI for various functions within the military, such as predictive analysis and decision support.",
            "url": "https://www.difesa.it/assets/allegati/3756/documento_programmatico_pluriennale_2025-2027_pdfa.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Under Secretary of Defense on the Challenges and Opportunities of Advanced Technologies (Dec 2025)\n\n- Under Secretary of Defense Isabella Rauti hints at Italy's plan for adopting AI in the military in predictive analysis, decision-making, and support of the chain of command and control.\n\n- She states that humans must always validate and verify the output of artificial intelligence.",
            "url": "https://www.fortuneita.com/2025/12/03/difesa-il-sottosegretario-rauti-la-mutua-assistenza-e-fondamento-di-ogni-strategia/"
          },
          {
            "text": "Defense Minister on AI as a Government Priority (Mar 2024)\n\n- Defense Minister Guido Crosetto states that AI is a priority for the Italian givernment in countering misuse by organizations with hostile objectives, and positions Italy as supporting full human control \"without compromising development opportunities\".",
            "url": "https://www.ansa.it/ansacom/notizie/economia/cybersec/2024/02/29/crosetto-intelligenza-artificiale-priorita-del-governo_d1f2244c-3539-4c3c-b32e-fefe4aa5f566.html"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Italy voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Italy signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Italy endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Algeria": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by Algeria at the 77th Session of the UNGA First Committee Thematic Discussion (Oct 2022)\n\n- Algeria supports the creation of a new legally binding instrument on Lethal Autonomous Weapons Systems (LAWS) \"for addressing the humanitarian and international security challenges posed by the emerging technologies in the area of LAWS\".",
            "url": "https://reachingcriticalwill.org/images/documents/Disarmament-fora/1com/1com22/statements/21Oct_Algeria.pdf"
          },
          {
            "text": "Algeria Statement at the First UNGA Meeting on Autonomous Weapons Systems (May 2025)\n\n- Algeria states that autonomous weapons systems \"fundamentally challenge the right to life by removing human judgement from lethal force decisions,\" which continues its stance on restricting such weapons.",
            "url": "https://www.hrw.org/news/2025/05/21/un-start-talks-treaty-ban-killer-robots"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Algeria voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Algeria voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Algeria voted in support of this resolution, which calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Armenia": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by the Delegation of Armenia at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems and the Challenge of Regulation\" (Apr 2024)\n\n- Armenia supports the creation of a new legally binding instrument and regulatory mechanism for addressing challenges posed by autonomoous weapons systems.\n\n- The document goes further and calls for joint efforts to be directed toward developing legal and ethical standards and accountability mechanisms for artificial intelligence, lethal autonomous weapons, and drones technologies.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Armenia_National_Statement.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Armenia voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Armenia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Armenia endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with International Humanitarian Law (IHL), and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by the Delegation of Armenia to the OSCE on Responsible Military Use of New and Emerging Technologies (Feb 2025)\n\n- Armenia states that human responsibility and accountability in autonomous weapons are essential.",
            "url": "https://www.osce.org/sites/default/files/f/documents/7/6/586737.pdf"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Armenia voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Armenia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Colombia": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Colombia and Other Countries for the UN Secretary General Report on Resolution 78/241 (May 2023)\n\n- Colombia expresses its joint views on lethal autonomous weapons systems by stating support for a legally binding instrument through a Draft Protocol VI to prohibit certain uses of Lethal Autonomous Weapons Systems (LAWS) and regulate other forms of autonomous weapons.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-G14__Draft_Protocol_VI-EN.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Colombia voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Colombia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "BelÃ©n CommuniquÃ© (Feb 2023)\n\n- Colombia adopted this joint communiquÃ© along with 32 other Latin American and Caribbean countries, which calls for the urgent negotiation of a binding international treaty to prohibit and regulate LAWS. The document is grounded in the concept of meaningful human control and international humanitarian law (IHL).",
            "url": "https://www.rree.go.cr/files/includes/files.php?id=2261&tipo=documentos"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "CONPES 4144 Natinonal Artificial Intelligence Policy 2025-2030 (Feb 2025)\n\n- This document is a whole-of-government strategy and applies to all state entities, including the Ministry of Defense, and explicitly includes national security and defense as key mission sectors requiring AI governance, capability development, and responsible use.\n\n- The strategy establishes mandatory governance structures for AI projects, requiring risk assessment, transparency measures, algorithmic accountability, and security-by-design for all systems.\n\n- The following are seen as national security missions in which AI is a critical enabler: threat detection, cyber-defense, criminal intelligence, border surveillance, and critical infrastucture protection.",
            "url": "https://colaboracion.dnp.gov.co/CDT/Conpes/Econ%C3%B3micos/4144.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Policy for Science, Technology and Innovation for the Defense and Security Sector (2024)\n\n- The Ministry of Defense establishes military intelligence modernization, cyberdefense and security, border and territorial defense, interoperable defense innovation ecosystems as high priority areas in which AI is central.\n\n- The document signals an acceleration of innovation and implementation of AI throughout various defense functions, such as workforce development, intelligence, and logistics.",
            "url": "https://www.trade.gov/market-intelligence/colombia-defense-and-security-innovation-initiative"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Colombia voted in support of this resolution, which calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Netherlands": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Kingdom of the Netherlands Submission in Accordance with Resolution 78/241 on Autonomous Weapons Systems (May 2024)\n\n- The Netherlands states that autonomous weapons systems that cannot be designed, developed, or used in accordance with international law and International Humanitarian Law (IHL) should be prohibited through a legally binding instrument.\n\n- The document presents the Netherlands' definition of what constitutes an autonomous weapon system and what conditions warrant a prohibition of a certain system.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Netherlands-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- The Netherlands voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- The Netherlands voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Kingdom of the Netherlands National Contribution to the UN Secretary General Report on Resolution 79/239 (Apr 2025)\n\n- The Netherlands recognizes the potential benefits of AI in the military domain, such as better insight, improved connectivity, enhanced civilian protection, and reduced risks in operations.\n\n- The document states the Netherlands' view that human control should be context-dependent, R&D efforts must implement testing, evaluation, verification and validation (TEVV) procedures, and that international governance should be \"flexible, inclusive, and realistic\".",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79_239-Netherlands-EN.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Defence White Paper 2024 (Sep 2024)\n\n- Section 3.5 Digital Transformation; sets a goal of harnessing the potential of AI, data analysis, and data use for operational readiness and deployment.\n\n- This signals a data-centric focus on AI applications in the military.",
            "url": "https://english.defensie.nl/downloads/publications/2024/09/05/defence-white-paper-2024"
          },
          {
            "text": "Letter From the Ministers of Foreign Affairs and of Defense (Jun 2023)\n\n- This letter states the Netherlands' intent to \"fund several regional training courses on the military use of AI\".\n\n- The Netherlands holds that autonomous weapons that cannot comply with IHL must be banned through an international legal framework.",
            "url": "https://zoek.officielebekendmakingen.nl/kst-33694-68.html?utm_source=chatgpt.com"
          },
          {
            "text": "Defence White Paper 2022 (Jul 2022)\n\n- This document states the Dutch Army's plan to commit joint investments with commercial partners to develop \"autonomous systems, robots and other forms of advanced combat technology in order to ensure that\u2026automation is optimised\".",
            "url": "https://english.defensie.nl/downloads/publications/2022/07/19/defence-white-paper-2022"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Cabinet's Response to Advisory Report \"Autonomous Weapon Systems: The Importance of Regulation and Investment\" (Jun 2022)\n\n- The document fully adopts the pursuit of a ban on fully autonomous weapon systems with the goal of preserving human judgement when deploying a weapon system.\n\n- The Dutch government's position on meaningful human control \"concerns the human capacity for judgement in the deployment of a weapon system\" and surrounds the ability to assess and apply principles of international law and IHL.",
            "url": "https://www.tweedekamer.nl/kamerstukken/brieven_regering/detail?did=2022D25679&id=2022Z12434&utm"
          }
        ],
        "public_statements": [
          {
            "text": "The Netherlands' Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- The Netherlands co-led the resolution (with South Korea and Singapore) on the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- The Netherlands voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- The Netherlands signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Cabinet's Response to Advisory Report \"Autonomous Weapon Systems: The Importance of Regulation and Investment\" (Jun 2022)\n\n- The document states that the Netherlands will make contributions to the NATO Science & Technology Organisation (STO) Joint Work Programme to help develop technologies in the areas of AI and autonomous weapons.\n\n- The Netherlands supports interoperability and standardization particularly in the field of partially autonomous systems.",
            "url": "https://www.tweedekamer.nl/kamerstukken/brieven_regering/detail?did=2022D25679&id=2022Z12434&utm"
          },
          {
            "text": "Adoption of the Budget Statements of the Ministry of Defence for the Year 2022 (Jun 2022)\n\n- Recommendation 8 calls for a framework that makes explainable AI the starting point for Dutch policy on the development, acquisition, and use of partially autonomous weapon systems.\n\n- The section recommends a clear accountability of human responsibility throughout the entire decision-making chain.",
            "url": "https://zoek.officielebekendmakingen.nl/kst-35925-X-90.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- The Netherlands endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Spain": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Spain's Submission to the UNGA Resolution 78/241 on Lethal Autonomous Weapons Systems (May 2024)\n\n- Spain supports a two-tier approach to regulating Lethal Autonomous Weapons Systems (LAWS), combining a prohibition of autonomous weapons that cannot be developed or used in compliance with IHL and a regulation of all other autonomous weapons.\n\n- The document reiterates Spain's commitment to clear human oversight and accountability in regards to artificial intelligence in the military.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Spain-SP.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Spain voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Spain voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Ministry of Defense \"Military Uses of Artificial Intelligence, Automation, and Robotics\" (Jul 2020)\n\n- This document comprises military applicatiuons of AI, automation, and robotics, including operational uses, risks, and ethical/legal challenges.\n\n- Chapter 1 covers use cases of AI in the Spanish military.\n\n- Chapter 2 outlines data integration to obtain a common picture at the operational and strategic level, including applications of machine learning techniques and deep learning methodologies in various conditions.\n\n- Chapter 3 addresses threats of AI in misinformation and disinformation.\n\n- Chapter 4 outlines various use cases for AI applications in cybersecurity and defense.",
            "url": "https://emad.defensa.gob.es/Galerias/CCDC/files/USOS_MILITARES_DE_LA_INTELIGENCIA_ARTIFICIALx_LA_AUTOMATIZACION_Y_LA_ROBOTICA_xIAAxRx.-_VV.AA.pdf?utm_source=chatgpt.com"
          },
          {
            "text": "Official Bulletin of the Ministry of Defense Number 131 (Jul 2023)\n\n- This document frames AI as one of the main catalysts for digital transformation and resource optimization within the Spanish Ministry of Defense.\n\n- Spain commits to using AI to augment and not replace humans, and commits to comply with the principles of lawfulness, fairness, transparency, integrity and confidentiality, and proactive accountability.\n\n- The document outlines the strategic and operational visions for the implementation and integration of AI into the Ministry of Defense.",
            "url": "https://elconfidencialdigital.opennemas.com/media/elconfidencialdigital/files/2023/07/12/estrategia%20ia.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Joint Development of the Future Combat Air System (FCAS) (Sep 2025)\n\n- Spain is jointly developing a sixth generation aircraft with France and Germany with an interconnected defense ecosystem that is expected to heavily incorporate AI capabilities.",
            "url": "https://as.com/actualidad/politica/espana-relanza-su-estrategia-militar-de-defensa-asi-sera-el-superavion-de-combate-europeo-con-fecha-limite-2040-n/?utm_source=chatgpt.com"
          },
          {
            "text": "Spain's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- Spain endorsed the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Ministry of Defense Statement on Human Control (Jun 2023)\n\n- The Spanish Ministry of Defense states that the military use of artificial intelligence will always be under human control.\n\n- The Ministry states that AI will be extensively integrated into military activities, but states that the development of AI \"must allow for clear supervision in order to guarantee due accountabilityand the attribution of responsibilities\".\n\n- The Ministry also designates the following authorities as responsible for resolving ethical matters: Chief of Defence Staff for applications in the field of military operations; head of the State Secretariat of the National Intelligence Centre for intelligence matters; and the head of the State Secretariat for Defence for all other matters.",
            "url": "https://www.elconfidencialdigital.com/articulo/defensa/defensa-garantiza-que-uso-militar-inteligencia-artificial-tendra-siempre-control-humano/20230712171647607253.html?utm_source=chatgpt.com"
          },
          {
            "text": "Spain's Stance in the Responsible AI in the Military Domain (REAIM) Summit 2024 (Sep 2024)\n\n- Spain endorsed the 'Blueprint for Action' for ethical and human-centric use of AI in the military, which addresses the impact of AI on international peace and security, the implementation of responsible AI in the military domain, and the future governance of AI in the military domain.",
            "url": "https://www.reaim2024.kr/home/reaimeng/board/bbsDetail.do?encMenuId=4e57325766362f626e5179454e6d6e4d4a4d33507a773d3d&encBbsMngNo=366e794c7a644d756342425668444f393053755142673d3d&encBbsNo=6f784e4542386f7735767465766a6531556f4b6149413d3d&ctlPageNow=1&schKind=bbsTtlCn&schWord=%23this"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Spain voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Spain signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Spain endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          }
        ]
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Iraq": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by the Delegation of the Republic of Iraq at the United Nations General Assembly (UNGA) on Conventional Weapons (Oct 2025)\n\n- Iraq calls for legally binding provisions that are consistent with IHL and the UN Charter to regulate lethal autonomous weapons systems.",
            "url": "https://reachingcriticalwill.org/images/documents/Disarmament-fora/1com/1com24/statements/24Oct_Iraq.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Iraq voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Iraq voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "Statement at the CCW Group of Governmental Experts (GGE) on LAWS (Aug 2021)\n\n- Iraq states that the responsibility of the decision to take life and death should never be delegated to machines and that doing so is a violation of international humanitarian law.",
            "url": "https://conf.unog.ch/digitalrecordings/en/clients/61.0500/sessions/5EBAAABD-DD16-458E-A2C9-FEA476FCE99B"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Iraq voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Lithuania": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Lithuania abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Lithuania voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Lithuania's Arms Control and Nonproliferation Policy (Jun 2025)\n\n- Lithuania follows NATO's Principles of Responsible Use for artificial intelligence.\n\n- Lithuania also supports a two-tier approach to regulating autonomous weapons, combining a prohibition on weapons systems that cannot comply with International Humanitarian Law (IHL) and a regulation of other types of weapons with autonomous functions.",
            "url": "https://www.urm.lt/en/lithuania-in-the-region-and-the-world/lithuanias-security-policy/arms-control-and-nonproliferation/998"
          },
          {
            "text": "Lithuania's Submission to the UN Secretary General on Resolution 79/239 (Apr 2025)\n\n- Lithuania supports various multilateral frameworks that discuss principles and good practice on AI in the military domain.\n\n- Lithuania also sees benefits in AI applications in the defense space, and is opposed to unnecessary and excessive restrictions that hinder AI innovation.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Lithuania-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Lithuania voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Greece": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Greece Pursuant to the UN Secretary General Report on Lethal Autonomous Weapons Systems (LAWS) (May 2024)\n\n- Greece supports a two-tier approach to regulating LAWS and advocates that military AI must fully comply IHL.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Greece-EN.pdf"
          },
          {
            "text": "Statement by Greece to the Group of Governmental Experts (GGE) on LAWS (Mar 2019)\n\n- Greece states that it is \"important that commanders and operators will remain on the loop of the decision-making process in order to apply the appropriate human judgement over the use of force\".\n\n- The document provides Greece's definition of a fully autonomous weapon system, and calls for the testing of critical functions in highly autonomous systems during development stage.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-_Group_of_Governmental_Experts_%282019%29/GGE%2BLAWS%2BSTATEMENT%2Bby%2BGREECE-%2BChallenges%2Bto%2BIHL.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Greece voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Greece voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Greece's Contribution to the UN Secretary General on Resolution 79/239 (2025)\n\n- This document frames Greece's efforts to implement and lead in safe and responsible use of AI in the military and defense.\n\n- Greece addresses the challenges that arise from applying AI in military contexts and commits to continued engagement in developing international standards.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Greece-en.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Prime Minister Speech at a UN Security Council Event (Sep 2025)\n\n- Prime Minister Kyriakos Mitsotakis aligns Greece with various multilateral frameworks on the safe and responsible use of AI in the military domain and commits Greece to always implementing human oversight in the development and use of AI for military use.",
            "url": "https://www.primeminister.gr/en/2025/09/25/37026?utm_source=chatgpt.com"
          },
          {
            "text": "Minister of National Defence Inauguration of International Defence Exhibition (May 2025)\n\n- Minister of Defense Nikos Dendias states that Greece \"pursues a presence in the developments in crucial area, in artificial intelligence, in unmanned autonomous systems, cyber operations, and space applications\".",
            "url": "https://www.mod.mil.gr/en/the-minister-of-national-defence-nikos-dendias-inaugurates-the-international/?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Hellenic Centre for Defence Innovation (HCDI) Call for Proposals (Mar 2025)\n\n- The HCDI, the contracting authority for defense and security programs, called for the development of \"dual-mode multi-configuration Unmanned Surface Vehicles, capable of operating with autonomous or semi-autonomous navigation\" among other military capabilities.",
            "url": "https://www.elkak.gr/en/hcdi-issues-calls-proposals-unmanned-systems-and-command-control-and-information-systems?utm_source=chatgpt.com"
          }
        ]
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Greece endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Greece signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Greece voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Sweden": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Swedish Input to the Report of the UN Secretary General on Resolution 78/241 on Lethal Autonomous Weapons Systems (LAWS) (May 2024)\n\n- Sweden supports the two-tier approach to regulating LAWS; prohibiting those systems which cannot comply with international law and IHL and regulating other systems which contain some form of autonomous function.\n\n- The document states that human responsibility for decisions must be retained and that preserving meaningful human control over the use of force is a key objective, included throughout the entire lifecycle of a weapon system.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Sweden-EN.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Sweden voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Sweden voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Speech by Minister for Defence at Annual National Conference (Jan 2024)\n\n- Minister for Defence Pal Jonson states that Sweden must strengthen its defense capabilities, including through the use of unmanned systems in all areas and \"AI technology for planning and decision support\".",
            "url": "https://www.government.se/speeches/2024/01/speech-by-minister-for-defence-pal-jonson-at-folk-och-forsvars-annual-national-conference-in-salen-on-the-8th-of-january-2024/?utm"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Sweden endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Sweden signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Sweden's Stance in the Responsible Artificial Intelligence in the Military Domain (Responsible AI in the Military Domain (REAIM)) Summit 2024 (Sep 2024)\n\n- Sweden supports the 'blueprint' for ethical and human-centric use of AI in the military, which emphasizes the importance of compliance with international law, human oversight, and risk assessment.",
            "url": "https://www.asiapacific.ca/publication/us-china-competition-looms-large-seoul-summit-use-ai?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Sweden voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Latvia": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by Latvia at the Thmatic Debate on Conventional Weapons at the UNGA (Oct 2024)\n\n- Latvia reiterates the need for human control and responsibility in the development and use of Lethal Autonomous Weapons Systems (LAWS), and states that the GGE on LAWS is the most appropriate forum for continued discussion on regulating such weapons.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/Statement_by_Latvia.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Latvia abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Latvia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Guidelines for the Involvement of the Defence and Security Industry in Strengthening Defence Capabilities (2025)\n\n- This document outlines the targeted investments in innovation, technology development, and R&D for the period 2025-2028 in: Robotics and Autonomous Systems for the purposes of ISR, target identification, communications, kinetic effects, and logistics; AI and Machine Learning in processing data, supporting decision-making, and cyber defense.\n\n- Latvia commits near term research efforts to focus on unmanned systems, artificial intelligence, and electronic warfare.",
            "url": "https://www.mod.gov.lv/sites/mod/files/document/Guidelines%20For%20The%20Involvement%20Of%20The%20Defence%20And%20Security%20Industry%20In%20Strengthening%20Defence%20Capabilities.pdf"
          },
          {
            "text": "Long-Term Development of the National Armed Forces 2025-2036 White Paper (Mar 2025)\n\n- This white paper sets the long term strategic goals for the National Armed Forces, including autonomous systems, machine learning, and artificial intelligence as key R&D priorities and capability development objectives for the defense sector.",
            "url": "https://www.mod.gov.lv/sites/mod/files/document/LONG-TERM%20DEVELOPMENT%20OF%20NAF.pdf"
          },
          {
            "text": "Defence Industry and Innovation Strategy 2025-2036 (2025)\n\n- This document addresses Latvia's relevant defense technology priorities for the next decade.\n\n- Robotics, remotely controlled and autonomous systems are a development priority for use cases in unmanned aerial vehicles, remotely-controlled land vehicles, drone boats and underwater drones for ISR, target location, signal transmission, kinetic effects, and logistical support.\n\n- Artificial intelligence and machine learning are another priority for use cases such as data processing, information landscape monitoring, and autonomous decission-making.",
            "url": "https://www.mod.gov.lv/sites/mod/files/document/Atbalsta_strate%CC%84g%CC%A7ija_ENG.pdf"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Latvia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "Latvia's Stance in the Responsible Artificial Intelligence in the Military Domain (Responsible AI in the Military Domain (REAIM)) Summit 2024 (Sep 2024)\n\n- Latvia supports the 'blueprint' for ethical and human-centric use of AI in the military, which emphasizes the importance of compliance with international law, human oversight, and risk assessment.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/Statement_by_Latvia.pdf"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Latvia voted in support of this resolution, which calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Finland": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Finland Concerning UNGA Resolution 78/241 on Lethal Autonomous Weapons Systems (LAWS) (May 2024)\n\n- Finland pursues an international instrument that provides principles or regulations on the development and deployment of LAWS.\n\n- Humans must always retain the decision on the use of force.\n\n- Finland supports the two-tier system, which would outlaw autonomous weapons systems that operate without any form of human involvement and outside a responsible chain of command, and regulate the development and use of all other weapons with autonomous functions.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_%282024%29/78-241-Finland-EN_0.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Finland voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Finland voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Finnish Defence Forces Data and Artificial Intelligence Strategy (Nov 2025)\n\n(Disclaimer - document is not publicly available)\n\n- The strategy presents the FDF's objectives for data-centric operations: ability to lead the operations of the FDF in a data-centric manner, safe use of information, effective information exchange, creating a situational picture, automation of routine tasks, and ensuring unified information management.",
            "url": "https://puolustusvoimat.fi/-/puolustusvoimien-data-ja-tekoalystrategia-on-julkaistu?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Opening Remarks by Minister for Foreign Affairs at Helsinki Roundtable on AI and National Security (Mar 2025)\n\n- Minister Elina Valtonen frames AI as central for international security, stressing the urgency to master AI's role in defense and security while respecting International Humanitarian Law (IHL) and international law.",
            "url": "https://valtioneuvosto.fi/en/-/opening-remarks-by-minister-elina-valtonen-at-the-helsinki-roundtable-on-ai-and-international-security?utm_source=chatgpt.com"
          },
          {
            "text": "Finnish Defence Forces Press Release on Indigenous AI Development (Oct 2025)\n\n- The Finnish Defence Forces (FDF) will begin to cooperate with NestAI, a Finnish AI group, to accelerate the development of AI capabilities.\n\n- Finland pursues a data-centric approach to \"enhance operational processes and analytics-supported decision-making\".\n\n- The FDF also intends to establish the AI Agency Centre of Excellence in 2026, which will \"bring together expertise, development capacity and cooperation networks to apply AI to FDF needs.\".\n\n- NestAI is one of many private sector companies the FDF currently does or plans to engage with to develop AI capabilities.",
            "url": "https://puolustusvoimat.fi/en/-/finnish-defence-forces-to-accelerate-indigenous-ai-development-with-nestai?utm_source=chatgpt.com"
          },
          {
            "text": "Press Release on Joining Political Declaration on Responsible Military Use of Artificial Intelligence in the Military Domain (Oct 2023)\n\n- Minister of Defence Antti Hakkanen approved the proposal for Finland to endorse the political declaration led by the US.\n\n- Finland views the regulation of AI and autonomous weapons as ethical matters as well as defense industry and trade policy opportunities.",
            "url": "https://valtioneuvosto.fi/en/-/236553176/finland-joins-the-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Submission by Finland Concerning UNGA Resolution 79/239 Artificial Intelligence in the Military Domain and its Implications for International Security (Apr 2025)\n\n- Finland states that it is committed to developing, deploying, and using AI capabilities in the military domain in a manner which complies with IHL and international law.\n\n- The document outlines FInland's recognition of the challenges and potential benefits of AI in the future of warfare, and emphasizes responsible development and use.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Finland-en.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Finland endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Finland signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Finland voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Denmark": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Denmark Submission to the CCW GGE on Lethal Autonomous Weapons Systems (LAWS) (Aug 2024)\n\n- Denmark supports the two-tier approach to regulating LAWS, which pushes for the prohibition of autonomous weapons that cannot comply with IHL and the regulation of all other types of weapons that operate with autonomous functions.",
            "url": "https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_%282024%29/GGE_LAWS_session_August_2024._Danish_statement._General_Statement.pdf?utm_source=chatgpt.com"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Denmark voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Denmark voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Defence Industrial Strategy of the Danish Government (Aug 2021)\n\n- Autonomous and unmanned systems are explicitly listed as areas of technological priority, focusing on drone technologies (swarm and autonomous operations) and counter-drone/counter-UAS capabilities.\n\n- The Ministry of Defence is given a priority goal of advancing digital development in artificial intelligence, particularly \"technologies and systems capable of collecting and analysing vas amounts of data.\"\n\n- Technologies of interest include those that promote the \"interplay of autonomous systems and people\".",
            "url": "https://www.fmn.dk/globalassets/fmn/dokumenter/nyheder/engelske/-national-defence-industrial-strategy-of-the-danish-government-.pdf"
          },
          {
            "text": "Danish Security and Defence Toward 2035 (Sep 2022)\n\n- Denmark views AI and autonomous systems as emerging disruptive technologies, and suggests the deployment of autonomous systems for long-reach defensive reasons, especially in Greenland.",
            "url": "https://www.fmn.dk/globalassets/fmn/dokumenter/strategi/rsa/-regeringens_security-policy-report_uk_web-.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Statement by Denmark at Arria-Formula Meeting on AI (Apr 2025)\n\n- Denmark advocates for human responsibility in the development, deployment, and use of AI in the military domain and for continued dialogue to enhance the safety and potential benefits of AI in conflict situations.",
            "url": "https://dkonunsc.dk/statements/04-04-2025-statement-by-denmark-at-arria-formula-meeting-on-ai?utm_source=chatgpt.com"
          },
          {
            "text": "Denmark's Statement at the UNSC Open Debate on the Use of AI (Sep 2025)\n\n- Denmark reiterates its commitment to safe and trustworthy AI that complies with IHL and international law, citing several use cases for military applications.",
            "url": "https://dkonunsc.dk/statements/24-09-2025-denmarks-statement-at-the-unsc-open-debate-on-the-use-of-ai?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Denmark endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Denmark signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Denmark voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Hungary": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Hunary voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Hungary voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "National Military Strategy of Hungary (Oct 2021)\n\n- The Hungarian armed forces commits to developing artificial intelligence to \"enhance soldiers' preparedness, survivability, and operational efficiency.\".\n\n- AI is also expected to be used in decision support systems with the ability to \"support operations with real-time updates across all operational domains\".",
            "url": "https://defence.hu/news/national-military-strategy-of-hungary.html"
          }
        ],
        "public_statements": [
          {
            "text": "Defense Minister at AI Summit 2024 (Sep 2024)\n\n- Minister Kristof Szalay-Bobrovniczky states that the human factor is \"indispensable\" in the use of artificial intelligence in defense.\n\n- There are also calls for cooperation between the defense industry and civilian businesses.",
            "url": "https://abouthungary.hu/news-in-brief/defense-minister-at-ai-summit-2024-human-factor-is-indispensable-in-defense"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Hungary signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Hungary voted in support of this resolution, which calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Croatia": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Croatia National Statement at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems and the Challenge of Regulation\" (Apr 2024)\n\n- Croatia advocates for the two-tier approach to regulating Lethal Autonomous Weapons Systems (LAWS), emphasizing human control over autonomous weapons systems and accountability over the use of force.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Croatia_Natioanl_Statement.pdf"
          },
          {
            "text": "Statement by Croatia at the 71st Session of General Assembly at the Thematic Discussion on Conventional Weapons (Oct 2016)\n\n- While this statement is from an earlier discussion on LAWS, Croatia emphasizes the principle of \"meaningful human control\" as pivotally important and that \"ultimate responsibility\" should remain with humans.",
            "url": "https://s3.amazonaws.com/unoda-web/wp-content/uploads/2016/10/21-Oct-Croatia-CW.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Croatia voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Croatia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Minister of Defense Statement on Investment on Security, Armed Forces, and Defense Industry (May 2025)\n\n- Minister Ivan Anusic states highlights the importance of strengthening national security, military modernization, and the domestic defense industry.\n\n- He highlights Croatia's goals of developing systems based on AI to protect critical military infrastructure and strengthen resilience to cyber threats.",
            "url": "https://www.morh.hr/en/croatia-invests-in-security-the-armed-forces-and-the-defence-industry/"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Croatia endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with International Humanitarian Law (IHL), and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Croatia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Croatia voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Morocco": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by the Kingdom of Morocco at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapons Systems and the Challenge of Regulation\" (Apr 2024)\n\n- Morocco supports an international instrument regulating the use of autonomous weapons systems and calls for continued discussion on the subject of Lethal Autonomous Weapons Systems (LAWS) through multilateral fora.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Morocco_National_Statement.pdf"
          },
          {
            "text": "Morocco's Declaration on LAWS at the Convention on Certain Conventional Weapons (CCW) (Nov 2018)\n\n- Morocco advocates for a legally binding instrument to prohibit the development and deployment of all LAWS and advocates for human control to always be present and in compliance with IHL.",
            "url": "https://reachingcriticalwill.org/images/documents/Disarmament-fora/ccw/2018/hcp-meeting/statements/22Nov_Morocco2.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Morocco voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Morocco voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Morocco Contribution \"Application of AI in the Military Domain: Opportunities and Challenges (Excluding LAWS) in a Context of International Peace and Security\" (2025)\n\n- This document explains in detail the military use case opportunities for which AI can be applied, and also acknowledges the challenges that AI can bring when used in the military domain.\n\n- This signals an awareness of the use cases of military AI as well as the ethical challenges that must be considered.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Eightieth_session_%282025%29/79-239-Morocco-EN.pdf"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Morocco signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Morocco voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Czechia": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Czechia abstained from voting on Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "UNGA Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Czechia voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by Lethal Autonomous Weapons Systems (LAWS). It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Czech Armed Forces Development Concept 2030 (Oct 2019)\n\n- This document acts as policy guidance for the Czech armed forces to be mission-ready and effective.\n\n- Czechia commits to introducing and developing robotization and artificial intelligence in CIS and CIS security.\n\n- The cyber forces are expected to implement autonomous systems and AI to align with the modernization of assets, and \"unmanned systems with a high degree of autonomous control\" will be acquired for reconnaissance forces and assets.",
            "url": "https://www.mo.gov.cz/assets/en/ministry-of-defence/basic-documents/cafdc.pdf"
          },
          {
            "text": "Czech Armed Forces Development Concept 2035 (Dec 2023)\n\n- Section 4.9 foresees the use of AI in effective communication and analytic tools for open source information gathering and deep web monitoring.\n\n- Section 6.3 expects the Czech Armed Forces to develop an experimentation capability for the development, testing, and application of emerging and disruptive technologies, with priority given to AI (among other technologies)..",
            "url": "https://www.mo.gov.cz/assets/en/ministry-of-defence/basic-documents/cafdc_2035.pdf"
          },
          {
            "text": "Czech Armed Forces Vision of Future Warfare Beyond 2040 (2024)\n\n- Czechia sees the integration of AI in \"the management of technology\" and \"soldiers' decision-making processes during planning, managing, and conducting combat operations\".\n\n- AI will be used for analyzing large amounts of data and assessing the battlefield situation, but Czechia advocates for the independent decision-making of human operators and commanders.\n\n- Artificial intelligence is also expected to be used in medical support, for use cases such as virtual reality, robotics, and bio-sensing.\n\n- Czechia views AI as a crucial asset to modernizing and enhancing its Armed Forces in all aspects.",
            "url": "https://www.mo.gov.cz/assets/en/ministry-of-defence/basic-documents/vize_2040_en_final_tisk.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "Speech by Minister of Defense at Command Meeting of the Chief of the General Staff (Feb 2025)\n\n- Minister of Defense Jana Cernochova states that artificial intelligence, robotization, automation, and autonomy will never completely replace humans and that \"there will always be an elected representative of citizens who will make decisions\".",
            "url": "https://mocr.mo.gov.cz/informacni-servis/zpravodajstvi/projev-ministryne-obrany-na-velitelskem-shromazdeni-nacelnika-generalniho-stabu-acr-256564/?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Czechia signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Czechia voted in support of this resolution, which calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Bulgaria": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Bulgaria Submission on Resolution 78/241 \"Lethal Autonomous Weapons Systems\" (May 2024)\n\n- Bulgaria supports the two-tier system to regulating Lethal Autonomous Weapons Systems (LAWS), making a distinction between autonomous weapons that operate completely outside human control and weapons with autonomous functions requiring regulation and compliance with IHL.\n\n- Human control is central to the ethical acceptability of autonomous weapons systems, and Bulgaria outlines the necessary requirements for the use of force by an autonomous weapon to be authorized.\n\n- Bulgaria is committed to the development of a set of elements for an instrument to better regulate LAWS.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Bulgaria-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Bulgaria voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Bulgaria voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Bulgaria Statement at the UN Security Council (Sep 2025)\n\n- Bulgaria reaffirms its commitment to the responsible and ethical use of AI, stressing that AI must be developed and used in accordance with IHL.\n\n- This statement presents Bulgaria's active support for the Responsible AI in the Military Domain (REAIM) Summit's Blueprint for Action and various other multilateral frameworks that discuss AI in the military domain.",
            "url": "https://www.mfa.bg/en/news/45855?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "Paris Declaration on Maintaining Human Control in AI Enabled Weapon Systems (Feb 2025)\n\n- Bulgaria endorsed this declaration, which affirms that while AI can transform military operations, it must be developed and used responsibly, fully consistent with international humanitarian law, and with humans retaining responsibility, judgement, and control over the use of force.\n\n- The declaration makes clear that autonomous systems will not be permitted to make independent life-and-death decisions, that no system may be developed or used if it cannot comply with IHL, and that continued international cooperation on this topic is essential.",
            "url": "https://www.elysee.fr/emmanuel-macron/2025/02/11/paris-declaration-on-maintaining-human-control-in-ai-enabled-weapon-systems"
          },
          {
            "text": "US DoS Political Declaration on Responsible Military Use of Artificial Intelligence & Autonomy (Nov 2024)\n\n- Bulgaria signed as an endorsing state to promote the development, deployment, and use of responsible military AI.\n\n- States must ensure responsible, lawful, and transparent development, deployment, and oversight of military AI systems\u2014through legal reviews, bias mitigation, testing, safeguards, and proper training\u2014to align with international humanitarian law and protect civilians. Endorsing states commit to implementing, publicizing, refining, and promoting these measures globally to ensure responsible and accountable military AI use.",
            "url": "https://www.state.gov/bureau-of-arms-control-deterrence-and-stability/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy?utm_source=chatgpt.com"
          },
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Bulgaria voted in support of this resolution, which calls for the application of IHL across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "Brazil": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Statement by Brazil at the Vienna Conference \"Humanity at the Crossroads: Autonomous Weapon Systems and the Challenge of Regulation\"(Apr 2024)\n\n- Brazil supports the creation of a legally binding instrument that would establish norms across the globe.",
            "url": "https://www.bmeia.gv.at/fileadmin/user_upload/Zentrale/Aussenpolitik/Abruestung/AWS_2024/Statements/Brazil_National_Statement.pdf"
          },
          {
            "text": "Brazil Submission Pursuant to Resolution 78/241 on Autonomous Weapons Systems (May 2024)\n\n- Brazil stresses the need for meaningful human control in the discussion of Lethal Autonomous Weapons Systems (LAWS), and advocates for the prohibition of autonomous weapons that cannot be: sufficiently understood, predicted, and explained by the user; be directed at a specific military objective; or cause disproportionate harm and suffering.\n\n- The document reiterates Brazil's support for a legally binding instrument and outlines the requirements demanded of the human operator of an autonomous weapon system.",
            "url": "https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-Brazil-EN.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- Brazil voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- Brazil voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          },
          {
            "text": "BelÃ©n CommuniquÃ© (Feb 2023)\n\n- Brazil adopted this joint communiquÃ© along with 32 other Latin American and Caribbean countries, which calls for the urgent negotiation of a binding international treaty to prohibit and regulate LAWS. The document is grounded in the concept of meaningful human control and international humanitarian law (IHL).",
            "url": "https://www.rree.go.cr/files/includes/files.php?id=2261&tipo=documentos"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "Brazilian Army Strategic Guidelines for Artificial Intelligence (May 2024)\n\n- This document normalizes the implementation and use of AI within the Brazilian Army, establishing the principles, guidelines, and instruments for the implementation.\n\n- Brazil emphasizes ethical principles andmoral values in the development of AI for military purposes.",
            "url": "https://www.sgex.eb.mil.br/sg8/006_outras_publicacoes/01_diretrizes/04_estado-maior_do_exercito/port_n_1318_eme_14mai2024.html?utm_source=chatgpt.com"
          }
        ],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- Brazil voted in support of this resolution, which calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "South Africa": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "South Africa Statement to the Sixth Review Conference at the CCW (Dec 2021)\n\n- South Africa supports the creation of a new legally binding instrument to regulate Lethal Autonomous Weapons Systems (LAWS).",
            "url": "https://documents.unoda.org/wp-content/uploads/2022/02/South-Africa-CCW-RevCon-General-Statement-.pdf"
          }
        ],
        "public_statements": [
          {
            "text": "UN Draft Resolution 79/L77 (Oct 2024)\n\n- South Africa voted in support of Draft Resolution L.77 on lethal autonomous weapons systems, which signals a push toward a legally binding instrument to ban such weapons. It also raises concerns about the \"negative consequences and impact of autonomous weapons systems on global security and regional and international stability,\" while stressing the \"importance of the role of humans in the use of force to ensure responsibility and accountability\".",
            "url": "https://www.stopkillerrobots.org/news/161-states-vote-against-the-machine-at-the-un-general-assembly/"
          },
          {
            "text": "United Nations General Assembly (UNGA) Resolution A/RES/78/241 \u201cLethal Autonomous Weapons Systems\u201d (Dec 2023)\n\n- South Africa voted in support of this resolution, which supports multilateral efforts to address humanitarian, legal, and ethical challenges posed by LAWS. It also stresses the urgent need to address the challenges and concerns raised by autonomous weapons systems.",
            "url": "https://digitallibrary.un.org/record/4031004?ln=en"
          }
        ]
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": [
          {
            "text": "UNGA Resolution A/RES/79/239 \u201cArtificial Intelligence in the Military Domain and its Implications for International Peace and Security\u201d (Dec 2024)\n\n- South Africa voted in support of this resolution, which calls for the application of International Humanitarian Law (IHL) across all stages of the AI lifecycle, encourages global efforts to pursue action and participate in multilateral dialogue, knowledge-sharing, and submit views on military AI.",
            "url": "https://digitallibrary.un.org/record/4070018?ln=en"
          }
        ]
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    }
  },
  "alliances": {
    "NATO": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "NATO Artificial Intelligence Strategy, Revised NATO Artificial Intelligence Strategy (Jul 2024)\n\n- NATO views autonomy in AI as an Emerging Disruptive Technology (EDT), and develops its policy in accordance with NATO\u2019s Autonomy Implementation Plan.\n\n- Principle of Responsible Use \u2013 Governability; NATO establishes a Data and Artificial Intelligence Review Board, which develops standards, assessment templates, and reviews processes to operationalize responsible AI adoption. The strategy emphasizes clear governance frameworks with appropriate levels of judgment, care, and human accountability.",
            "url": "https://www.nato.int/en/about-us/official-texts-and-resources/official-texts/2024/07/10/summary-of-natos-revised-artificial-intelligence-ai-strategy"
          }
        ],
        "public_statements": [
          {
            "text": "Washington Summit Declaration by NATO Member Heads of State and Government (Jul 2024)\n\n- The Heads of State and Government of NATO include a commitment to \"implement our revised Artificial Intelligence Strategy\u2026and further promote principles of responsible use which underpin our growth\".",
            "url": "https://www.nato.int/en/about-us/official-texts-and-resources/official-texts/2024/07/10/washington-summit-declaration?utm_source=chatgpt.com"
          },
          {
            "text": "NATO's Autonomy Implementation Plan (Oct 2022)\n\n- This plan clarifies that NATO's PRUs apply to AI-enabled autonomous systems and frames the PRUs as a baseline for trustworthiness and interoperability.",
            "url": "https://www.nato.int/en/about-us/official-texts-and-resources/official-texts/2022/10/13/summary-of-natos-autonomy-implementation-plan?utm_source=chatgpt.com"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "NATO Artificial Intelligence Strategy, Revised NATO Artificial Intelligence Strategy (Jul 2024)\n\n- The Principles of Responsible Use \u2013 Lawfulness, Responsibility; emphasize developing and using AI in accordance with international law, human rights laws, and NATO\u2019s common values.",
            "url": "https://www.nato.int/en/about-us/official-texts-and-resources/official-texts/2024/07/10/summary-of-natos-revised-artificial-intelligence-ai-strategy"
          }
        ],
        "public_statements": []
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "NATO Artificial Intelligence Strategy, Revised NATO Artificial Intelligence Strategy (Jul 2024)\n\n- Joint AI research and development initiatives among Allies, partner countries, industry, and academia are promoted to tap into collective expertise and resources. Activities are supported through programs like the Science for Peace and Security Programme and DIANA test centers.\n\n- The updated List of Outcomes states a goal of increased contributions from member states to shaping norms and standards and a growing interoperability between all AI systems throughout the Alliance.",
            "url": "https://www.nato.int/en/about-us/official-texts-and-resources/official-texts/2024/07/10/summary-of-natos-revised-artificial-intelligence-ai-strategy"
          }
        ],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "NATO Artificial Intelligence Strategy, Revised NATO Artificial Intelligence Strategy (Jul 2024)\n\n- The significance of safety concerns from emerging technologies are recognized, and the strategy mandates testing and assurances that AI capabilities can be used safely throughout the entire AI lifecycle while upholding responsible use behaviors.\n\n- The strategy proposes a 360-degree monitoring of evolving AI and data technology trends, and an Alliance-wide Testing, Evaluation, Verification & Validation (TEV&V) landscape.\n\n- Appropriate cyber defenses are mandated, with reference to stress testing, security audits, and protection against sabotage, exploitation, and malicious actors.",
            "url": "https://www.nato.int/en/about-us/official-texts-and-resources/official-texts/2024/07/10/summary-of-natos-revised-artificial-intelligence-ai-strategy"
          }
        ],
        "public_statements": []
      }
    },
    "AUKUS": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "AUKUS Trilateral Security Partnership Agreement Pillar 2 (May 2024)\n\n- A Congress report on AUKUS Pillar 2 states that the working group on Artificial Intelligence and Autonomy aims to \"improv[e] the speed and precision of decision-making processes to maintain a capability edge and defend against AI-enabled threats.\u201d.",
            "url": "https://www.congress.gov/crs-product/R47599"
          }
        ],
        "public_statements": [
          {
            "text": "AUKUS Trilateral Security Partnership Agreement Joint Statement (Sep 2024)\n\n- A joint statement by the Secretaries and Defense Ministers of the AUKUS partnership states a demonstrated ability to use AI technologies to \"enhance decision making and bolster combined military effects,\" to include trilateral AI algorithms to find and fix targets for strike.\n\n- The statement presents the possibility of operationalizing these capabilities into units in the future.",
            "url": "https://www.gov.uk/government/news/aukus-statement-26-september-2024"
          },
          {
            "text": "AUKUS Trilateral Security Partnership Agreement Joint Statement (Dec 2023)\n\n- A joint statement by the defense ministers and secretaries of the partnership countries identified Resilient and Autonomous Artificial Intelligence Technologies (RAAIT) to deliver on force protection, precision targeting, and ISR.\n\n- AUKUS partnership countries state a goal of integrating RAAIT into national programs by 2024 across land and maritime domains.",
            "url": "https://www.minister.defence.gov.au/statements/2023-12-02/aukus-defense-ministers-meeting-joint-statement"
          }
        ]
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "AUKUS Trilateral Security Partnership Agreement Pillar 2 (May 2024)\n\n- Artificial Intelligence and Autonomy is an official working group under the trilateral partnership that seeks to integrate autonomous functions to act as a force multiplier in future conflicts.",
            "url": "https://www.congress.gov/crs-product/R47599"
          }
        ],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      }
    },
    "FVEY": {
      "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Adoption & Intent of Use": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Acquisition & Procurement": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Ethical Guidelines & Restrictions": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "International Cooperation & Interoperability": {
        "legal_directives": [],
        "policy_documents": [],
        "public_statements": []
      },
      "Technical Safety & Security Requirements": {
        "legal_directives": [],
        "policy_documents": [
          {
            "text": "FVEY Deploying AI Systems Securely\u00a0 \u2013 Best Practices for Deploying Secure and Resilient AI Systems (Apr 2024)\n\n- This document provides best practices for deploying and operating externally developed AI systems.\n\n- It aims to improve confidentiality, integrity, and availability of AI systems; ensure presence of appropriate mitigations for known vulnerabilities in AI systems; and provide methodologies and controls to protect, detect, and respond to malicious activity against AI systems.",
            "url": "https://media.defense.gov/2024/apr/15/2003439257/-1/-1/0/csi-deploying-ai-systems-securely.pdf"
          }
        ],
        "public_statements": []
      }
    }
  },
  "summaries": {
    "Algeria": "Algeria strongly advocates for a legally binding international instrument to regulate lethal autonomous weapons systems, consistently emphasizing that such weapons fundamentally challenge international humanitarian law and human dignity.",
    "Armenia": "Armenia supports international regulation of autonomous weapons and emphasizes meaningful human control, while actively engaging in defense modernization efforts and endorsing key international declarations on responsible military AI use.",
    "Australia": "Australia is actively developing military AI and autonomous systems capabilities through major defense initiatives and allied cooperation frameworks. The country maintains strong alignment with partners while supporting international governance frameworks and meaningful human control requirements.",
    "Azerbaijan": "Azerbaijan is investing in unmanned aerial vehicle capabilities for defense modernization, while participating in international discussions on AI governance in the military domain.",
    "Belgium": "Belgium was among the first countries to pass a parliamentary resolution calling for a ban on fully autonomous weapons, and consistently advocates for internationally agreed legal standards and binding instruments on autonomous weapons.",
    "Brazil": "Brazil stresses the need for meaningful human control over autonomous weapons systems and supports the development of new international legal instruments to regulate autonomous weapons under multilateral frameworks.",
    "Bulgaria": "Bulgaria supports a two-tier regulatory approach to autonomous weapons, combining prohibitions on systems incompatible with international humanitarian law with risk mitigation measures for other autonomous systems.",
    "Canada": "Canada has developed a comprehensive defense AI strategy emphasizing human control, ethical guidelines, and compliance with international humanitarian law across all military AI applications. The country is investing significantly in AI-enabled defense capabilities while actively participating in allied AI cooperation initiatives.",
    "China": "China actively develops military AI capabilities while advocating for international governance frameworks, supporting human control requirements and proposing specific definitions and risk assessments for autonomous weapons. The country emphasizes AI-enabled modernization as a strategic priority while calling for prohibitions on fully autonomous lethal systems.",
    "Colombia": "Colombia supports international regulation of autonomous weapons systems and advocates for meaningful human control, emphasizing the importance of addressing these issues within multilateral frameworks.",
    "Croatia": "Croatia supports the development of international regulations on autonomous weapons and emphasizes maintaining human control and accountability in military AI systems, having endorsed key international governance declarations.",
    "Czechia": "Czechia is investing in defense modernization including AI capabilities while taking a cautious approach to international autonomous weapons regulation, abstaining from some UN resolutions while supporting others.",
    "Denmark": "Denmark supports a two-tier approach to autonomous weapons regulation and is actively developing national defense AI strategies emphasizing compliance with international humanitarian law. The country participates in multinational defense initiatives and has endorsed key international governance frameworks.",
    "Egypt": "Egypt strongly supports a two-tiered approach to regulating autonomous weapons, calling for prohibitions on fully autonomous systems while allowing regulated use of semi-autonomous weapons under human control.",
    "Estonia": "Estonia is a leader in defense AI policy, having published dedicated defense AI strategies and consistently advocating for meaningful human control while developing innovative military AI capabilities. The country emphasizes AI as critical to national defense and actively promotes international governance frameworks.",
    "Finland": "Finland pursues international instruments to govern autonomous weapons while developing national defense AI capabilities, emphasizing human oversight and compliance with international law. The country supports legally binding instruments and has endorsed key international AI governance frameworks.",
    "France": "France has developed one of Europe's most comprehensive military AI frameworks, explicitly rejecting fully autonomous lethal systems while investing heavily in AI-enabled defense capabilities and leading international governance initiatives. The country maintains human control requirements across all weapon systems and has been at the forefront of multilateral efforts on responsible AI use.",
    "Germany": "Germany strongly supports international regulation of autonomous weapons, advocating for legally binding instruments and comprehensive implementation of international guiding principles. The country emphasizes meaningful human control and has published detailed national positions on autonomous weapons governance.",
    "Greece": "Greece supports a two-tier approach to autonomous weapons regulation and is investing in defense innovation including AI capabilities through multinational programs. The country emphasizes human control over critical decisions and has endorsed international AI governance frameworks.",
    "Hungary": "Hungary supports international governance frameworks for autonomous weapons while developing national defense capabilities, voting in favor of UN resolutions promoting multilateral discussions on these issues.",
    "India": "India is rapidly developing military AI capabilities through dedicated defense AI organizations, pursuing indigenous AI systems across multiple domains. The country takes an independent stance on international autonomous weapons regulation while emphasizing AI as critical to defense modernization.",
    "Iran": "Iran takes a cautious approach to international autonomous weapons discussions, abstaining from key UN resolutions while expressing concerns about the implications of autonomous weapons for international security.",
    "Iraq": "Iraq calls for clear international legal frameworks governing autonomous weapons, supporting UN resolutions that promote multilateral discussions and emphasizing the importance of human control.",
    "Israel": "Israel is a global leader in military AI and autonomous systems development, with extensive operational deployment of AI-enabled defense capabilities. The country views human control as one consideration among several, but this advanced operational posture contrasts with a limited public policy footprint, with few formal guidelines or governance frameworks addressing military AI use.",
    "Italy": "Italy supports a two-tier approach to autonomous weapons regulation and is actively investing in military AI through participation in major European defense programs. The country emphasizes ethical guidelines and human oversight in autonomous systems.",
    "Japan": "Japan has established comprehensive guidelines for responsible AI in defense systems through dedicated governmental bodies, explicitly maintaining human involvement in critical decisions. The country is significantly expanding defense AI investments while emphasizing safety, security, and international cooperation.",
    "Latvia": "Latvia emphasizes human control and responsibility in autonomous weapons discussions while developing national defense capabilities, taking a measured approach to international regulation and endorsing key governance declarations.",
    "Lithuania": "Lithuania supports multilateral discussions on autonomous weapons governance and emphasizes maintaining human control, while developing national defense and security AI policies aligned with allied frameworks.",
    "Morocco": "Morocco advocates for a legally binding international instrument to regulate autonomous weapons, emphasizing the importance of human control and the potential risks of fully autonomous systems.",
    "Netherlands": "The Netherlands has developed comprehensive policies on autonomous weapons governance with strong ethical frameworks, supporting international regulation while actively investing in defense AI capabilities. The country emphasizes transparency and has published detailed policy positions on autonomy in weapons systems.",
    "North Korea": "North Korea has limited public engagement on autonomous weapons governance, voting against or abstaining from key UN resolutions while maintaining opacity about military AI development.",
    "Norway": "Norway supports a legally binding instrument on autonomous weapons with a two-tier approach, while developing national defense AI strategies that emphasize human control and compliance with international humanitarian law. The country actively participates in international governance discussions.",
    "Pakistan": "Pakistan strongly supports international regulation of autonomous weapons, emphasizing that fully autonomous weapons pose fundamental challenges to international humanitarian law and human dignity.",
    "Poland": "Poland is actively developing military AI and autonomous systems capabilities, including significant unmanned systems programs driven by regional security concerns. The country engages in international governance discussions while pursuing rapid defense AI modernization.",
    "Russia": "Russia does not support international bans on military AI development, emphasizing national discretion in implementing human control measures while actively developing advanced autonomous weapons capabilities. The country views AI-enabled combat systems as strategically essential.",
    "Singapore": "Singapore supports a two-tier approach to autonomous weapons regulation and is establishing dedicated military AI organizations. The country emphasizes governance frameworks while developing advanced defense AI capabilities and international partnerships.",
    "South Africa": "South Africa supports the creation of a legally binding instrument to regulate autonomous weapons, emphasizing the importance of maintaining meaningful human control over weapons systems.",
    "South Korea": "South Korea is a major developer of military AI and autonomous systems, establishing dedicated defense AI organizations and pursuing AI-enabled capabilities across multiple domains. The country supports international governance frameworks and human control requirements while significantly expanding defense AI investments.",
    "Spain": "Spain supports a two-tier approach to autonomous weapons regulation and is participating in major international defense AI programs. The country emphasizes ethical guidelines and human oversight while developing national autonomous systems capabilities.",
    "Sweden": "Sweden supports international regulation of autonomous weapons through legally binding instruments, emphasizing human control and accountability while developing national defense AI capabilities and participating in European defense initiatives.",
    "Turkey": "Turkey is actively developing and deploying autonomous weapons capabilities while maintaining that binding international instruments would be premature. The country emphasizes existing international humanitarian law frameworks as sufficient governance.",
    "UAE": "The United Arab Emirates is investing in autonomous defense systems through international partnerships and domestic development initiatives while engaging in UN discussions on AI governance in the military domain.",
    "UK": "The United Kingdom has developed one of the world's most comprehensive defense AI frameworks, including dedicated strategies, detailed ethical guidelines, and governance structures covering the entire AI lifecycle. The country actively invests in AI-enabled capabilities across all domains while supporting international governance efforts and responsible military AI use.",
    "USA": "The United States maintains the world's most extensive military AI policy framework, with comprehensive directives on autonomous weapons, detailed ethical principles, and massive investments in AI-enabled defense capabilities across all domains. The country leads international governance efforts while emphasizing responsible development, human oversight, and maintaining technological advantage.",
    "Ukraine": "Ukraine is rapidly developing and deploying military AI and autonomous systems driven by wartime necessity, gaining significant operational experience with unmanned systems and AI-enabled capabilities. The country engages in international discussions on responsible AI use while pursuing accelerated defense AI adoption."
  }
}
    </script>


    <script>
        const rawData = JSON.parse(document.getElementById("policy-data").textContent);
        const policyData = rawData.countries;
        const allianceData = rawData.alliances;
        const MAX_COMPARE = 2;


        const countryNameMap = {
            "United States of America": "USA",
            "United States": "USA",
            "China": "China",
            "France": "France",
            "United Kingdom": "UK",
            "UK": "UK",
            "South Korea": "South Korea",
            "Korea, Republic of": "South Korea",
            "Republic of Korea": "South Korea",
            "Israel": "Israel",
            "Russia": "Russia",
            "Russian Federation": "Russia",
            "Estonia": "Estonia",
            "Australia": "Australia",
            "Germany": "Germany",
            "Turkey": "Turkey",
            "TÃ¼rkiye": "Turkey",
            "India": "India",
            "Pakistan": "Pakistan",
            "Azerbaijan": "Azerbaijan",
            "Ukraine": "Ukraine",
            "United Arab Emirates": "UAE",
            "Iran": "Iran",
            "Iran, Islamic Republic of": "Iran",
            "North Korea": "North Korea",
            "Korea, Democratic People's Republic of": "North Korea",
            "Dem. Rep. Korea": "North Korea",
            "Democratic People's Republic of Korea": "North Korea",
            "Norway": "Norway",
            "Singapore": "Singapore",
            "Japan": "Japan",
            "Canada": "Canada",
            "Poland": "Poland",
            "Belgium": "Belgium",
            "Egypt": "Egypt",
            "Italy": "Italy",
            "Algeria": "Algeria",
            "Armenia": "Armenia",
            "Colombia": "Colombia",
            "Netherlands": "Netherlands",
            "Spain": "Spain",
            "Iraq": "Iraq",
            "Lithuania": "Lithuania",
            "Greece": "Greece",
            "Sweden": "Sweden",
            "Latvia": "Latvia",
            "Finland": "Finland",
            "Denmark": "Denmark",
            "Hungary": "Hungary",
            "Croatia": "Croatia",
            "Morocco": "Morocco",
            "Czechia": "Czechia",
            "Czech Republic": "Czechia",
            "Bulgaria": "Bulgaria",
            "Brazil": "Brazil",
            "South Africa": "South Africa",
            "S. Africa": "South Africa"
        };


        // Alliance member countries (map names -> our keys, for highlighting)
        const allianceMembers = {
            "NATO": [
                "USA", "UK", "France", "Germany", "Turkey", "Estonia", "Norway",
                "Canada", "Belgium", "Bulgaria", "Croatia", "Czechia", "Denmark",
                "Finland", "Greece", "Hungary", "Iceland", "Italy", "Latvia",
                "Lithuania", "Luxembourg", "Montenegro", "Netherlands", "North Macedonia",
                "Poland", "Portugal", "Romania", "Slovakia", "Slovenia", "Spain",
                "Sweden", "Albania"
            ],
            "AUKUS": ["USA", "UK", "Australia"],
            "FVEY": ["USA", "UK", "Australia", "Canada", "New Zealand"]
        };


        // Map from TopoJSON names to alliance member names
        const allianceMemberMap = {
            "United States of America": "USA",
            "United States": "USA",
            "United Kingdom": "UK",
            "U.K.": "UK",
            "Britain": "UK",
            "Great Britain": "UK",
            "France": "France",
            "Germany": "Germany",
            "Turkey": "Turkey",
            "TÃ¼rkiye": "Turkey",
            "TÃ¼rkiye": "Turkey",
            "Estonia": "Estonia",
            "Norway": "Norway",
            "Canada": "Canada",
            "Belgium": "Belgium",
            "Bulgaria": "Bulgaria",
            "Croatia": "Croatia",
            "Czechia": "Czechia",
            "Czech Republic": "Czechia",
            "Czech Rep.": "Czechia",
            "Denmark": "Denmark",
            "Finland": "Finland",
            "Greece": "Greece",
            "Hungary": "Hungary",
            "Iceland": "Iceland",
            "Italy": "Italy",
            "Latvia": "Latvia",
            "Lithuania": "Lithuania",
            "Luxembourg": "Luxembourg",
            "Montenegro": "Montenegro",
            "Netherlands": "Netherlands",
            "North Macedonia": "North Macedonia",
            "Macedonia": "North Macedonia",
            "Poland": "Poland",
            "Portugal": "Portugal",
            "Romania": "Romania",
            "Slovakia": "Slovakia",
            "Slovenia": "Slovenia",
            "Spain": "Spain",
            "Sweden": "Sweden",
            "Albania": "Albania",
            "Australia": "Australia",
            "New Zealand": "New Zealand",
            "Japan": "Japan",
            "Greenland": "Greenland",
            "Republic of Albania": "Albania",
            "Kingdom of Belgium": "Belgium",
            "Republic of Bulgaria": "Bulgaria",
            "Republic of Croatia": "Croatia",
            "Kingdom of Denmark": "Denmark",
            "Republic of Estonia": "Estonia",
            "Republic of Finland": "Finland",
            "French Republic": "France",
            "Federal Republic of Germany": "Germany",
            "Hellenic Republic": "Greece",
            "Republic of Hungary": "Hungary",
            "Republic of Iceland": "Iceland",
            "Italian Republic": "Italy",
            "Republic of Latvia": "Latvia",
            "Republic of Lithuania": "Lithuania",
            "Grand Duchy of Luxembourg": "Luxembourg",
            "Kingdom of the Netherlands": "Netherlands",
            "Kingdom of Norway": "Norway",
            "Republic of Poland": "Poland",
            "Portuguese Republic": "Portugal",
            "Romania": "Romania",
            "Slovak Republic": "Slovakia",
            "Republic of Slovenia": "Slovenia",
            "Kingdom of Spain": "Spain",
            "Kingdom of Sweden": "Sweden",
            "Republic of Turkey": "Turkey",
            "Republic of TÃ¼rkiye": "Turkey",
            "Commonwealth of Australia": "Australia",
            "Dominion of Canada": "Canada"
        };


        const displayNames = {
            "USA": "United States of America",
            "China": "China",
            "France": "France",
            "UK": "United Kingdom",
            "South Korea": "Republic of Korea",
            "Israel": "Israel",
            "Russia": "Russian Federation",
            "Estonia": "Estonia",
            "Australia": "Australia",
            "Germany": "Germany",
            "Turkey": "TÃ¼rkiye",
            "India": "India",
            "Pakistan": "Pakistan",
            "Azerbaijan": "Azerbaijan",
            "Ukraine": "Ukraine",
            "UAE": "United Arab Emirates",
            "Iran": "Iran",
            "North Korea": "Democratic People's Republic of Korea",
            "Norway": "Norway",
            "Singapore": "Singapore",
            "Japan": "Japan",
            "Canada": "Canada",
            "Poland": "Poland",
            "Belgium": "Belgium",
            "Egypt": "Egypt",
            "Italy": "Italy",
            "Algeria": "Algeria",
            "Armenia": "Armenia",
            "Colombia": "Colombia",
            "Netherlands": "Netherlands",
            "Spain": "Spain",
            "Iraq": "Iraq",
            "Lithuania": "Lithuania",
            "Greece": "Greece",
            "Sweden": "Sweden",
            "Latvia": "Latvia",
            "Finland": "Finland",
            "Denmark": "Denmark",
            "Hungary": "Hungary",
            "Croatia": "Croatia",
            "Morocco": "Morocco",
            "Czechia": "Czechia",
            "Czech Republic": "Czechia",
            "Bulgaria": "Bulgaria",
            "Brazil": "Brazil",
            "South Africa": "South Africa",
            "S. Africa": "South Africa"
        };


        let currentView = "overview";
        let selectedCountry = null;
        let selectedAlliance = null;
        let selectedCountries = new Set();
        let selectedPolicyArea = "all";
        let mapZoom = null;
        const tooltip = document.getElementById("tooltip");


        function escapeHtml(text) {
            const div = document.createElement("div");
            div.textContent = text;
            return div.innerHTML;
        }


        function extractUrl(text) {
            var urlRegex = /(https?:\/\/[^\s\)]+)/g;
            var match = text.match(urlRegex);
            return match ? match[0].replace(/[.,;:]+$/, '') : null;
        }


        function extractDate(text) {
            // Match patterns like (Jan 2023), (December 2024), (2019), etc.
            var dateRegex = /\(([A-Z][a-z]+ \d{4}|\d{4})\)\s*$/;
            var title = text.split("\n")[0].trim();
            var match = title.match(dateRegex);
            return match ? match[1] : null;
        }


        function parseTitleWithoutDate(text) {
            var title = text.split("\n")[0].trim();
            // Remove the date in parentheses from the end
            return title.replace(/\s*\([A-Z][a-z]+ \d{4}\)\s*$/, '').replace(/\s*\(\d{4}\)\s*$/, '').trim();
        }


        function parseTitle(text) {
            return text.split("\n")[0].trim();
        }


        function parseDetails(text) {
            var lines = text.split("\n").slice(1).join("\n").trim();
            var paragraphs = lines.split("\n").filter(function(l) { return l.trim(); });
            return paragraphs.map(function(line) {
                var cleaned = line.replace(/^-\s*/, "").trim().replace(/(https?:\/\/[^\s\)]+)/g, "").trim();
                return cleaned ? "<p>" + escapeHtml(cleaned) + "</p>" : "";
            }).filter(function(p) { return p; }).join("");
        }


        // ===== VIEW SWITCHING =====
        document.querySelectorAll(".view-tab").forEach(function(tab) {
            tab.addEventListener("click", function() {
                currentView = this.dataset.view;
                document.querySelectorAll(".view-tab").forEach(function(t) { t.classList.remove("active"); });
                this.classList.add("active");
                document.querySelectorAll(".view-content").forEach(function(v) { v.classList.remove("active"); });
                document.getElementById("view-" + currentView).classList.add("active");
                
                // Clear alliance highlighting and selection when leaving alliance view
                if (currentView !== "alliance") {
                    selectedAlliance = null;
                    document.querySelectorAll(".country-path").forEach(function(p) {
                        p.classList.remove("alliance-member");
                    });
                }
                
                updateMapHighlights();
                updateCompareChipsState();
            });
        });


        // ===== BUILD CHIPS =====
        function buildDropdowns() {
            var overviewDropdown = document.getElementById("overview-dropdown");
            var compareDropdown = document.getElementById("compare-dropdown");
            
            // Get all countries and sort alphabetically by display name
            var countries = Object.keys(policyData);
            countries.sort(function(a, b) {
                var nameA = displayNames[a] || a;
                var nameB = displayNames[b] || b;
                return nameA.localeCompare(nameB);
            });


            countries.forEach(function(country) {
                var displayName = displayNames[country] || country;


                var option1 = document.createElement("option");
                option1.value = country;
                option1.textContent = displayName;
                overviewDropdown.appendChild(option1);
                
                var option2 = document.createElement("option");
                option2.value = country;
                option2.textContent = displayName;
                compareDropdown.appendChild(option2);
            });


            // Add event listeners
            overviewDropdown.addEventListener("change", function() {
                if (this.value) {
                    selectOverviewCountry(this.value);
                } else {
                    // Clear selection when "Choose a country" is selected
                    selectedCountry = null;
                    document.getElementById("overview-header").style.display = "none";
                    document.getElementById("overview-content").innerHTML = '<div class="placeholder"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M9 20l-5.447-2.724A1 1 0 013 16.382V5.618a1 1 0 011.447-.894L9 7m0 13l6-3m-6 3V7m6 10l4.553 2.276A1 1 0 0021 18.382V7.618a1 1 0 00-.553-.894L15 4m0 13V4m0 0L9 7" /></svg><p>Select a country to explore its<br>defense AI policy framework</p></div>';
                    // Clear map selection
                    d3.selectAll(".country-path").classed("selected", false);
                }
            });


            compareDropdown.addEventListener("change", function() {
                if (this.value && !selectedCountries.has(this.value) && selectedCountries.size < MAX_COMPARE) {
                    toggleCompareCountry(this.value);
                    this.value = ""; // Reset dropdown
                }
            });
        }


        
        // ===== COUNTRY SEARCH =====
        function initCountrySearch() {
            // Get all country names for searching
            var countryList = Object.keys(policyData).map(function(key) {
                return {
                    key: key,
                    displayName: displayNames[key] || key
                };
            });
            
            // Setup search for overview
            setupSearch(
                document.getElementById("country-search"),
                document.getElementById("search-results-dropdown"),
                document.getElementById("search-message"),
                countryList,
                function(country) {
                    selectOverviewCountry(country.key);
                }
            );
            
            // Setup search for compare
            setupSearch(
                document.getElementById("compare-search"),
                document.getElementById("compare-search-results"),
                document.getElementById("compare-search-message"),
                countryList,
                function(country) {
                    if (!selectedCountries.has(country.key) && selectedCountries.size < MAX_COMPARE) {
                        toggleCompareCountry(country.key);
                    }
                }
            );
        }
        
        function setupSearch(searchInput, resultsDropdown, searchMessage, countryList, onSelect) {
            if (!searchInput) return;
            
            function performSearch(query) {
                query = query.trim().toLowerCase();
                
                // Hide both dropdowns initially
                resultsDropdown.classList.remove("visible");
                searchMessage.classList.remove("visible");
                resultsDropdown.innerHTML = "";
                
                if (query.length === 0) {
                    return;
                }
                
                // Find matches
                var matches = countryList.filter(function(country) {
                    return country.displayName.toLowerCase().includes(query) ||
                           country.key.toLowerCase().includes(query);
                });
                
                if (matches.length === 0) {
                    // No matches found
                    searchMessage.textContent = "Sorry, your search does not match any entries";
                    searchMessage.classList.add("visible");
                } else if (matches.length === 1) {
                    // Single match - auto-select
                    onSelect(matches[0]);
                    searchInput.value = "";
                } else {
                    // Multiple matches - show dropdown
                    matches.forEach(function(country) {
                        var item = document.createElement("div");
                        item.className = "search-result-item";
                        item.textContent = country.displayName;
                        item.addEventListener("click", function() {
                            onSelect(country);
                            searchInput.value = "";
                            resultsDropdown.classList.remove("visible");
                        });
                        resultsDropdown.appendChild(item);
                    });
                    resultsDropdown.classList.add("visible");
                }
            }
            
            // Debounce search
            var searchTimeout;
            searchInput.addEventListener("input", function() {
                clearTimeout(searchTimeout);
                searchTimeout = setTimeout(function() {
                    performSearch(searchInput.value);
                }, 150);
            });
            
            // Handle Enter key
            searchInput.addEventListener("keydown", function(e) {
                if (e.key === "Enter") {
                    e.preventDefault();
                    clearTimeout(searchTimeout);
                    performSearch(searchInput.value);
                }
            });
            
            // Close dropdown when clicking outside
            document.addEventListener("click", function(e) {
                if (!e.target.closest(".country-search-wrapper")) {
                    resultsDropdown.classList.remove("visible");
                    searchMessage.classList.remove("visible");
                }
            });
            
            // Close dropdown on escape
            searchInput.addEventListener("keydown", function(e) {
                if (e.key === "Escape") {
                    resultsDropdown.classList.remove("visible");
                    searchMessage.classList.remove("visible");
                    searchInput.blur();
                }
            });
        }


        function updateCompareChipsState() {
            var atLimit = selectedCountries.size >= MAX_COMPARE;
            var dropdown = document.getElementById("compare-dropdown");
            dropdown.disabled = atLimit;


            // Update selected countries display
            var container = document.getElementById("selected-countries");
            container.innerHTML = "";
            
            selectedCountries.forEach(function(country) {
                var tag = document.createElement("div");
                tag.className = "selected-tag";
                tag.innerHTML = '<span>' + escapeHtml(displayNames[country] || country) + '</span>' +
                    '<button class="remove-btn" data-country="' + country + '">' +
                    '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="18" y1="6" x2="6" y2="18"></line><line x1="6" y1="6" x2="18" y2="18"></line></svg>' +
                    '</button>';
                tag.querySelector(".remove-btn").addEventListener("click", function() {
                    toggleCompareCountry(this.dataset.country);
                });
                container.appendChild(tag);
            });


            var limitText = document.getElementById("selection-limit");
            if (selectedCountries.size > 0) {
                limitText.textContent = "(" + selectedCountries.size + "/" + MAX_COMPARE + " selected)";
            } else {
                limitText.textContent = "(max " + MAX_COMPARE + ")";
            }
        }


        // ===== OVERVIEW FUNCTIONS =====
        function selectOverviewCountry(country) {
            selectedCountry = country;
            document.getElementById("overview-dropdown").value = country;
            updateMapHighlights();
            renderOverview();
        }


        // ===== ALLIANCE FUNCTIONS =====
        function selectAlliance(alliance) {
            selectedAlliance = alliance;
            document.getElementById("alliance-dropdown").value = alliance;
            updateMapHighlights();
            renderAllianceOverview();
        }


        function switchToCountryOverview(countryKey) {
            // Switch to Country Overview tab
            currentView = "overview";
            
            // Update tab buttons
            document.querySelectorAll(".view-tab").forEach(function(t) { 
                t.classList.remove("active"); 
            });
            document.querySelector('.view-tab[data-view="overview"]').classList.add("active");
            
            // Update view content
            document.querySelectorAll(".view-content").forEach(function(v) { 
                v.classList.remove("active"); 
            });
            document.getElementById("view-overview").classList.add("active");
            
            // Select the country
            selectOverviewCountry(countryKey);
        }


        function getAllianceFilters() {
            return {
                legal: document.getElementById("alliance-filter-legal").checked,
                policy: document.getElementById("alliance-filter-policy").checked,
                statement: document.getElementById("alliance-filter-statement").checked
            };
        }


        function renderAllianceOverview() {
            if (!selectedAlliance) return;


            var data = allianceData[selectedAlliance];
            if (!data) return;


            var allianceNames = {
                "NATO": "North Atlantic Treaty Organization (NATO)",
                "AUKUS": "AUKUS (Australia, UK, US)",
                "FVEY": "Five Eyes (FVEY)"
            };


            var displayName = allianceNames[selectedAlliance] || selectedAlliance;
            document.getElementById("alliance-header").style.display = "flex";
            document.getElementById("alliance-name").textContent = displayName;


            // Render member countries list
            var membersListContainer = document.getElementById("alliance-members-list");
            membersListContainer.style.display = "block";
            membersListContainer.innerHTML = "";
            
            var membersLabel = document.createElement("div");
            membersLabel.className = "alliance-members-label";
            membersLabel.textContent = "Member States";
            membersListContainer.appendChild(membersLabel);
            
            var membersChips = document.createElement("div");
            membersChips.className = "alliance-members-chips";
            
            var members = allianceMembers[selectedAlliance] || [];
            members.sort().forEach(function(member) {
                var chip = document.createElement("span");
                chip.className = "alliance-member-chip";
                chip.textContent = displayNames[member] || member;
                
                // Check if we have data for this country
                if (policyData[member]) {
                    chip.classList.add("has-data");
                    chip.addEventListener("click", function() {
                        // Switch to country overview
                        switchToCountryOverview(member);
                    });
                }
                
                membersChips.appendChild(chip);
            });
            
            membersListContainer.appendChild(membersChips);


            var content = document.getElementById("alliance-content");
            content.innerHTML = "";
            
            // Alliance summary blurbs
            var allianceSummaries = {
                "NATO": "NATO has developed a comprehensive AI strategy framework emphasizing principles of responsible use (PRUs) including lawfulness, accountability, explainability, reliability, governability, and bias mitigation. The alliance actively coordinates AI development among member states while ensuring interoperability and shared ethical standards.",
                "AUKUS": "AUKUS is a trilateral security partnership focused on sharing advanced defense capabilities including AI and autonomous systems. Pillar II of the agreement specifically addresses emerging technologies including artificial intelligence, quantum computing, and advanced cyber capabilities.",
                "FVEY": "The Five Eyes intelligence alliance has developed joint guidance on secure AI deployment, focusing on protecting AI systems from adversarial manipulation. However, due to the opaque nature of the alliance, limited public documentation exists regarding specific AI governance frameworks and policies."
            };
            
            // Add summary box
            var allianceSummary = allianceSummaries[selectedAlliance];
            if (allianceSummary) {
                var summaryBox = document.createElement("div");
                summaryBox.className = "country-summary-box";
                summaryBox.textContent = allianceSummary;
                content.appendChild(summaryBox);
            }


            var filters = getAllianceFilters();
            var totalCount = 0;
            var areaCount = 0;


            var POLICY_AREAS = [
                "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment",
                "Adoption & Intent of Use",
                "Acquisition & Procurement",
                "Ethical Guidelines & Restrictions",
                "Technical Safety & Security Requirements",
                "International Cooperation & Interoperability"
            ];
            
            var AREA_KEYS = ["laws", "adoption", "acquisition", "ethical", "technical", "international"];
            var AREA_COLORS = ["#1a2744", "#d64045", "#6b3074", "#4a9d5b", "#e07020", "#0d7377"];
            var AREA_SHORT = ["LAWS", "Adoption", "Acq.", "Ethics", "Tech.", "Int'l"];


            // ===== CALCULATE MEMBER CONTRIBUTION DATA =====
            var memberContributions = [];
            var memberByArea = {};
            var allianceMembersList = allianceMembers[selectedAlliance] || [];
            
            allianceMembersList.forEach(function(member) {
                if (policyData[member]) {
                    var memberTotal = 0;
                    var areaData = {};
                    
                    POLICY_AREAS.forEach(function(areaName, idx) {
                        var area = policyData[member][areaName];
                        var count = 0;
                        if (area) {
                            count = (area.legal_directives || []).length +
                                   (area.policy_documents || []).length +
                                   (area.public_statements || []).length;
                        }
                        areaData[AREA_KEYS[idx]] = count;
                        memberTotal += count;
                    });
                    
                    if (memberTotal > 0) {
                        memberContributions.push({
                            key: member,
                            name: displayNames[member] || member,
                            total: memberTotal
                        });
                        memberByArea[member] = areaData;
                    }
                }
            });
            
            // Sort by total descending
            memberContributions.sort(function(a, b) { return b.total - a.total; });
            var maxMemberTotal = memberContributions.length > 0 ? memberContributions[0].total : 1;
            
            // Find max heat value for heatmap
            var maxHeatValue = 1;
            Object.keys(memberByArea).forEach(function(member) {
                AREA_KEYS.forEach(function(key) {
                    if (memberByArea[member][key] > maxHeatValue) {
                        maxHeatValue = memberByArea[member][key];
                    }
                });
            });


            // ===== BUILD VISUALIZATIONS =====
            if (memberContributions.length > 0) {
                var insightsRow = document.createElement("div");
                insightsRow.className = "alliance-insights-row";
                
                // ----- Member Contribution Bar Chart -----
                var barChartBox = document.createElement("div");
                barChartBox.className = "alliance-chart-box";
                
                // Header row with title and info icon
                var barHeader = document.createElement("div");
                barHeader.className = "alliance-chart-header";
                
                var barTitle = document.createElement("div");
                barTitle.className = "alliance-chart-title";
                barTitle.textContent = "Member Contributions";
                barHeader.appendChild(barTitle);
                
                var barInfoNote = document.createElement("div");
                barInfoNote.className = "alliance-info-note";
                barInfoNote.innerHTML = '<span class="info-icon">i</span><span>Info</span>' +
                    '<div class="alliance-info-tooltip">Visualizations include only alliance members with individual country profiles in this database. Some member states may not yet be documented.</div>';
                barHeader.appendChild(barInfoNote);
                
                barChartBox.appendChild(barHeader);
                
                var barSubtitle = document.createElement("div");
                barSubtitle.className = "alliance-chart-subtitle";
                barSubtitle.textContent = "Policy entries by member state";
                barChartBox.appendChild(barSubtitle);
                
                var barsContainer = document.createElement("div");
                barsContainer.style.cssText = "display: flex; flex-direction: column; gap: 2px;";
                
                // Show top 10 members initially
                var initialMembers = memberContributions.slice(0, 10);
                var extraMembers = memberContributions.slice(10);
                
                // Function to create a bar row
                function createBarRow(member, idx) {
                    var row = document.createElement("div");
                    row.className = "member-bar-row";
                    
                    var nameSpan = document.createElement("div");
                    nameSpan.className = "member-bar-name";
                    nameSpan.textContent = member.name;
                    nameSpan.title = member.name;
                    row.appendChild(nameSpan);
                    
                    var track = document.createElement("div");
                    track.className = "member-bar-track";
                    
                    var fill = document.createElement("div");
                    fill.className = "member-bar-fill";
                    if (idx < 3) fill.classList.add("rank-1");
                    else if (idx < 6) fill.classList.add("rank-2");
                    else fill.classList.add("rank-3");
                    fill.style.width = ((member.total / maxMemberTotal) * 100) + "%";
                    track.appendChild(fill);
                    row.appendChild(track);
                    
                    var valueSpan = document.createElement("div");
                    valueSpan.className = "member-bar-value";
                    if (idx >= 3) valueSpan.classList.add("muted");
                    valueSpan.textContent = member.total;
                    row.appendChild(valueSpan);
                    
                    row.style.cursor = "pointer";
                    (function(countryKey) {
                        row.addEventListener("click", function() {
                            switchToCountryOverview(countryKey);
                        });
                    })(member.key);
                    
                    return row;
                }
                
                // Add initial members
                initialMembers.forEach(function(member, idx) {
                    barsContainer.appendChild(createBarRow(member, idx));
                });
                
                barChartBox.appendChild(barsContainer);
                
                // Add expandable section for extra members
                if (extraMembers.length > 0) {
                    var extraBarsContainer = document.createElement("div");
                    extraBarsContainer.style.cssText = "display: none; flex-direction: column; gap: 2px; margin-top: 2px;";
                    extraBarsContainer.className = "extra-bars-container";
                    
                    extraMembers.forEach(function(member, idx) {
                        extraBarsContainer.appendChild(createBarRow(member, idx + 10));
                    });
                    
                    barChartBox.appendChild(extraBarsContainer);
                    
                    var expandToggle = document.createElement("div");
                    expandToggle.className = "expand-more-toggle";
                    expandToggle.innerHTML = '<span class="expand-more-text">+' + extraMembers.length + ' more members</span><svg class="expand-more-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M19 9l-7 7-7-7"/></svg>';
                    
                    var isExpanded = false;
                    expandToggle.addEventListener("click", function() {
                        isExpanded = !isExpanded;
                        extraBarsContainer.style.display = isExpanded ? "flex" : "none";
                        expandToggle.querySelector(".expand-more-text").textContent = isExpanded ? "Show less" : "+" + extraMembers.length + " more members";
                        expandToggle.querySelector(".expand-more-icon").style.transform = isExpanded ? "rotate(180deg)" : "rotate(0)";
                    });
                    
                    barChartBox.appendChild(expandToggle);
                }
                
                insightsRow.appendChild(barChartBox);
                
                // ----- Policy Coverage Heatmap -----
                var heatmapBox = document.createElement("div");
                heatmapBox.className = "alliance-chart-box";
                
                // Header row with title and info icon
                var heatHeader = document.createElement("div");
                heatHeader.className = "alliance-chart-header";
                
                var heatTitle = document.createElement("div");
                heatTitle.className = "alliance-chart-title";
                heatTitle.textContent = "Policy Coverage Heatmap";
                heatHeader.appendChild(heatTitle);
                
                var heatInfoNote = document.createElement("div");
                heatInfoNote.className = "alliance-info-note";
                heatInfoNote.innerHTML = '<span class="info-icon">i</span><span>Info</span>' +
                    '<div class="alliance-info-tooltip">Visualizations include only alliance members with individual country profiles in this database. Some member states may not yet be documented.</div>';
                heatHeader.appendChild(heatInfoNote);
                
                heatmapBox.appendChild(heatHeader);
                
                var heatSubtitle = document.createElement("div");
                heatSubtitle.className = "alliance-chart-subtitle";
                heatSubtitle.textContent = "Entry counts by member and policy area (darker = more)";
                heatmapBox.appendChild(heatSubtitle);
                
                var tableWrapper = document.createElement("div");
                tableWrapper.style.cssText = "overflow-x: auto;";
                
                var table = document.createElement("table");
                table.className = "alliance-heatmap";
                
                // Header row
                var thead = document.createElement("thead");
                var headerRow = document.createElement("tr");
                
                var memberTh = document.createElement("th");
                memberTh.className = "member-col";
                memberTh.textContent = "MEMBER";
                headerRow.appendChild(memberTh);
                
                AREA_SHORT.forEach(function(shortName, idx) {
                    var th = document.createElement("th");
                    th.style.minWidth = "52px";
                    var dot = document.createElement("div");
                    dot.className = "area-dot";
                    dot.style.background = AREA_COLORS[idx];
                    th.appendChild(dot);
                    th.appendChild(document.createTextNode(shortName));
                    headerRow.appendChild(th);
                });
                
                var totalTh = document.createElement("th");
                totalTh.textContent = "TOTAL";
                headerRow.appendChild(totalTh);
                
                thead.appendChild(headerRow);
                table.appendChild(thead);
                
                // Body rows - show top 10 initially, rest in expandable section
                var tbody = document.createElement("tbody");
                var initialHeatmapMembers = memberContributions.slice(0, 10);
                var extraHeatmapMembers = memberContributions.slice(10);
                
                // Function to create a heatmap row
                function createHeatmapRow(member) {
                    var row = document.createElement("tr");
                    
                    var nameTd = document.createElement("td");
                    nameTd.className = "member-name";
                    nameTd.textContent = member.name;
                    nameTd.style.cursor = "pointer";
                    (function(countryKey) {
                        nameTd.addEventListener("click", function() {
                            switchToCountryOverview(countryKey);
                        });
                    })(member.key);
                    row.appendChild(nameTd);
                    
                    AREA_KEYS.forEach(function(key) {
                        var td = document.createElement("td");
                        td.className = "heat-cell";
                        var value = memberByArea[member.key][key] || 0;
                        
                        if (value === 0) {
                            td.classList.add("empty");
                            td.textContent = "â€”";
                            td.style.background = "#f5f5f5";
                        } else {
                            td.textContent = value;
                            var intensity = value / maxHeatValue;
                            var r = Math.round(245 - (245 - 26) * intensity);
                            var g = Math.round(245 - (245 - 39) * intensity);
                            var b = Math.round(245 - (245 - 68) * intensity);
                            td.style.background = "rgb(" + r + "," + g + "," + b + ")";
                            if (intensity > 0.5) {
                                td.classList.add("high");
                            }
                        }
                        row.appendChild(td);
                    });
                    
                    var totalTd = document.createElement("td");
                    totalTd.className = "total-cell";
                    totalTd.textContent = member.total;
                    row.appendChild(totalTd);
                    
                    return row;
                }
                
                // Add initial members to tbody
                initialHeatmapMembers.forEach(function(member) {
                    tbody.appendChild(createHeatmapRow(member));
                });
                
                table.appendChild(tbody);
                
                // Create expandable tbody for extra members
                var extraTbody = null;
                if (extraHeatmapMembers.length > 0) {
                    extraTbody = document.createElement("tbody");
                    extraTbody.className = "extra-heatmap-rows";
                    extraTbody.style.display = "none";
                    
                    extraHeatmapMembers.forEach(function(member) {
                        extraTbody.appendChild(createHeatmapRow(member));
                    });
                    
                    table.appendChild(extraTbody);
                }
                
                tableWrapper.appendChild(table);
                heatmapBox.appendChild(tableWrapper);
                
                // Add expand toggle for heatmap
                if (extraHeatmapMembers.length > 0) {
                    var heatmapExpandToggle = document.createElement("div");
                    heatmapExpandToggle.className = "expand-more-toggle";
                    heatmapExpandToggle.innerHTML = '<span class="expand-more-text">+' + extraHeatmapMembers.length + ' more members</span><svg class="expand-more-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M19 9l-7 7-7-7"/></svg>';
                    
                    var heatmapExpanded = false;
                    heatmapExpandToggle.addEventListener("click", function() {
                        heatmapExpanded = !heatmapExpanded;
                        extraTbody.style.display = heatmapExpanded ? "table-row-group" : "none";
                        heatmapExpandToggle.querySelector(".expand-more-text").textContent = heatmapExpanded ? "Show less" : "+" + extraHeatmapMembers.length + " more members";
                        heatmapExpandToggle.querySelector(".expand-more-icon").style.transform = heatmapExpanded ? "rotate(180deg)" : "rotate(0)";
                    });
                    
                    heatmapBox.appendChild(heatmapExpandToggle);
                }
                
                // Legend
                var legend = document.createElement("div");
                legend.className = "heatmap-legend";
                legend.innerHTML = '<span>Coverage:</span>' +
                    '<div class="heatmap-legend-item"><div class="heatmap-legend-swatch" style="background:#f5f5f5"></div><span>None</span></div>' +
                    '<div class="heatmap-legend-item"><div class="heatmap-legend-swatch" style="background:#b8c4d4"></div><span>Low</span></div>' +
                    '<div class="heatmap-legend-item"><div class="heatmap-legend-swatch" style="background:#5a7a9a"></div><span>Med</span></div>' +
                    '<div class="heatmap-legend-item"><div class="heatmap-legend-swatch" style="background:#1a2744"></div><span>High</span></div>';
                heatmapBox.appendChild(legend);
                
                insightsRow.appendChild(heatmapBox);
                content.appendChild(insightsRow);
            }


            // Build policy areas container (same structure as country overview)
            var areasContainer = document.createElement("div");
            areasContainer.className = "policy-areas";


            POLICY_AREAS.forEach(function(areaName) {
                var entries = data[areaName];
                if (!entries) return;


                var filteredEntries = {
                    legal_directives: filters.legal ? (entries.legal_directives || []) : [],
                    policy_documents: filters.policy ? (entries.policy_documents || []) : [],
                    public_statements: filters.statement ? (entries.public_statements || []) : []
                };


                var areaTotal = filteredEntries.legal_directives.length +
                               filteredEntries.policy_documents.length +
                               filteredEntries.public_statements.length;


                if (areaTotal === 0) return;


                areaCount++;
                totalCount += areaTotal;


                var policyArea = document.createElement("div");
                policyArea.className = "policy-area";
                
                // Set data-area attribute for consistent color coding
                if (areaName.indexOf("LAWS") !== -1) policyArea.setAttribute("data-area", "laws");
                else if (areaName.indexOf("Adoption") !== -1) policyArea.setAttribute("data-area", "adoption");
                else if (areaName.indexOf("Acquisition") !== -1) policyArea.setAttribute("data-area", "acquisition");
                else if (areaName.indexOf("International") !== -1) policyArea.setAttribute("data-area", "international");
                else if (areaName.indexOf("Technical") !== -1) policyArea.setAttribute("data-area", "technical");
                else if (areaName.indexOf("Ethical") !== -1) policyArea.setAttribute("data-area", "ethical");


                var areaHeader = document.createElement("div");
                areaHeader.className = "policy-area-header";
                areaHeader.addEventListener("click", function() { policyArea.classList.toggle("expanded"); });


                var areaTitle = document.createElement("span");
                areaTitle.className = "policy-area-title";
                areaTitle.textContent = areaName;
                areaHeader.appendChild(areaTitle);


                var areaMeta = document.createElement("div");
                areaMeta.className = "policy-area-meta";


                var sourceCount = document.createElement("span");
                sourceCount.className = "source-count";
                sourceCount.textContent = areaTotal + " entries";
                areaMeta.appendChild(sourceCount);


                var expandIcon = document.createElementNS("http://www.w3.org/2000/svg", "svg");
                expandIcon.setAttribute("class", "expand-icon");
                expandIcon.setAttribute("viewBox", "0 0 24 24");
                expandIcon.setAttribute("fill", "none");
                expandIcon.setAttribute("stroke", "currentColor");
                var expandPath = document.createElementNS("http://www.w3.org/2000/svg", "path");
                expandPath.setAttribute("stroke-linecap", "round");
                expandPath.setAttribute("stroke-linejoin", "round");
                expandPath.setAttribute("stroke-width", "2");
                expandPath.setAttribute("d", "M19 9l-7 7-7-7");
                expandIcon.appendChild(expandPath);
                areaMeta.appendChild(expandIcon);


                areaHeader.appendChild(areaMeta);
                policyArea.appendChild(areaHeader);


                var areaContent = document.createElement("div");
                areaContent.className = "policy-area-content";


                var legalSection = createSourceSection(filteredEntries.legal_directives, "legal", "Legal Directives");
                if (legalSection) areaContent.appendChild(legalSection);


                var policySection = createSourceSection(filteredEntries.policy_documents, "policy", "Policy Documents");
                if (policySection) areaContent.appendChild(policySection);
                                
                var statementSection = createSourceSection(filteredEntries.public_statements, "statement", "Public Statements");
                if (statementSection) areaContent.appendChild(statementSection);


                policyArea.appendChild(areaContent);
                areasContainer.appendChild(policyArea);
            });


            // Add section title for alliance-specific policies
            if (areasContainer.children.length > 0) {
                var policySectionTitle = document.createElement("div");
                policySectionTitle.style.cssText = "font-family: 'Plus Jakarta Sans', sans-serif; font-weight: 700; font-size: 0.95rem; color: var(--navy); margin-bottom: 16px;";
                policySectionTitle.textContent = "Alliance-Level Policies";
                content.appendChild(policySectionTitle);
            }


            document.getElementById("alliance-subtitle").textContent = totalCount + " alliance entries â€¢ " + memberContributions.length + " members with policy data";
            content.appendChild(areasContainer);
        }


        // Alliance filter event listeners
        ["alliance-filter-legal", "alliance-filter-policy", "alliance-filter-statement"].forEach(function(id) {
            document.getElementById(id).addEventListener("change", renderAllianceOverview);
        });


        // Alliance dropdown event listener
        document.getElementById("alliance-dropdown").addEventListener("change", function() {
            if (this.value) {
                selectAlliance(this.value);
            } else {
                // Clear selection when "Choose an alliance" is selected
                selectedAlliance = null;
                document.getElementById("alliance-header").style.display = "none";
                document.getElementById("alliance-members-list").style.display = "none";
                document.getElementById("alliance-content").innerHTML = '<div class="placeholder"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M3.055 11H5a2 2 0 012 2v1a2 2 0 002 2 2 2 0 012 2v2.945M8 3.935V5.5A2.5 2.5 0 0010.5 8h.5a2 2 0 012 2 2 2 0 104 0 2 2 0 012-2h1.064M15 20.488V18a2 2 0 012-2h3.064M21 12a9 9 0 11-18 0 9 9 0 0118 0z" /></svg><p>Select an alliance to explore combined<br>defense AI policies of member states</p></div>';
                // Clear map highlighting
                d3.selectAll(".country-path").classed("alliance-member", false);
            }
        });


        function getActiveFilters() {
            return {
                legal: document.getElementById("filter-legal").checked,
                policy: document.getElementById("filter-policy").checked,
                                statement: document.getElementById("filter-statement").checked
            };
        }


        function createSourceItem(entry) {
            var text = entry.text || entry;
            var url = entry.url || null;
            
            var item = document.createElement("div");
            item.className = "source-item";


            var itemHeader = document.createElement("div");
            itemHeader.className = "source-item-header";


            var titleRow = document.createElement("div");
            titleRow.className = "source-item-title-row";


            var title = document.createElement("span");
            title.className = "source-item-title";
            title.textContent = parseTitleWithoutDate(text);
            titleRow.appendChild(title);


            var dateStr = extractDate(text);
            if (dateStr) {
                var dateBadge = document.createElement("span");
                dateBadge.className = "source-item-date";
                dateBadge.textContent = dateStr;
                titleRow.appendChild(dateBadge);
            }


            if (url) {
                var link = document.createElement("button");
                link.className = "source-link";
                link.type = "button";
                link.title = "Open source document";
                link.innerHTML = '<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14" /></svg>';
                (function(targetUrl) {
                    link.addEventListener("click", function(e) {
                        e.stopPropagation();
                        e.preventDefault();
                        window.open(targetUrl, "_blank");
                    });
                })(url);
                titleRow.appendChild(link);
            }


            itemHeader.appendChild(titleRow);


            var icon = document.createElementNS("http://www.w3.org/2000/svg", "svg");
            icon.setAttribute("class", "source-item-expand");
            icon.setAttribute("viewBox", "0 0 24 24");
            icon.setAttribute("fill", "none");
            icon.setAttribute("stroke", "currentColor");
            var path = document.createElementNS("http://www.w3.org/2000/svg", "path");
            path.setAttribute("stroke-linecap", "round");
            path.setAttribute("stroke-linejoin", "round");
            path.setAttribute("stroke-width", "2");
            path.setAttribute("d", "M19 9l-7 7-7-7");
            icon.appendChild(path);
            itemHeader.appendChild(icon);


            itemHeader.addEventListener("click", function(e) { 
                if (e.target.closest(".source-link")) return;
                item.classList.toggle("expanded"); 
            });
            item.appendChild(itemHeader);


            var details = document.createElement("div");
            details.className = "source-item-details";
            details.innerHTML = parseDetails(text);
            item.appendChild(details);


            return item;
        }


        function createSourceSection(entries, type, label) {
            if (entries.length === 0) return null;


            var section = document.createElement("div");
            section.className = "source-section";


            var header = document.createElement("div");
            header.className = "source-type-header " + type;
            header.textContent = label + " (" + entries.length + ")";
            section.appendChild(header);


            var items = document.createElement("div");
            items.className = "source-items";
            entries.forEach(function(entry) { items.appendChild(createSourceItem(entry)); });
            section.appendChild(items);


            return section;
        }


        function renderOverview() {
            if (!selectedCountry) return;


            var data = policyData[selectedCountry];
            var filters = getActiveFilters();
            var displayName = displayNames[selectedCountry] || selectedCountry;
            var summary = rawData.summaries ? rawData.summaries[selectedCountry] : null;


            document.getElementById("overview-header").style.display = "flex";
            document.getElementById("overview-country-name").textContent = displayName;


            // Calculate totals and area distribution for pie chart
            var totalCount = 0;
            var areaDistribution = [];
            var legalCount = 0, policyCount = 0, statementCount = 0;


            var policyAreaNames = [
                "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment",
                "Adoption & Intent of Use",
                "Acquisition & Procurement",
                "International Cooperation & Interoperability",
                "Technical Safety & Security Requirements",
                "Ethical Guidelines & Restrictions"
            ];


            var pieColors = ["#1a2744", "#d64045", "#6b3074", "#0d7377", "#e07020", "#4a9d5b"];


            policyAreaNames.forEach(function(areaName, idx) {
                var entries = data[areaName];
                if (!entries) return;
                
                var areaLegal = filters.legal ? entries.legal_directives.length : 0;
                var areaPolicy = filters.policy ? entries.policy_documents.length : 0;
                var areaStatement = filters.statement ? entries.public_statements.length : 0;
                var areaTotal = areaLegal + areaPolicy + areaStatement;
                
                if (areaTotal > 0) {
                    areaDistribution.push({
                        name: areaName,
                        count: areaTotal,
                        color: pieColors[idx]
                    });
                    totalCount += areaTotal;
                    legalCount += areaLegal;
                    policyCount += areaPolicy;
                    statementCount += areaStatement;
                }
            });


            // Build policy areas container
            var areasContainer = document.createElement("div");
            areasContainer.className = "policy-areas";


            Object.keys(data).forEach(function(areaName) {
                var entries = data[areaName];
                var filtered = {
                    legal_directives: filters.legal ? entries.legal_directives : [],
                    policy_documents: filters.policy ? entries.policy_documents : [],
                    public_statements: filters.statement ? entries.public_statements : []
                };


                var areaTotal = filtered.legal_directives.length + filtered.policy_documents.length +
                                filtered.public_statements.length;


                if (areaTotal === 0) return;


                var policyArea = document.createElement("div");
                policyArea.className = "policy-area";
                
                // Set data-area attribute for consistent color coding
                if (areaName.indexOf("LAWS") !== -1) policyArea.setAttribute("data-area", "laws");
                else if (areaName.indexOf("Adoption") !== -1) policyArea.setAttribute("data-area", "adoption");
                else if (areaName.indexOf("Acquisition") !== -1) policyArea.setAttribute("data-area", "acquisition");
                else if (areaName.indexOf("International") !== -1) policyArea.setAttribute("data-area", "international");
                else if (areaName.indexOf("Technical") !== -1) policyArea.setAttribute("data-area", "technical");
                else if (areaName.indexOf("Ethical") !== -1) policyArea.setAttribute("data-area", "ethical");


                var areaHeader = document.createElement("div");
                areaHeader.className = "policy-area-header";
                areaHeader.addEventListener("click", function() { policyArea.classList.toggle("expanded"); });


                var areaTitle = document.createElement("span");
                areaTitle.className = "policy-area-title";
                areaTitle.textContent = areaName;
                areaHeader.appendChild(areaTitle);


                var areaMeta = document.createElement("div");
                areaMeta.className = "policy-area-meta";


                var sourceCount = document.createElement("span");
                sourceCount.className = "source-count";
                sourceCount.textContent = areaTotal + " entries";
                areaMeta.appendChild(sourceCount);


                var expandIcon = document.createElementNS("http://www.w3.org/2000/svg", "svg");
                expandIcon.setAttribute("class", "expand-icon");
                expandIcon.setAttribute("viewBox", "0 0 24 24");
                expandIcon.setAttribute("fill", "none");
                expandIcon.setAttribute("stroke", "currentColor");
                var expandPath = document.createElementNS("http://www.w3.org/2000/svg", "path");
                expandPath.setAttribute("stroke-linecap", "round");
                expandPath.setAttribute("stroke-linejoin", "round");
                expandPath.setAttribute("stroke-width", "2");
                expandPath.setAttribute("d", "M19 9l-7 7-7-7");
                expandIcon.appendChild(expandPath);
                areaMeta.appendChild(expandIcon);


                areaHeader.appendChild(areaMeta);
                policyArea.appendChild(areaHeader);


                var areaContent = document.createElement("div");
                areaContent.className = "policy-area-content";


                var legalSection = createSourceSection(filtered.legal_directives, "legal", "Legal Directives");
                if (legalSection) areaContent.appendChild(legalSection);


                var policySection = createSourceSection(filtered.policy_documents, "policy", "Policy Documents");
                if (policySection) areaContent.appendChild(policySection);
                                
                var statementSection = createSourceSection(filtered.public_statements, "statement", "Public Statements");
                if (statementSection) areaContent.appendChild(statementSection);


                policyArea.appendChild(areaContent);
                areasContainer.appendChild(policyArea);
            });


            var areaCount = areasContainer.children.length;
            document.getElementById("overview-subtitle").textContent = totalCount + " entries across " + areaCount + " policy areas";


            var content = document.getElementById("overview-content");
            content.innerHTML = "";
            
            if (areaCount === 0) {
                content.innerHTML = '<div class="no-data-message">No results match the current filters</div>';
                return;
            }


            // Add summary box
            if (summary) {
                var summaryBox = document.createElement("div");
                summaryBox.className = "country-summary-box";
                summaryBox.textContent = summary;
                content.appendChild(summaryBox);
            }


            // Add insights row with pie chart and bar chart (Option A: Side by Side Layout)
            var insightsRow = document.createElement("div");
            insightsRow.className = "country-insights-row";
            insightsRow.id = "insights-container";


            // Define policy areas with keys for hover coordination
            var policyAreasConfig = [
                { key: "ethical", name: "Ethical Guidelines & Restrictions", short: "Ethical\nGuidelines", color: "#4a9d5b" },
                { key: "adoption", name: "Adoption & Intent of Use", short: "Adoption &\nIntent", color: "#d64045" },
                { key: "acquisition", name: "Acquisition & Procurement", short: "Acquisition &\nProcurement", color: "#6b3074" },
                { key: "technical", name: "Technical Safety & Security Requirements", short: "Technical\nSafety", color: "#e07020" },
                { key: "laws", name: "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment", short: "LAWS\nDeployment", color: "#1a2744" },
                { key: "international", name: "International Cooperation & Interoperability", short: "Int'l\nCooperation", color: "#0d7377" }
            ];


            // Build data object keyed by area key
            var chartData = {};
            policyAreasConfig.forEach(function(areaConfig) {
                var entries = data[areaConfig.name];
                if (entries) {
                    var areaLegal = filters.legal ? entries.legal_directives.length : 0;
                    var areaPolicy = filters.policy ? entries.policy_documents.length : 0;
                    var areaStatement = filters.statement ? entries.public_statements.length : 0;
                    chartData[areaConfig.key] = areaLegal + areaPolicy + areaStatement;
                } else {
                    chartData[areaConfig.key] = 0;
                }
            });


            // ===== PIE CHART SECTION =====
            var pieSection = document.createElement("div");
            pieSection.className = "chart-section";


            var pieTitle = document.createElement("div");
            pieTitle.className = "pie-chart-title";
            pieTitle.textContent = "Policy Distribution";
            pieSection.appendChild(pieTitle);


            var pieWrapper = document.createElement("div");
            pieWrapper.className = "pie-chart-wrapper";


            // Create SVG pie chart (Option A: Enlarged dimensions)
            var pieSvgWidth = 500;
            var pieSvgHeight = 380;
            var pieRadius = 100;
            var pieCenterX = pieSvgWidth / 2;
            var pieCenterY = pieSvgHeight / 2;


            var pieSvg = document.createElementNS("http://www.w3.org/2000/svg", "svg");
            pieSvg.setAttribute("class", "pie-chart-svg");
            pieSvg.setAttribute("width", pieSvgWidth);
            pieSvg.setAttribute("height", pieSvgHeight);
            pieSvg.setAttribute("viewBox", "0 0 " + pieSvgWidth + " " + pieSvgHeight);


            // Draw pie slices
            var pieStartAngle = -Math.PI / 2;
            var pieSliceData = [];


            policyAreasConfig.forEach(function(areaConfig) {
                var value = chartData[areaConfig.key];
                if (value === 0) return;


                var sliceAngle = (value / totalCount) * 2 * Math.PI;
                var endAngle = pieStartAngle + sliceAngle;


                var x1 = pieCenterX + pieRadius * Math.cos(pieStartAngle);
                var y1 = pieCenterY + pieRadius * Math.sin(pieStartAngle);
                var x2 = pieCenterX + pieRadius * Math.cos(endAngle);
                var y2 = pieCenterY + pieRadius * Math.sin(endAngle);


                var largeArc = sliceAngle > Math.PI ? 1 : 0;
                var pathD = "M " + pieCenterX + " " + pieCenterY + " L " + x1 + " " + y1 + " A " + pieRadius + " " + pieRadius + " 0 " + largeArc + " 1 " + x2 + " " + y2 + " Z";


                var slicePath = document.createElementNS("http://www.w3.org/2000/svg", "path");
                slicePath.setAttribute("d", pathD);
                slicePath.setAttribute("fill", areaConfig.color);
                slicePath.setAttribute("stroke", "white");
                slicePath.setAttribute("stroke-width", "2");
                slicePath.setAttribute("class", "pie-slice");
                slicePath.setAttribute("data-area", areaConfig.key);
                slicePath.setAttribute("data-area-name", areaConfig.name);
                pieSvg.appendChild(slicePath);


                // Store for labels
                var midAngle = pieStartAngle + sliceAngle / 2;
                pieSliceData.push({
                    key: areaConfig.key,
                    name: areaConfig.name,
                    short: areaConfig.short,
                    color: areaConfig.color,
                    midAngle: midAngle,
                    pct: Math.round((value / totalCount) * 100)
                });


                pieStartAngle = endAngle;
            });


            // Draw pie labels with leader lines
            var pieLabelRadius = pieRadius + 18;
            var pieTextOffset = 25;


            pieSliceData.forEach(function(slice) {
                var midAngle = slice.midAngle;
                var edgeX = pieCenterX + pieRadius * Math.cos(midAngle);
                var edgeY = pieCenterY + pieRadius * Math.sin(midAngle);
                var anchorX = pieCenterX + pieLabelRadius * Math.cos(midAngle);
                var anchorY = pieCenterY + pieLabelRadius * Math.sin(midAngle);
                var isRight = Math.cos(midAngle) >= 0;
                var lineEndX = isRight ? anchorX + pieTextOffset : anchorX - pieTextOffset;


                // Leader line
                var leaderLine = document.createElementNS("http://www.w3.org/2000/svg", "polyline");
                leaderLine.setAttribute("points", edgeX + "," + edgeY + " " + anchorX + "," + anchorY + " " + lineEndX + "," + anchorY);
                leaderLine.setAttribute("fill", "none");
                leaderLine.setAttribute("stroke", "#999");
                leaderLine.setAttribute("stroke-width", "1");
                leaderLine.setAttribute("class", "pie-leader-line");
                leaderLine.setAttribute("data-area", slice.key);
                pieSvg.appendChild(leaderLine);


                // Dot at line end
                var leaderDot = document.createElementNS("http://www.w3.org/2000/svg", "circle");
                leaderDot.setAttribute("cx", lineEndX);
                leaderDot.setAttribute("cy", anchorY);
                leaderDot.setAttribute("r", "3");
                leaderDot.setAttribute("fill", slice.color);
                leaderDot.setAttribute("class", "pie-leader-dot");
                leaderDot.setAttribute("data-area", slice.key);
                pieSvg.appendChild(leaderDot);


                // Label text
                var labelText = document.createElementNS("http://www.w3.org/2000/svg", "text");
                labelText.setAttribute("x", isRight ? lineEndX + 6 : lineEndX - 6);
                labelText.setAttribute("text-anchor", isRight ? "start" : "end");
                labelText.setAttribute("font-size", "12");
                labelText.setAttribute("font-family", "Plus Jakarta Sans, sans-serif");
                labelText.setAttribute("font-weight", "500");
                labelText.setAttribute("fill", "#333");
                labelText.setAttribute("class", "pie-label");
                labelText.setAttribute("data-area", slice.key);


                var lines = slice.short.split("\n");
                lines.forEach(function(txt, idx) {
                    var tspan = document.createElementNS("http://www.w3.org/2000/svg", "tspan");
                    tspan.setAttribute("x", isRight ? lineEndX + 6 : lineEndX - 6);
                    if (idx === 0) {
                        tspan.setAttribute("y", anchorY - 5);
                    } else {
                        tspan.setAttribute("dy", "14");
                    }
                    tspan.textContent = idx === lines.length - 1 ? txt + " (" + slice.pct + "%)" : txt;
                    labelText.appendChild(tspan);
                });


                pieSvg.appendChild(labelText);
            });


            pieWrapper.appendChild(pieSvg);
            pieSection.appendChild(pieWrapper);
            insightsRow.appendChild(pieSection);


            // ===== BAR CHART SECTION =====
            var barSection = document.createElement("div");
            barSection.className = "chart-section";


            var barTitle = document.createElement("div");
            barTitle.className = "bar-chart-title";
            barTitle.textContent = "Number of Policies by Area";
            barSection.appendChild(barTitle);


            var barWrapper = document.createElement("div");
            barWrapper.className = "bar-chart-wrapper";


            // Create SVG bar chart
            var barSvgWidth = 520;
            var barSvgHeight = 320;
            var barMargin = { top: 30, right: 25, bottom: 80, left: 55 };
            var barWidth = barSvgWidth - barMargin.left - barMargin.right;
            var barHeight = barSvgHeight - barMargin.top - barMargin.bottom;


            var barSvg = document.createElementNS("http://www.w3.org/2000/svg", "svg");
            barSvg.setAttribute("class", "bar-chart-svg");
            barSvg.setAttribute("width", barSvgWidth);
            barSvg.setAttribute("height", barSvgHeight);
            barSvg.setAttribute("viewBox", "0 0 " + barSvgWidth + " " + barSvgHeight);


            // Get max value for scale - round up to nearest even number
            var maxBarValue = Math.max.apply(null, Object.values(chartData).filter(function(v) { return v > 0; }));
            if (maxBarValue === 0 || maxBarValue === 1) maxBarValue = 2;
            // Round up to nearest even number
            maxBarValue = Math.ceil(maxBarValue / 2) * 2;
            var yScale = barHeight / maxBarValue;
            var singleBarWidth = barWidth / policyAreasConfig.length * 0.7;
            var barGap = barWidth / policyAreasConfig.length * 0.3;


            // Y-axis line
            var yAxisLine = document.createElementNS("http://www.w3.org/2000/svg", "line");
            yAxisLine.setAttribute("x1", barMargin.left);
            yAxisLine.setAttribute("y1", barMargin.top);
            yAxisLine.setAttribute("x2", barMargin.left);
            yAxisLine.setAttribute("y2", barMargin.top + barHeight);
            yAxisLine.setAttribute("stroke", "#ccc");
            yAxisLine.setAttribute("stroke-width", "1");
            barSvg.appendChild(yAxisLine);


            // X-axis line
            var xAxisLine = document.createElementNS("http://www.w3.org/2000/svg", "line");
            xAxisLine.setAttribute("x1", barMargin.left);
            xAxisLine.setAttribute("y1", barMargin.top + barHeight);
            xAxisLine.setAttribute("x2", barMargin.left + barWidth);
            xAxisLine.setAttribute("y2", barMargin.top + barHeight);
            xAxisLine.setAttribute("stroke", "#ccc");
            xAxisLine.setAttribute("stroke-width", "1");
            barSvg.appendChild(xAxisLine);


            // Y-axis title
            var yAxisTitle = document.createElementNS("http://www.w3.org/2000/svg", "text");
            yAxisTitle.setAttribute("x", 15);
            yAxisTitle.setAttribute("y", barMargin.top + barHeight / 2);
            yAxisTitle.setAttribute("text-anchor", "middle");
            yAxisTitle.setAttribute("font-size", "11");
            yAxisTitle.setAttribute("fill", "#666");
            yAxisTitle.setAttribute("transform", "rotate(-90, 15, " + (barMargin.top + barHeight / 2) + ")");
            yAxisTitle.textContent = "Number of Policies";
            barSvg.appendChild(yAxisTitle);


            // Y-axis ticks and grid lines - every 2 numbers
            var tickStep = 2;
            var numTicks = maxBarValue / tickStep;
            for (var i = 0; i <= numTicks; i++) {
                var tickValue = i * tickStep;
                var yPos = barMargin.top + barHeight - (tickValue * yScale);


                // Grid line
                var gridLine = document.createElementNS("http://www.w3.org/2000/svg", "line");
                gridLine.setAttribute("x1", barMargin.left);
                gridLine.setAttribute("y1", yPos);
                gridLine.setAttribute("x2", barMargin.left + barWidth);
                gridLine.setAttribute("y2", yPos);
                gridLine.setAttribute("stroke", "#eee");
                gridLine.setAttribute("stroke-width", "1");
                barSvg.appendChild(gridLine);


                // Tick label
                var tickLabel = document.createElementNS("http://www.w3.org/2000/svg", "text");
                tickLabel.setAttribute("x", barMargin.left - 8);
                tickLabel.setAttribute("y", yPos + 4);
                tickLabel.setAttribute("text-anchor", "end");
                tickLabel.setAttribute("font-size", "10");
                tickLabel.setAttribute("fill", "#666");
                tickLabel.textContent = tickValue;
                barSvg.appendChild(tickLabel);
            }


            // Draw bars
            policyAreasConfig.forEach(function(areaConfig, idx) {
                var value = chartData[areaConfig.key];
                var rectHeight = value * yScale;
                var xPos = barMargin.left + idx * (singleBarWidth + barGap) + barGap / 2;
                var yPos = barMargin.top + barHeight - rectHeight;


                // Bar rectangle
                var rect = document.createElementNS("http://www.w3.org/2000/svg", "rect");
                rect.setAttribute("x", xPos);
                rect.setAttribute("y", yPos);
                rect.setAttribute("width", singleBarWidth);
                rect.setAttribute("height", rectHeight);
                rect.setAttribute("fill", areaConfig.color);
                rect.setAttribute("rx", "3");
                rect.setAttribute("class", "bar-rect");
                rect.setAttribute("data-area", areaConfig.key);
                rect.setAttribute("data-area-name", areaConfig.name);
                barSvg.appendChild(rect);


                // Value label above bar (or at baseline for zero)
                var valueLabel = document.createElementNS("http://www.w3.org/2000/svg", "text");
                valueLabel.setAttribute("x", xPos + singleBarWidth / 2);
                valueLabel.setAttribute("y", value > 0 ? yPos - 8 : barMargin.top + barHeight - 8);
                valueLabel.setAttribute("text-anchor", "middle");
                valueLabel.setAttribute("font-size", "11");
                valueLabel.setAttribute("font-weight", "600");
                valueLabel.setAttribute("fill", value > 0 ? "#333" : "#999");
                valueLabel.setAttribute("class", "bar-value");
                valueLabel.setAttribute("data-area", areaConfig.key);
                valueLabel.textContent = value;
                barSvg.appendChild(valueLabel);


                // X-axis label (rotated)
                var shortLabel = areaConfig.short.replace("\n", " ");
                var xLabel = document.createElementNS("http://www.w3.org/2000/svg", "text");
                xLabel.setAttribute("x", xPos + singleBarWidth / 2);
                xLabel.setAttribute("y", barMargin.top + barHeight + 12);
                xLabel.setAttribute("text-anchor", "start");
                xLabel.setAttribute("font-size", "10");
                xLabel.setAttribute("fill", "#666");
                xLabel.setAttribute("transform", "rotate(35, " + (xPos + singleBarWidth / 2) + ", " + (barMargin.top + barHeight + 12) + ")");
                xLabel.setAttribute("class", "bar-label");
                xLabel.setAttribute("data-area", areaConfig.key);
                xLabel.textContent = shortLabel;
                barSvg.appendChild(xLabel);
            });


            barWrapper.appendChild(barSvg);
            barSection.appendChild(barWrapper);
            insightsRow.appendChild(barSection);


            // ===== INTERACTION HINT =====
            var hintDiv = document.createElement("div");
            hintDiv.className = "insights-hint";
            hintDiv.innerHTML = "<strong>Tip:</strong> Hover to highlight + Click to expand policies below";
            insightsRow.appendChild(hintDiv);


            // ===== ADD TO DOM =====
            content.appendChild(insightsRow);


            // ===== SETUP HOVER AND CLICK INTERACTIONS =====
            setTimeout(function() {
                var container = document.getElementById("insights-container");
                if (!container) return;


                // Map from key to full policy area name
                var keyToNameMap = {};
                policyAreasConfig.forEach(function(cfg) {
                    keyToNameMap[cfg.key] = cfg.name;
                });


                var clickableElements = container.querySelectorAll(".pie-slice, .bar-rect");
                var allDataElements = container.querySelectorAll("[data-area]");


                // Hover interactions
                allDataElements.forEach(function(el) {
                    el.addEventListener("mouseenter", function() {
                        var area = this.getAttribute("data-area");
                        container.classList.add("has-hover");


                        allDataElements.forEach(function(other) {
                            if (other.getAttribute("data-area") === area) {
                                other.classList.add("highlighted");
                            }
                        });
                    });


                    el.addEventListener("mouseleave", function() {
                        container.classList.remove("has-hover");
                        allDataElements.forEach(function(other) {
                            other.classList.remove("highlighted");
                        });
                    });
                });


                // Click interactions - expand corresponding policy area
                clickableElements.forEach(function(el) {
                    el.addEventListener("click", function() {
                        var areaKey = this.getAttribute("data-area");
                        var areaName = keyToNameMap[areaKey];
                        
                        if (!areaName) return;


                        // Find the policy area section with matching name
                        var policyAreas = document.querySelectorAll(".policy-area");
                        policyAreas.forEach(function(policyArea) {
                            var titleEl = policyArea.querySelector(".policy-area-title");
                            if (titleEl && titleEl.textContent === areaName) {
                                // Expand this policy area
                                policyArea.classList.add("expanded");
                                
                                // Scroll to it smoothly
                                setTimeout(function() {
                                    policyArea.scrollIntoView({ behavior: "smooth", block: "start" });
                                }, 100);
                            }
                        });
                    });
                });
            }, 0);


            // Add policy areas
            content.appendChild(areasContainer);
        }


        document.querySelectorAll(".filter-checkbox input").forEach(function(cb) {
            cb.addEventListener("change", renderOverview);
        });


        // ===== COMPARE FUNCTIONS =====
        function toggleCompareCountry(country) {
            if (selectedCountries.has(country)) {
                selectedCountries.delete(country);
            } else if (selectedCountries.size < MAX_COMPARE) {
                selectedCountries.add(country);
            }
            updateCompareChipsState();
            updateMapHighlights();
            renderComparison();
        }


        function buildPolicyAreaDropdown() {
            var dropdown = document.getElementById("policy-area-dropdown");
            if (!dropdown) return; // Element removed in redesign
            
            var allAreas = new Set();


            Object.values(policyData).forEach(function(country) {
                Object.keys(country).forEach(function(area) { allAreas.add(area); });
            });


            Array.from(allAreas).sort().forEach(function(area) {
                var option = document.createElement("option");
                option.value = area;
                option.textContent = area;
                dropdown.appendChild(option);
            });


            dropdown.addEventListener("change", function() {
                selectedPolicyArea = this.value;
                renderComparison();
            });
        }


        function renderComparison() {
            var content = document.getElementById("compare-content");


            if (selectedCountries.size === 0) {
                content.innerHTML = '<div class="placeholder"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M9 20l-5.447-2.724A1 1 0 013 16.382V5.618a1 1 0 011.447-.894L9 7m0 13l6-3m-6 3V7m6 10l4.553 2.276A1 1 0 0021 18.382V7.618a1 1 0 00-.553-.894L15 4m0 13V4m0 0L9 7" /></svg><p>Select 2 countries to compare their<br>defense AI policy frameworks</p></div>';
                return;
            }


            if (selectedCountries.size === 1) {
                content.innerHTML = '<div class="placeholder"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 4v16m8-8H4" /></svg><p>Select one more country to<br>compare policy frameworks</p></div>';
                return;
            }


            // Get the two countries
            var countries = Array.from(selectedCountries);
            var country1 = countries[0];
            var country2 = countries[1];
            var name1 = displayNames[country1] || country1;
            var name2 = displayNames[country2] || country2;
            var data1 = policyData[country1];
            var data2 = policyData[country2];


            // ISO Alpha-3 country codes
            var isoAlpha3 = {
                "Algeria": "DZA",
                "Armenia": "ARM",
                "Australia": "AUS",
                "Azerbaijan": "AZE",
                "Belgium": "BEL",
                "Brazil": "BRA",
                "Bulgaria": "BGR",
                "Canada": "CAN",
                "China": "CHN",
                "Colombia": "COL",
                "Croatia": "HRV",
                "Czechia": "CZE",
                "Denmark": "DNK",
                "Egypt": "EGY",
                "Estonia": "EST",
                "Finland": "FIN",
                "France": "FRA",
                "Germany": "DEU",
                "Greece": "GRC",
                "Hungary": "HUN",
                "India": "IND",
                "Iran": "IRN",
                "Iraq": "IRQ",
                "Israel": "ISR",
                "Italy": "ITA",
                "Japan": "JPN",
                "Latvia": "LVA",
                "Lithuania": "LTU",
                "Morocco": "MAR",
                "Netherlands": "NLD",
                "North Korea": "PRK",
                "Norway": "NOR",
                "Pakistan": "PAK",
                "Poland": "POL",
                "Russia": "RUS",
                "Singapore": "SGP",
                "South Africa": "ZAF",
                "South Korea": "KOR",
                "Spain": "ESP",
                "Sweden": "SWE",
                "Turkey": "TUR",
                "UAE": "ARE",
                "UK": "GBR",
                "USA": "USA",
                "Ukraine": "UKR"
            };
            
            function getAlpha3(countryName) {
                return isoAlpha3[countryName] || countryName.substring(0, 3).toUpperCase();
            }


            // Calculate totals and area counts
            var policyAreas = [
                "Lethal Autonomous Weapons Systems (LAWS) Employment/Deployment",
                "Adoption & Intent of Use",
                "Acquisition & Procurement",
                "Ethical Guidelines & Restrictions",
                "International Cooperation & Interoperability",
                "Technical Safety & Security Requirements",
                "Training & Human-AI Interaction"
            ];


            function countEntries(countryData, areaName) {
                var area = countryData[areaName];
                if (!area) return 0;
                return (area.legal_directives || []).length + 
                       (area.policy_documents || []).length + 
                       (area.public_statements || []).length;
            }


            function getTotalEntries(countryData) {
                var total = 0;
                Object.keys(countryData).forEach(function(area) {
                    total += countEntries(countryData, area);
                });
                return total;
            }


            function getTimelineEntries(countryData) {
                var entries = [];
                var seen = {}; // Track unique year+title combinations
                Object.keys(countryData).forEach(function(areaName) {
                    var area = countryData[areaName];
                    if (!area) return;
                    var allSources = (area.legal_directives || [])
                        .concat(area.policy_documents || [])
                        .concat(area.public_statements || []);
                    allSources.forEach(function(entry) {
                        var text = entry.text || entry;
                        var dateMatch = text.match(/\(([A-Za-z]{3,4}\s+\d{4}|\d{4})\)/);
                        if (dateMatch) {
                            var dateStr = dateMatch[1];
                            var year = parseInt(dateStr.match(/\d{4}/)[0]);
                            var title = text.split("\n")[0].replace(/\s*\([^)]*\)\s*$/, "").trim();
                            var key = year + "|" + title.toLowerCase();
                            if (!seen[key]) {
                                seen[key] = true;
                                entries.push({ year: year, title: title, area: areaName });
                            }
                        }
                    });
                });
                return entries;
            }


            var total1 = getTotalEntries(data1);
            var total2 = getTotalEntries(data2);
            var maxValue = Math.max(total1, total2);
            var timeline1 = getTimelineEntries(data1);
            var timeline2 = getTimelineEntries(data2);


            // Build HTML
            var html = '';


            // Header chips removed - country names now above bars


            // Bar Chart Section
            html += '<div class="compare-section-box">';
            html += '<div class="chart-header-row">';
            html += '<h3 class="compare-section-title">Policy Area Coverage</h3>';
            html += '<div class="country-names-row">';
            html += '<div class="country-name-label country-1"><span class="country-name-dot"></span>' + escapeHtml(name1) + '</div>';
            html += '<div class="country-name-spacer"></div>';
            html += '<div class="country-name-label country-2">' + escapeHtml(name2) + '<span class="country-name-dot"></span></div>';
            html += '</div>';
            html += '</div>';
            html += '<div class="diverging-chart">';


            // Total row
            var leftPct = maxValue > 0 ? (total1 / maxValue) * 100 : 0;
            var rightPct = maxValue > 0 ? (total2 / maxValue) * 100 : 0;
            html += '<div class="chart-row total-row">';
            html += '<div class="chart-value-left">' + total1 + '</div>';
            html += '<div class="chart-bar-left"><div class="chart-bar left" style="width:' + leftPct + '%"></div></div>';
            html += '<div class="chart-row-label total">TOTAL ENTRIES</div>';
            html += '<div class="chart-bar-right"><div class="chart-bar right" style="width:' + rightPct + '%"></div></div>';
            html += '<div class="chart-value-right">' + total2 + '</div>';
            html += '</div>';


            // Policy area rows
            policyAreas.forEach(function(areaName, idx) {
                var count1 = countEntries(data1, areaName);
                var count2 = countEntries(data2, areaName);
                if (count1 === 0 && count2 === 0) return;


                var leftW = maxValue > 0 ? (count1 / maxValue) * 100 : 0;
                var rightW = maxValue > 0 ? (count2 / maxValue) * 100 : 0;
                var shortLabel = areaName.replace("Lethal Autonomous Weapons Systems (LAWS) ", "LAWS ").replace(" & Restrictions", "").replace(" & Interoperability", "").replace(" & Security Requirements", "").replace(" & Human-AI Interaction", "");


                html += '<div class="chart-row clickable" data-area="' + escapeHtml(areaName) + '" data-section-id="detail-section-' + idx + '">';
                html += '<div class="chart-value-left">' + count1 + '</div>';
                html += '<div class="chart-bar-left"><div class="chart-bar left" style="width:' + leftW + '%"></div></div>';
                html += '<div class="chart-row-label">' + escapeHtml(shortLabel) + '</div>';
                html += '<div class="chart-bar-right"><div class="chart-bar right" style="width:' + rightW + '%"></div></div>';
                html += '<div class="chart-value-right">' + count2 + '</div>';
                html += '</div>';
            });


            html += '</div></div>';


            // Timeline Section
            var allYears = timeline1.concat(timeline2).map(function(e) { return e.year; });
            if (allYears.length > 0) {
                var minYear = Math.min.apply(null, allYears) - 1; // One year before earliest
                var maxYear = 2025; // Fixed at 2025


                // Group entries by year for each country
                function groupByYear(entries) {
                    var grouped = {};
                    entries.forEach(function(entry) {
                        if (!grouped[entry.year]) grouped[entry.year] = [];
                        grouped[entry.year].push(entry);
                    });
                    return grouped;
                }


                var grouped1 = groupByYear(timeline1);
                var grouped2 = groupByYear(timeline2);


                html += '<div class="compare-section-box">';
                html += '<h3 class="compare-section-title">Policy Development Timeline</h3>';
                html += '<div class="compare-timeline-container">';


                // Country 1 row
                html += '<div class="timeline-row">';
                html += '<div class="timeline-row-label country-1">' + escapeHtml(getAlpha3(country1)) + '</div>';
                
                Object.keys(grouped1).forEach(function(year) {
                    var entries = grouped1[year];
                    var pos = ((year - minYear) / (maxYear - minYear)) * 100;
                    var numCols = Math.ceil(entries.length / 5);
                    
                    entries.forEach(function(entry, idx) {
                        var colIdx = Math.floor(idx / 5);
                        var rowIdx = idx % 5;
                        var offsetX = (colIdx - (numCols - 1) / 2) * 14; // 14px spacing between columns
                        // Country 1: emanate upward from bottom (near axis)
                        var offsetY = -rowIdx * 13; // Stack upward from bottom
                        
                        html += '<div class="timeline-dot country-1" style="left:calc(' + pos + '% + ' + offsetX + 'px); bottom:' + (5 + rowIdx * 13) + 'px;" data-title="' + escapeHtml(entry.title) + '" data-year="' + year + '" data-country="' + escapeHtml(name1) + '"></div>';
                    });
                });
                html += '</div>';


                // Axis
                html += '<div class="timeline-axis"></div>';


                // Country 2 row
                html += '<div class="timeline-row">';
                html += '<div class="timeline-row-label country-2">' + escapeHtml(getAlpha3(country2)) + '</div>';
                
                Object.keys(grouped2).forEach(function(year) {
                    var entries = grouped2[year];
                    var pos = ((year - minYear) / (maxYear - minYear)) * 100;
                    var numCols = Math.ceil(entries.length / 5);
                    
                    entries.forEach(function(entry, idx) {
                        var colIdx = Math.floor(idx / 5);
                        var rowIdx = idx % 5;
                        var offsetX = (colIdx - (numCols - 1) / 2) * 14;
                        // Country 2: emanate downward from top (near axis)
                        
                        html += '<div class="timeline-dot country-2" style="left:calc(' + pos + '% + ' + offsetX + 'px); top:' + (5 + rowIdx * 13) + 'px;" data-title="' + escapeHtml(entry.title) + '" data-year="' + year + '" data-country="' + escapeHtml(name2) + '"></div>';
                    });
                });
                html += '</div>';


                // Year labels
                html += '<div class="timeline-year-labels">';
                for (var y = minYear; y <= maxYear; y++) {
                    html += '<div class="timeline-year-label">' + y + '</div>';
                }
                html += '</div>';


                // Legend
                html += '<div class="timeline-legend">';
                html += '<div class="timeline-legend-item"><div class="timeline-legend-dot country-1"></div><span>' + escapeHtml(getAlpha3(country1)) + '</span></div>';
                html += '<div class="timeline-legend-item"><div class="timeline-legend-dot country-2"></div><span>' + escapeHtml(getAlpha3(country2)) + '</span></div>';
                html += '</div>';


                html += '</div></div>';
            }


            // Detail List Section (Collapsible)
            html += '<div class="compare-section-box" style="padding:0;">';
            html += '<button class="detail-toggle-btn" id="compare-detail-toggle">';
            html += '<span>View Detailed Entry List</span>';
            html += '<span class="detail-toggle-icon">â–¼</span>';
            html += '</button>';
            html += '<div class="detail-content-wrapper" id="compare-detail-content" style="padding: 24px 30px; background: #fafbfc;">';


            policyAreas.forEach(function(areaName, idx) {
                var count1 = countEntries(data1, areaName);
                var count2 = countEntries(data2, areaName);
                if (count1 === 0 && count2 === 0) return;


                var area1 = data1[areaName] || {};
                var area2 = data2[areaName] || {};


                // Determine data-area for color coding
                var dataArea = "";
                if (areaName.indexOf("LAWS") !== -1) dataArea = "laws";
                else if (areaName.indexOf("Adoption") !== -1) dataArea = "adoption";
                else if (areaName.indexOf("Acquisition") !== -1) dataArea = "acquisition";
                else if (areaName.indexOf("International") !== -1) dataArea = "international";
                else if (areaName.indexOf("Technical") !== -1) dataArea = "technical";
                else if (areaName.indexOf("Ethical") !== -1) dataArea = "ethical";


                html += '<div class="detail-policy-section" id="detail-section-' + idx + '" data-area="' + dataArea + '">';
                html += '<div class="detail-policy-header">';
                html += '<span>' + escapeHtml(areaName) + '<span class="toggle-icon">â–¼</span></span>';
                html += '<div class="detail-policy-counts">';
                html += '<span class="count-1">' + escapeHtml(getAlpha3(country1)) + ': ' + count1 + '</span>';
                html += '<span class="count-2">' + escapeHtml(getAlpha3(country2)) + ': ' + count2 + '</span>';
                html += '</div></div>';


                html += '<div class="detail-policy-content">';
                html += '<div class="detail-entries-grid">';


                // Country 1 entries
                html += '<div class="detail-country-entries country-1">';
                html += '<h4>' + escapeHtml(getAlpha3(country1)) + '</h4>';
                var entries1 = (area1.legal_directives || []).concat(area1.policy_documents || []).concat(area1.public_statements || []);
                if (entries1.length === 0) {
                    html += '<div style="color: var(--text-muted); font-size: 0.85rem;">No entries</div>';
                } else {
                    entries1.forEach(function(entry) {
                        var text = entry.text || entry;
                        var url = entry.url || null;
                        var titleWithDate = text.split("\n")[0];
                        var title = parseTitleWithoutDate(text);
                        var date = extractDate(text);
                        var details = parseDetails(text);
                        
                        html += '<div class="detail-entry-item">';
                        html += '<div class="detail-entry-header">';
                        html += '<div class="detail-entry-info">';
                        if (url) {
                            html += '<div class="detail-entry-title"><a href="' + escapeHtml(url) + '" target="_blank">' + escapeHtml(title) + '</a></div>';
                        } else {
                            html += '<div class="detail-entry-title">' + escapeHtml(title) + '</div>';
                        }
                        if (date) html += '<div class="detail-entry-date">' + escapeHtml(date) + '</div>';
                        html += '</div>';
                        if (details) {
                            html += '<svg class="detail-entry-expand" viewBox="0 0 24 24" fill="none" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>';
                        }
                        html += '</div>';
                        if (details) {
                            html += '<div class="detail-entry-description">' + details + '</div>';
                        }
                        html += '</div>';
                    });
                }
                html += '</div>';


                // Country 2 entries
                html += '<div class="detail-country-entries country-2">';
                html += '<h4>' + escapeHtml(getAlpha3(country2)) + '</h4>';
                var entries2 = (area2.legal_directives || []).concat(area2.policy_documents || []).concat(area2.public_statements || []);
                if (entries2.length === 0) {
                    html += '<div style="color: var(--text-muted); font-size: 0.85rem;">No entries</div>';
                } else {
                    entries2.forEach(function(entry) {
                        var text = entry.text || entry;
                        var url = entry.url || null;
                        var titleWithDate = text.split("\n")[0];
                        var title = parseTitleWithoutDate(text);
                        var date = extractDate(text);
                        var details = parseDetails(text);
                        
                        html += '<div class="detail-entry-item">';
                        html += '<div class="detail-entry-header">';
                        html += '<div class="detail-entry-info">';
                        if (url) {
                            html += '<div class="detail-entry-title"><a href="' + escapeHtml(url) + '" target="_blank">' + escapeHtml(title) + '</a></div>';
                        } else {
                            html += '<div class="detail-entry-title">' + escapeHtml(title) + '</div>';
                        }
                        if (date) html += '<div class="detail-entry-date">' + escapeHtml(date) + '</div>';
                        html += '</div>';
                        if (details) {
                            html += '<svg class="detail-entry-expand" viewBox="0 0 24 24" fill="none" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>';
                        }
                        html += '</div>';
                        if (details) {
                            html += '<div class="detail-entry-description">' + details + '</div>';
                        }
                        html += '</div>';
                    });
                }
                html += '</div>';


                html += '</div></div></div>';
            });


            html += '</div></div>';


            content.innerHTML = html;


            // Add event listeners
            // Toggle detail list
            var toggleBtn = document.getElementById("compare-detail-toggle");
            var detailContent = document.getElementById("compare-detail-content");
            if (toggleBtn && detailContent) {
                toggleBtn.addEventListener("click", function() {
                    toggleBtn.classList.toggle("open");
                    detailContent.classList.toggle("open");
                });
            }


            // Policy section header clicks (collapse/expand)
            content.querySelectorAll(".detail-policy-header").forEach(function(header) {
                header.addEventListener("click", function() {
                    header.parentElement.classList.toggle("expanded");
                });
            });


            // Detail entry item clicks (expand/collapse description)
            content.querySelectorAll(".detail-entry-header").forEach(function(header) {
                header.addEventListener("click", function(e) {
                    if (e.target.closest("a")) return; // Don't toggle if clicking link
                    header.parentElement.classList.toggle("expanded");
                });
            });


            // Chart row clicks
            content.querySelectorAll(".chart-row.clickable").forEach(function(row) {
                row.addEventListener("click", function() {
                    var sectionId = row.dataset.sectionId;
                    if (sectionId) {
                        // Open detail list if not open
                        if (!detailContent.classList.contains("open")) {
                            toggleBtn.click();
                        }
                        // Scroll to section and expand it
                        setTimeout(function() {
                            var section = document.getElementById(sectionId);
                            if (section) {
                                if (!section.classList.contains("expanded")) {
                                    section.classList.add("expanded");
                                }
                                section.scrollIntoView({ behavior: "smooth", block: "start" });
                            }
                        }, 100);
                    }
                });
            });


            // Timeline tooltip
            var tooltip = document.getElementById("compare-timeline-tooltip");
            if (!tooltip) {
                tooltip = document.createElement("div");
                tooltip.id = "compare-timeline-tooltip";
                tooltip.className = "compare-tooltip";
                document.body.appendChild(tooltip);
            }


            content.querySelectorAll(".timeline-dot").forEach(function(dot) {
                dot.addEventListener("mouseenter", function() {
                    tooltip.innerHTML = '<strong>' + dot.dataset.country + '</strong><br>' + dot.dataset.title + '<br><em>' + dot.dataset.year + '</em>';
                    tooltip.classList.add("visible");
                });
                dot.addEventListener("mousemove", function(e) {
                    tooltip.style.left = (e.clientX + 12) + "px";
                    tooltip.style.top = (e.clientY - 50) + "px";
                });
                dot.addEventListener("mouseleave", function() {
                    tooltip.classList.remove("visible");
                });
            });
        }


        // ===== MAP =====
        function updateMapHighlights() {
            var paths = document.querySelectorAll(".country-path");
            
            paths.forEach(function(path) {
                var country = path.getAttribute("data-country");
                var mapName = path.getAttribute("data-map-name");
                var isSelected = false;
                var isDisabled = false;
                var isAllianceMember = false;


                if (currentView === "overview") {
                    isSelected = country === selectedCountry;
                } else if (currentView === "alliance" && selectedAlliance) {
                    // Check if this country is a member of the selected alliance
                    var members = allianceMembers[selectedAlliance];
                    if (members && mapName) {
                        var memberName = allianceMemberMap[mapName];
                        if (memberName) {
                            isAllianceMember = members.indexOf(memberName) !== -1;
                        }
                        // Also check direct name match as fallback
                        if (!isAllianceMember) {
                            isAllianceMember = members.some(function(m) {
                                return mapName.indexOf(m) !== -1 || m.indexOf(mapName) !== -1;
                            });
                        }
                    }
                } else if (currentView === "compare") {
                    isSelected = selectedCountries.has(country);
                    isDisabled = selectedCountries.size >= MAX_COMPARE && !isSelected && policyData[country];
                }


                path.classList.remove("selected", "disabled", "alliance-member");
                if (isSelected) path.classList.add("selected");
                if (isDisabled) path.classList.add("disabled");
                if (isAllianceMember) path.classList.add("alliance-member");
            });
        }


        function showTooltip(event, countryName) {
            var displayName = displayNames[countryName] || countryName;
            tooltip.querySelector(".tooltip-title").textContent = displayName;


            var msg = "Click to select";
            if (currentView === "compare" && selectedCountries.size >= MAX_COMPARE && !selectedCountries.has(countryName)) {
                msg = "Max " + MAX_COMPARE + " countries selected";
            } else if (currentView === "alliance") {
                msg = policyData[countryName] ? "Click to view country" : "No country data available";
            }
            tooltip.querySelector(".tooltip-subtitle").textContent = msg;


            tooltip.style.left = (event.clientX + 15) + "px";
            tooltip.style.top = (event.clientY - 10) + "px";
            tooltip.classList.add("visible");
        }


        function hideTooltip() { tooltip.classList.remove("visible"); }


        function showAllianceMemberTooltip(event, mapName, memberName) {
            var allianceFullNames = {
                "NATO": "NATO",
                "AUKUS": "AUKUS", 
                "FVEY": "Five Eyes"
            };
            tooltip.querySelector(".tooltip-title").textContent = memberName;
            tooltip.querySelector(".tooltip-subtitle").textContent = allianceFullNames[selectedAlliance] + " member";
            tooltip.style.left = (event.clientX + 15) + "px";
            tooltip.style.top = (event.clientY - 10) + "px";
            tooltip.classList.add("visible");
        }


        async function initMap() {
            var width = 960;
            var height = 480;


            var svg = d3.select("#map-svg")
                .attr("width", "100%")
                .attr("height", height)
                .attr("viewBox", "0 0 " + width + " " + height)
                .attr("preserveAspectRatio", "xMidYMid meet");


            // Create a group for zoomable content
            var g = svg.append("g").attr("id", "map-group");


            var projection = d3.geoNaturalEarth1()
                .scale(180)
                .translate([width / 2, height / 2 + 25]);


            var path = d3.geoPath().projection(projection);


            // Add ocean background
            g.append("rect")
                .attr("class", "ocean")
                .attr("width", width)
                .attr("height", height);


            // Add graticule
            var graticule = d3.geoGraticule();
            g.append("path").datum(graticule).attr("class", "graticule").attr("d", path);


            // Setup zoom behavior
            mapZoom = d3.zoom()
                .scaleExtent([1, 8])
                .on("zoom", function(event) {
                    g.attr("transform", event.transform);
                });


            svg.call(mapZoom);


            // Zoom controls
            document.getElementById("zoom-in").addEventListener("click", function() {
                svg.transition().duration(300).call(mapZoom.scaleBy, 1.5);
            });


            document.getElementById("zoom-out").addEventListener("click", function() {
                svg.transition().duration(300).call(mapZoom.scaleBy, 0.67);
            });


            document.getElementById("zoom-reset").addEventListener("click", function() {
                svg.transition().duration(300).call(mapZoom.transform, d3.zoomIdentity);
            });


            try {
                var world = await d3.json("https://cdn.jsdelivr.net/npm/world-atlas@2/countries-110m.json");
                var countries = topojson.feature(world, world.objects.countries);


                var countryNames = {};
                world.objects.countries.geometries.forEach(function(geo) {
                    countryNames[geo.id] = geo.properties.name;
                });


                g.selectAll(".country-path")
                    .data(countries.features)
                    .enter()
                    .append("path")
                    .attr("class", function(d) {
                        var name = countryNames[d.id] || d.properties.name;
                        var mappedName = countryNameMap[name];
                        return "country-path" + (mappedName && policyData[mappedName] ? " has-data" : "");
                    })
                    .attr("d", path)
                    .attr("data-country", function(d) {
                        var name = countryNames[d.id] || d.properties.name;
                        return countryNameMap[name] || null;
                    })
                    .attr("data-map-name", function(d) {
                        return countryNames[d.id] || d.properties.name;
                    })
                    .on("click", function(event, d) {
                        var name = countryNames[d.id] || d.properties.name;
                        var mappedName = countryNameMap[name];
                        if (mappedName && policyData[mappedName]) {
                            if (currentView === "overview") {
                                selectOverviewCountry(mappedName);
                            } else if (currentView === "alliance") {
                                // Switch to Country Overview and select this country
                                switchToCountryOverview(mappedName);
                            } else {
                                if (selectedCountries.has(mappedName) || selectedCountries.size < MAX_COMPARE) {
                                    toggleCompareCountry(mappedName);
                                }
                            }
                        }
                    })
                    .on("mousemove", function(event, d) {
                        var name = countryNames[d.id] || d.properties.name;
                        var mappedName = countryNameMap[name];
                        
                        // Show tooltip for countries with data, or alliance members
                        if (mappedName && policyData[mappedName]) {
                            showTooltip(event, mappedName);
                        } else if (currentView === "alliance" && selectedAlliance) {
                            var memberName = allianceMemberMap[name];
                            if (memberName && allianceMembers[selectedAlliance].indexOf(memberName) !== -1) {
                                showAllianceMemberTooltip(event, name, memberName);
                            }
                        }
                    })
                    .on("mouseout", hideTooltip);


                document.getElementById("map-loading").style.display = "none";
                document.getElementById("map-svg").style.display = "block";


                // Auto-select removed


            } catch (error) {
                console.error("Error loading map:", error);
                document.getElementById("map-loading").innerHTML = '<span style="color: #d64045;">Error loading map. Please refresh.</span>';
            }
        }


        buildDropdowns();
            initCountrySearch();
        buildPolicyAreaDropdown();
        
        // Check if D3 and TopoJSON loaded successfully before initializing map
        if (typeof d3 !== 'undefined' && typeof topojson !== 'undefined') {
            initMap().catch(function(error) {
                console.error("Map initialization error:", error);
                document.getElementById("map-loading").innerHTML = '<span style="color: rgba(255,255,255,0.7);">Could not load map.<br>Use country chips below to navigate.</span>';
                // Auto-select removed
            });
        } else {
            // Show fallback message if libraries didn't load
            document.getElementById("map-loading").innerHTML = '<span style="color: rgba(255,255,255,0.7);">Map requires external libraries.<br>Use country chips below to navigate.</span>';
            // Auto-select USA after a brief delay
            // Auto-select removed
        }
    </script>
</body>
</html>
